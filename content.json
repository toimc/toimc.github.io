{"meta":{"title":"Coding World","subtitle":"Stay hungry, stay foolish","description":"指尖改变世界","author":"var author='Brian'","url":"https://www.toimc.com","root":"/"},"pages":[{"title":"archives","date":"2017-10-19T03:01:43.000Z","updated":"2017-10-19T03:01:44.000Z","comments":true,"path":"archives/index.html","permalink":"https://www.toimc.com/archives/index.html","excerpt":"","text":""},{"title":"categories","date":"2017-10-19T07:39:45.000Z","updated":"2019-02-13T03:09:54.000Z","comments":true,"path":"categories/index.html","permalink":"https://www.toimc.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-10-19T03:01:34.000Z","updated":"2019-02-13T03:09:54.000Z","comments":true,"path":"tags/index.html","permalink":"https://www.toimc.com/tags/index.html","excerpt":"","text":""},{"title":"print(\"关于\"+Author)","date":"2017-10-19T03:02:03.000Z","updated":"2021-03-14T13:09:21.054Z","comments":true,"path":"about/index.html","permalink":"https://www.toimc.com/about/index.html","excerpt":"","text":"Hi, 大家好，我是Brian。 我热爱跑步、游泳，更喜欢一个宁静的午后，一杯绿茶，写写代码与博客。 作为开发人员的经验 我是toimc团队的高级Web开发人员，曾经在互联网大厂里面搬砖，做过跨专业的应用，但是由于身体原因和个人喜好，我选择了转行——这是我在30岁之前做的最正确的决定之一。我热爱编程，所以我四处寻找实践的机会，最终我成功的转型了。 在2018年，我组建了自己的团队，开始以工作室的形式，提供企业咨询、软件培训、微服务框架、服务治理等软件服务。同时，我非常的喜欢前端技术，不断的去尝试比如：Angular，React(Meteor)，Vue等框架与技术，结合着自己对于数据库、自动化、容器化技术的理解，在公司创立了多种应用场景，解决了公司的流程问题，提升了团队的开发效率。 作为讲师的经验 在工作与生活中，看到越来越多的朋友与同事，因为技术或者择业而困惑不已，我想通过自己的绵薄之力去改变这个现状，去帮助到他们，所以我决定通过视频的方式帮助更多的人。我的座右铭是“让学习变成一种快乐，让分享成为一种习惯”——这也是我们的愿景。通过不断的分享，总结自己也能得到提升，也能帮助到他人。我在这个过程中，非常的快乐，我也将一直做下去。 如果，你也想加入我们的团队，认同我们的愿景，请联系我们吧~~~"},{"title":"我的课程","date":"2020-12-31T16:00:00.000Z","updated":"2021-03-15T01:27:54.712Z","comments":true,"path":"lessons/index.html","permalink":"https://www.toimc.com/lessons/index.html","excerpt":"","text":"概述Hi, 在《慕课网》录制了如下视频课程： 3小时速成 Vue2.x 核心技术：了解vue2.x的核心技术，建立前端组件化的思想 大前端-高级前端工程师，对标P6+：慕课精品成长课，培养更高思维+技术能力的综合性高端前端人才 初衷愿景：传播技术的种子，让分享带来价值 经验：如果一个人在学习一项新技术的时候，想象的最终他是要把这项技术输出或者说是交给别人，那么他正在使用一种叫做输出式的学习方式。 好的老师，不应该是云里雾里，而是言简意赅通俗易懂，那么这句话，我之前还不是特别的理解，但是现在我非常的认同。 过程：所有录好的视频，都会重复的去听，精心的剪辑。同时，在录制之前，我会考量所讲内容是否是最佳的一种表达方式，是否能够让没有任何前端基础的同学也能够听懂也能够去理解。所以，视频总是录了又删删了又录，我相信这些努力是有价值的，因为大家在听到看到我的视频的时候，会觉得这门技术不是那么的冷冰冰，它是可以学会和掌握的。 2020年年终总结告别了2020磨难的一年，新的一年里大家有没有准备好继续出发了呢？ 《大前端》课程已陪伴了大家一年，在过去的一年中，我们团队秉持着“不忘初心，方得始终”服务同学的态度，为大家更新了视频的内容，并扩展了Vue3的内容，具体数据如下： 先后对第一批推出的100+小时视频，其中152节视频进行了精剪，加速，内容修正； 加入扩展的Vue3的内容12+小时，并预计后续继续优化，扩展部分TypeScript知识； 从2020年1月1日0时0分0秒至2021年1月1日0时0分0秒，共回复了1252条同学的问题，所有问题均已实现闭环（已采纳，或者已回复）； 统计问答区的高频问题144条，并更新对应的视频的内容，或加入字幕；梳理对出对学习有帮助的问答，课程中让大家更方便查看。 补充Q群中的资料，多次发布重要的技术更新公告通知，并配合慕课完善了资料的访问方式； 2020年完成了6次直播，收获了同学们的喜爱以外，帮助同学们修改简历，加强沟通，调整“悲观”的心态，已有多位同学成为我们的一员； 2021年的计划： 课程：设计同学们所需知识内容的直播，继续保持内容的更新，参与同学答疑； 教学环节：丰富教学环节，增大学习过程的交互，让学习体验提升，效果更友好。 项目：研讨微服务、Node后台、移动端（跨端）的项目储备与内容设计； 社区：完善一期社区功能，升级完整Vue3对应的代码，研讨移动端内容（预计）；研讨开源基础的框架与代码，做开源项目； 相关福利 专属QQ群，助教答疑，技术氛围浓厚 在慕课网，有专属的QQ群，在群里面的大家可以相互学习。Q群存在的一个最大的意义就在于它提供了一个陪伴式的学习环境，而最重要的是大家可以向我提问，我会尽自己最大的努力去帮助大家，分享知识 + 资料给大家。 在学习这门技术的时候，如果有一个比较有经验的“老司机”来带你，将会变得非常的高效，知识点也会串联起来形成一个完整的体系。后面你在遇到新的问题的时候呢，就会有一个应对的方法。 慕课问答区、在线测验、讨论 + 作业 图文资料：Q群、博客、慕课在线文档 项目Git代码仓库：按章节进行提交，第一块都有具体的代码"}],"posts":[{"title":"nestjs搭建通用业务框架（4）：数据库+配置","slug":"nestjs-example-project-4","date":"2021-03-13T03:02:33.000Z","updated":"2021-03-14T12:27:22.797Z","comments":true,"path":"nestjs-example-project-4/","link":"","permalink":"https://www.toimc.com/nestjs-example-project-4/","excerpt":"这是《nestjs搭建通用业务框架》系列的第4篇，进入开发具体的功能之前，学习nest框架本身提供的CLI工具与规划合理的工程目录，对于要实现的内容进行架构与计划，这是实现健壮高可用的框架的前提。","text":"这是《nestjs搭建通用业务框架》系列的第4篇，进入开发具体的功能之前，学习nest框架本身提供的CLI工具与规划合理的工程目录，对于要实现的内容进行架构与计划，这是实现健壮高可用的框架的前提。 前言大多数前端同学拿到一个新的任务的时候，或者要做一个新的技术设计的时候，往往无从下手。知乎、掘金上问人可能是一种方案，还可以找一个社交渠道(推特、电报、微博、朋友圈、学校论坛)，通过别人的现实例子来进行架构的设计是一个很好切入点。其实，大家可能忽视了以下的渠道：技术框架的官方+示例、公司&amp;团队的历史项目库、找比较厉害的同事取经和发有偿技术咨询的单（程序员各种接单平台）等。 那么，对于nestjs，它的官方提供了很多现成的技术解决方案，所以我们可以借鉴(拿来即用)。 认识CLI先从官方的CLI开始： Nest CLI是一个命令行界面工具，以帮助您初始化、开发和维护 Nest 应用程序。它以多种方式提供帮助，包括搭建项目、以开发模式为其提供服务，以及为生产分发构建和打包应用程序。它体现了最佳实践的架构模式，以构建良好的应用程序。 大多命令行工具可以使用--help来查看帮助： 1234567891011121314151617181920212223242526272829303132333435363738➜ nest --helpUsage: nest &lt;command&gt; [options]Options: -v, --version Output the current version. -h, --help Output usage information.Commands: new|n [options] [name] Generate Nest application. build [options] [app] Build Nest application. start [options] [app] Run Nest application. info|i Display Nest project details. update|u [options] Update Nest dependencies. add [options] &lt;library&gt; Adds support for an external library to your project. generate|g [options] &lt;schematic&gt; [name] [path] Generate a Nest element. Available schematics: ┌───────────────┬─────────────┬──────────────────────────────────────────────┐ │ name │ alias │ description │ │ application │ application │ Generate a new application workspace │ │ class │ cl │ Generate a new class │ │ configuration │ config │ Generate a CLI configuration file │ │ controller │ co │ Generate a controller declaration │ │ decorator │ d │ Generate a custom decorator │ │ filter │ f │ Generate a filter declaration │ │ gateway │ ga │ Generate a gateway declaration │ │ guard │ gu │ Generate a guard declaration │ │ interceptor │ in │ Generate an interceptor declaration │ │ interface │ interface │ Generate an interface │ │ middleware │ mi │ Generate a middleware declaration │ │ module │ mo │ Generate a module declaration │ │ pipe │ pi │ Generate a pipe declaration │ │ provider │ pr │ Generate a provider declaration │ │ resolver │ r │ Generate a GraphQL resolver declaration │ │ service │ s │ Generate a service declaration │ │ library │ lib │ Generate a new library within a monorepo │ │ sub-app │ app │ Generate a new application within a monorepo │ │ resource │ res │ Generate a new CRUD resource │ └───────────────┴─────────────┴──────────────────────────────────────────────┘ 然后，如果想知道其中某一个子命令的用法，可以使用nest &lt;command&gt; --help的形式来进行查看： 12# 例如：➜ nest generate --help 特别说明： 名称 缩写 描述 application application 生成一个新的应用工作区 class cl 生成一个新的class configuration config 生成 CLI 配置文件 controller co 生成一个控制器声明 decorator d 生成一个自定义的装饰者 filter f 生成一个过滤器声明 gateway ga 生成网关 guard gu 生成守卫 interceptor in 生成拦截器 interface interface 生成接口声明 middleware mi 生成中间件声明 module mo 生成一个模块声明 pipe pi 生成管道声明 provider pr 生成提供者声明 resolver r 生成GraphQL resolver声明 service s 生成服务 library lib 生成一个monorepo库 sub-app App 生成一个monorepo的应用 resource Res 生成一个新的CURD资源 我们最开始使用了一个new命令，后面最常用的即是generator或g（简写）命令，可以对照着上表进行熟悉。 合理的工程目录为了去理解Python的语言设计之美，其实更要理解这样的一句话“约定大于配置”，好的工程化目录（约定）能够很好的提升项目的可维护性。 作者推荐在官方的issues中，我们可以找到一些提示：Best scalable project structure #2249 这里有作者的回复。 12345678910111213- src - core - common - middleware - interceptors - guards - user - interceptors (scoped interceptors) - user.controller.ts - user.model.ts - store - store.controller.ts - store.model.ts 可以使用monorepo的方法——在一个repo中创建两个项目，并在它们之间共享共同的东西，如库/包。 没有模块目录，按照功能进行划分。 把通用/核心的东西归为单独的目录：common，比如：拦截器/守卫/管道 参考项目第一个参考项目 技术栈：Nest + sequelize-typescript + JWT + Jest + Swagger 项目地址：kentloog/nestjs-sequelize-typescript 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364.├── README.md├── assets│ └── logo.png├── config│ ├── config.development.ts│ └── config.production.ts├── config.ts├── db│ ├── config.ts│ ├── migrations│ │ └── 20190128160000-create-table-user.js│ └── seeders-dev│ └── 20190129093300-test-data-users.js├── nest-cli.json├── nodemon-debug.json├── nodemon.json├── package-lock.json├── package.json├── src│ ├── app.module.ts│ ├── database│ │ ├── database.module.ts│ │ └── database.providers.ts│ ├── main.ts│ ├── posts│ │ ├── dto│ │ │ ├── create-post.dto.ts│ │ │ ├── post.dto.ts│ │ │ └── update-post.dto.ts│ │ ├── post.entity.ts│ │ ├── posts.controller.ts│ │ ├── posts.module.ts│ │ ├── posts.providers.ts│ │ └── posts.service.ts│ ├── shared│ │ ├── config│ │ │ └── config.service.ts│ │ ├── enum│ │ │ └── gender.ts│ │ └── shared.module.ts│ ├── swagger.ts│ └── users│ ├── auth│ │ ├── jwt-payload.model.ts│ │ └── jwt-strategy.ts│ ├── dto│ │ ├── create-user.dto.ts│ │ ├── update-user.dto.ts│ │ ├── user-login-request.dto.ts│ │ ├── user-login-response.dto.ts│ │ └── user.dto.ts│ ├── user.entity.ts│ ├── users.controller.ts│ ├── users.module.ts│ ├── users.providers.ts│ └── users.service.ts├── test│ ├── app.e2e-spec.ts│ ├── jest-e2e.json│ └── test-data.ts├── tsconfig.build.json├── tsconfig.json└── tslint.json 特点： 项目文档及相关的资源在根目录 数据库及项目配置会放在根目录（细节：数据库升级文件） src中会对功能进行划分建不同的文件夹users、posts 单个功能文件夹中，会包括一个完整CURD的相关文件(dto/controller/module/providers/service) 抽离公共配置到shared文件夹 第二个参考项目 技术栈：具有AWS Lambda，DynamoDB，DynamoDB Streams的完全无服务器生产应用程序 项目地址：International-Slackline-Association/Rankings-Backend 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129.├── LICENSE├── README.md├── docs│ ├── AWS_Architecture.png│ ├── Development\\ Notes.md│ └── GourceOutput.png├── jest.config.js├── package-lock.json├── package.json├── serverless│ ├── environment.yml│ └── secrets.example.yml├── serverless.yml├── src│ ├── api│ │ ├── admin│ │ │ ├── api.module.ts│ │ │ ├── athlete│ │ │ ├── contest│ │ │ ├── database.module.ts│ │ │ ├── index.ts│ │ │ ├── results│ │ │ └── submit│ │ └── webapp│ │ ├── api.module.ts│ │ ├── athlete│ │ ├── contest│ │ ├── country│ │ ├── database.module.ts│ │ ├── index.ts│ │ ├── nestjsTest.controller.ts│ │ └── rankings│ ├── core│ │ ├── athlete│ │ │ ├── athlete.service.ts│ │ │ ├── entity│ │ │ ├── interfaces│ │ │ └── rankings.service.ts│ │ ├── aws│ │ │ ├── aws.module.ts│ │ │ ├── aws.services.interface.ts│ │ │ └── aws.services.ts│ │ ├── category│ │ │ └── categories.service.ts│ │ ├── contest│ │ │ ├── contest.service.ts│ │ │ ├── entity│ │ │ └── points-calculator.service.ts│ │ └── database│ │ ├── database.module.ts│ │ ├── database.service.ts│ │ ├── dynamodb│ │ ├── redis│ │ └── test│ ├── cron-job│ │ ├── cron-job.module.ts│ │ ├── cron-job.service.ts│ │ ├── cron-job.spec.ts│ │ ├── database.module.ts│ │ └── index.ts│ ├── dynamodb-streams│ │ ├── athlete│ │ │ ├── athlete-contest-record.service.ts│ │ │ ├── athlete-details-record.service.ts│ │ │ └── athlete-records.module.ts│ │ ├── contest│ │ │ ├── contest-record.service.ts│ │ │ └── contest-records.module.ts│ │ ├── database.module.ts│ │ ├── dynamodb-streams.module.ts│ │ ├── dynamodb-streams.service.ts│ │ ├── index.ts│ │ ├── test│ │ │ ├── contest-modifications.spec.ts│ │ │ └── lambda-trigger.ts│ │ └── utils.ts│ ├── image-resizer│ │ ├── S3Events.module.ts│ │ ├── S3Events.service.ts│ │ ├── database.module.ts│ │ ├── index.ts│ │ ├── test│ │ │ ├── lambda-trigger.ts│ │ │ └── s3-image-put.spec.ts│ │ └── thumbnail-creator│ │ ├── imagemagick.ts│ │ ├── s3.service.ts│ │ ├── thumbnail-creator.module.ts│ │ └── thumbnail-creator.service.ts│ └── shared│ ├── constants.ts│ ├── decorators│ │ └── roles.decorator.ts│ ├── enums│ │ ├── contestType-utility.ts│ │ ├── discipline-utility.ts│ │ ├── enums-utility.ts│ │ └── index.ts│ ├── env_variables.ts│ ├── exceptions│ │ ├── api.error.ts│ │ └── api.exceptions.ts│ ├── extensions.ts│ ├── filters│ │ └── exception.filter.ts│ ├── generators│ │ └── id.generator.ts│ ├── guards│ │ └── roles.guard.ts│ ├── index.ts│ ├── logger.ts│ ├── pipes│ │ └── JoiValidation.pipe.ts│ ├── types│ │ ├── express.d.ts│ │ ├── extensions.d.ts│ │ └── shared.d.ts│ └── utils.ts├── test│ ├── jest-e2e.json│ └── test-setup.ts├── tsconfig.json├── tslint.json└── webpack ├── webpack.config.Dev.js ├── webpack.config.Prod.js ├── webpack.config.Test.js └── webpack.config.base.js 特点： 根目录中存放webpack、微服务配置 + 项目文档 src中会对功能进行划分建不同的文件夹： api、core、dynamodb-stream、image-resizer 在核心模块中，按照功能模块进划分，与之相关的entity、service放置在同一文件夹中 抽离公共配置到shared文件夹：常量、自定义的装饰器、统一错误处理、过滤器、生成器、守卫、日志服务 第三个参考项目： 技术栈：使用 NestJS 的 Blog/CMS， RESTful API 服务端应用 项目地址：surmon-china/nodepressTemplate 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140.├── API_DOC.md├── CHANGELOG.md├── LICENSE├── README.md├── classified├── cspell.json├── dbbackup├── logo.png├── logo.psd├── nest-cli.json├── package.json├── scripts│ ├── README.md│ ├── dbbackup.sh│ ├── dbrecover.sh│ └── deploy.sh├── src│ ├── app.config.ts│ ├── app.controller.spec.ts│ ├── app.controller.ts│ ├── app.environment.ts│ ├── app.module.ts│ ├── constants│ │ ├── cache.constant.ts│ │ ├── meta.constant.ts│ │ ├── system.constant.ts│ │ └── text.constant.ts│ ├── decorators│ │ ├── cache.decorator.ts│ │ ├── http.decorator.ts│ │ └── query-params.decorator.ts│ ├── errors│ │ ├── bad-request.error.ts│ │ ├── custom.error.ts│ │ ├── forbidden.error.ts│ │ ├── unauthorized.error.ts│ │ └── validation.error.ts│ ├── filters│ │ └── error.filter.ts│ ├── guards│ │ ├── auth.guard.ts│ │ └── humanized-auth.guard.ts│ ├── interceptors│ │ ├── cache.interceptor.ts│ │ ├── error.interceptor.ts│ │ ├── logging.interceptor.ts│ │ └── transform.interceptor.ts│ ├── interfaces│ │ ├── http.interface.ts│ │ ├── mongoose.interface.ts│ │ └── state.interface.ts│ ├── main.ts│ ├── middlewares│ │ ├── cors.middleware.ts│ │ └── origin.middleware.ts│ ├── models│ │ └── extend.model.ts│ ├── modules│ │ ├── announcement│ │ │ ├── announcement.controller.ts│ │ │ ├── announcement.model.ts│ │ │ ├── announcement.module.ts│ │ │ └── announcement.service.ts│ │ ├── article│ │ │ ├── article.controller.ts│ │ │ ├── article.model.ts│ │ │ ├── article.module.ts│ │ │ └── article.service.ts│ │ ├── auth│ │ │ ├── auth.controller.ts│ │ │ ├── auth.interface.ts│ │ │ ├── auth.model.ts│ │ │ ├── auth.module.ts│ │ │ ├── auth.service.ts│ │ │ └── jwt.strategy.ts│ │ ├── category│ │ │ ├── category.controller.ts│ │ │ ├── category.model.ts│ │ │ ├── category.module.ts│ │ │ └── category.service.ts│ │ ├── comment│ │ │ ├── comment.controller.ts│ │ │ ├── comment.model.ts│ │ │ ├── comment.module.ts│ │ │ └── comment.service.ts│ │ ├── expansion│ │ │ ├── expansion.controller.ts│ │ │ ├── expansion.module.ts│ │ │ ├── expansion.service.dbbackup.ts│ │ │ └── expansion.service.statistic.ts│ │ ├── like│ │ │ ├── like.controller.ts│ │ │ ├── like.module.ts│ │ │ └── like.service.ts│ │ ├── option│ │ │ ├── option.controller.ts│ │ │ ├── option.model.ts│ │ │ ├── option.module.ts│ │ │ └── option.service.ts│ │ ├── syndication│ │ │ ├── syndication.controller.ts│ │ │ ├── syndication.module.ts│ │ │ └── syndication.service.ts│ │ └── tag│ │ ├── tag.controller.ts│ │ ├── tag.model.ts│ │ ├── tag.module.ts│ │ └── tag.service.ts│ ├── pipes│ │ └── validation.pipe.ts│ ├── processors│ │ ├── cache│ │ │ ├── cache.config.service.ts│ │ │ ├── cache.module.ts│ │ │ └── cache.service.ts│ │ ├── database│ │ │ ├── database.module.ts│ │ │ └── database.provider.ts│ │ └── helper│ │ ├── helper.module.ts│ │ ├── helper.service.akismet.ts│ │ ├── helper.service.cs.ts│ │ ├── helper.service.email.ts│ │ ├── helper.service.google.ts│ │ ├── helper.service.ip.ts│ │ └── helper.service.seo.ts│ └── transformers│ ├── codec.transformer.ts│ ├── error.transformer.ts│ ├── model.transformer.ts│ ├── mongoose.transformer.ts│ └── urlmap.transformer.ts├── test│ ├── app.e2e-spec.ts│ └── jest-e2e.json├── tsconfig.build.json├── tsconfig.json├── tsconfig.spec.json└── yarn.lock 特点： 项目文档及相关的资源在根目录 src中modules会对功能进行划分建不同的文件夹 单个功能文件夹中，会包括一个完整CURD的相关文件(model/controller/module/service) 把公共的代码（按照nestjs逻辑分层）拆成单独的文件夹guards、filters、decorators、interceptors、interfaces、errors 最佳实践项目：CatsMiaow/node-nestjs-structure 下面的项目结构： 12345678910111213141516171819202122232425+-- bin // Custom tasks+-- dist // Source build+-- public // Static Files+-- src| +-- config // Environment Configuration| +-- entity // TypeORM Entities generated by `typeorm-model-generator` module| +-- auth // Authentication| +-- common // Global Nest Module| | +-- constants // Constant value and Enum| | +-- controllers // Nest Controllers| | +-- decorators // Nest Decorators| | +-- dto // DTO (Data Transfer Object) Schema, Validation| | +-- filters // Nest Filters| | +-- guards // Nest Guards| | +-- interceptors // Nest Interceptors| | +-- interfaces // TypeScript Interfaces| | +-- middleware // Nest Middleware| | +-- pipes // Nest Pipes| | +-- providers // Nest Providers| | +-- * // models, repositories, services...| +-- shared // Shared Nest Modules| +-- gql // GraphQL Structure Sample| +-- * // Other Nest Modules, non-global, same as common structure above+-- test // Jest testing+-- typings // Modules and global type definitions 如果是功能模块： 12345678910// Module structure// Add folders according to module scale. If it&#x27;s small, you don&#x27;t need to add folders.+-- src/greeter| +-- * // folders| +-- greeter.constant.ts| +-- greeter.controller.ts| +-- greeter.service.ts| +-- greeter.module.ts| +-- greeter.*.ts| +-- index.ts 特点： 项目文档及相关的资源在根目录，包括typings、test、bin src中会对功能进行划分建不同的文件夹 抽离公共代码到common文件夹，配置文件放在config文件夹，实体类放置在entity中 鉴权相关的逻辑放在auth 把同类的guards、filters、decorators、interceptors、interfaces、errors存放在common文件夹中 代码规范(风格指南)我们对Angular风格指南进行了摘抄，如下： 参考：Angular风格指南 总则坚持每个文件只定义一样东西（例如服务或组件） 考虑把文件大小限制在 400 行代码以内 坚持定义简单函数 考虑限制在 75 行之内 命名坚持所有符号使用一致的命名规则 坚持遵循同一个模式来描述符号的特性和类型 使用点和横杠来分隔文件名坚持 在描述性名字中，用横杠来分隔单词。 坚持使用点来分隔描述性名字和类型。 坚持遵循先描述组件特性，再描述它的类型的模式，对所有组件使用一致的类型命名规则。推荐的模式为 feature.type.ts。 坚持使用惯用的后缀来描述类型，包括 *.service、*.component、*.pipe、.module、.directive。 必要时可以创建更多类型名，但必须注意，不要创建太多。 符号名与文件名坚持为所有东西使用一致的命名约定，以它们所代表的东西命名。 坚持使用大写驼峰命名法来命名类 坚持匹配符号名与它所在的文件名 坚持在符号名后面追加约定的类型后缀（例如 Component、Directive、Module、Pipe、Service）。 坚持在文件名后面追加约定的类型后缀（例如 .component.ts、.directive.ts、.module.ts、.pipe.ts、.service.ts） 坚持使用中线命名法（dashed-case）或叫烤串命名法（kebab-case）来命名组件的元素选择器。 服务名&amp;管道名坚持使用一致的规则命名服务，以它们的特性来命名 坚持为服务的类名加上 Service 后缀。 例如，获取数据或英雄列表的服务应该命名为 DataService 或 HeroService 坚持为所有管道使用一致的命名约定，用它们的特性来命名。 管道类名应该使用 UpperCamelCase（类名的通用约定），而相应的 name 字符串应该使用 lowerCamelCase。 name 字符串中不应该使用中线（“中线格式”或“烤串格式”）。例如： ellipsis.pipe.ts 12@Pipe(&#123; name: &#x27;ellipsis&#x27; &#125;)export class EllipsisPipe implements PipeTransform &#123; &#125; 和 init-caps.pipe.ts 12@Pipe(&#123; name: &#x27;initCaps&#x27; &#125;)export class InitCapsPipe implements PipeTransform &#123; &#125; 坚持在模块中只包含模块间的依赖关系，所有其它逻辑都应该放到服务中 坚持把可复用的逻辑放到服务中，保持组件简单，聚焦于它们预期目的 坚持在同一个注入器内，把服务当做单例使用，用它们来共享数据和功能 坚持创建封装在上下文中的单一职责的服务 坚持当服务成长到超出单一用途时，创建一个新服务 坚持把数据操作和与数据交互的逻辑重构到服务里。 引导坚持把应用的引导程序和平台相关的逻辑放到名为 main.ts 的文件里 坚持在引导逻辑中包含错误处理代码 避免把应用逻辑放在 main.ts 中，而应放在组件或服务里 测试文件名单元测试： 坚持测试规格文件名与被测试组件文件名相同 坚持测试规格文件名添加 .spec 后缀 端到端的测试： 坚持端到端测试规格文件和它们所测试的特性同名，添加 .e2e-spec 后缀，或者放在特定的文件夹中。 其他原则 定位： 坚持直观、简单和快速地定位代码。 识别： 坚持命名文件到这个程度：看到名字立刻知道它包含了什么，代表了什么。 坚持文件名要具有说明性，确保文件中只包含一个组件。 避免创建包含多个组件、服务或者混合体的文件。 扁平 坚持尽可能保持扁平的目录结构。 考虑当同一目录下达到 7 个或更多个文件时创建子目录。 考虑配置 IDE，以隐藏无关的文件，例如生成出来的 .js 文件和 .js.map 文件等。 T-DRY 坚持 DRY（Don’t Repeat Yourself，不重复自己）。 避免过度 DRY，以致牺牲了阅读性 代码结构 坚持从零开始，但要考虑应用程序接下来的路往哪儿走 坚持有一个近期实施方案和一个长期的愿景 坚持把所有源代码都放到名为 src 的目录里 坚持如果组件具有多个伴生文件 (.ts、.html、.css 和 .spec)，就为它创建一个文件夹 ESLint 坚持使用VSCode等IDE、配合ESLint + Prettier等工具来整理代码格式、检查代码风格问题。 技术整合会从三个层次进行介绍： 数据库 -&gt; 配置(多环境) -&gt; 配置验证 -&gt; 系统日志（本篇） 跨域 -&gt; 错误拦截器 -&gt; 缓存Redis 数据校验 -&gt; 日志拦截 -&gt; 鉴权 数据库ORM工具库通过数据库集成库或 ORM ，例如 Sequelize (recipe)和 TypeORM ，以在更高的抽象级别上进行操作。 \u0011ORM：对象关系映射（英语：Object Relational Mapping）是一种程序设计技术，用于实现面向对象编程语言里不同类型系统的数据之间的转换。 从效果上说，它其实是创建了一个可在编程语言里使用的“虚拟对象数据库”。 应用场景： SQL -&gt; DB：我们写一套配置，针对不同的数据库，都可以方便的接入 DB -&gt; SQL：针对不同的数据库，都可以通过抽象层进行联接 Nest 还提供了与现成的 TypeORM 与 @nestjs/typeorm 的紧密集成，我们将在本章中对此进行介绍，而与 @nestjs/mongoose 的紧密集成将在官方的这一章中介绍 目前主要的ORM工具库与特点： typeorm：跨库查询，事务、TS支持，支持数据库：MySQL, MariaDB, Postgres, CockroachDB, SQLite, MSSQL, Oracle, SAPHana, sql.js, MongoDB objection： TS、事务、饥饿加载、数据效验，基于knexjs，支持数据库：Postgres**, MSSQL, MySQL, MariaDB, SQLite3, **Oracle, Amazon Redshift sequelize： 有非官方的中文文档，目前缺少核心的维护与开发。支持：PostgreSQL, MySQL, MariaDB, SQLite, MSSQL prisma：后起之秀(官方文档写的很不错)，SQL自动合并，对接GraphQL，客户端、服务端+数据管理GUI，支持：PostgreSQL, MSSQL, MySQL, SQLite 通过上面的简单对比，目前来看TypeORM是nest官方支持且推荐的，可以来这里看看它的特性。 使用docker-compose创建progres数据库1234567891011121314151617181920212223242526272829303132333435363738394041version: &#x27;3.5&#x27;services: postgres: container_name: postgres_container image: postgres environment: POSTGRES_USER: $&#123;POSTGRES_USER:-postgres&#125; POSTGRES_PASSWORD: $&#123;POSTGRES_PASSWORD:-changeme&#125; PGDATA: /data/postgres volumes: - postgres:/data/postgres ports: - &quot;5432:5432&quot; networks: - postgres restart: unless-stopped pgadmin: container_name: pgadmin_container image: dpage/pgadmin4 environment: PGADMIN_DEFAULT_EMAIL: $&#123;PGADMIN_DEFAULT_EMAIL:-pgadmin4@pgadmin.org&#125; PGADMIN_DEFAULT_PASSWORD: $&#123;PGADMIN_DEFAULT_PASSWORD:-admin&#125; PGADMIN_CONFIG_SERVER_MODE: &#x27;False&#x27; volumes: - pgadmin:/root/.pgadmin ports: - &quot;$&#123;PGADMIN_PORT:-5050&#125;:80&quot; networks: - postgres restart: unless-stoppednetworks: postgres: driver: bridgevolumes: postgres: pgadmin: 访问postgreslocalhost:5432用户名: postgres (默认)密码：changeme（默认） 进入PgAdmin网址：http://localhost:5050用户名: &#112;&#x67;&#x61;&#100;&#x6d;&#x69;&#x6e;&#x34;&#x40;&#112;&#x67;&#97;&#100;&#109;&#105;&#110;&#46;&#111;&#114;&#103; (默认)密码：admin（默认) 集成TypeORM和Postgre数据库步骤： 安装@nestjs/typeorm，typeorm 安装nodejs侧的数据库驱动程序，如mysql，pg 新建数据库配置文件，配置数据库 在app.module.ts引入数据库的配置文件，调用TypeOrmModule.forRoot方法 启动程序，进行测试 安装依赖（跳过数据库安装过程）： 1npm install --save @nestjs/typeorm typeorm pg 按照上面的步骤，创建文件src/config/database.config.ts： 数据库配置信息： 12345678910111213import &#123; TypeOrmModuleOptions &#125; from &#x27;@nestjs/typeorm&#x27;export const typeOrmConfig: TypeOrmModuleOptions = &#123; type: &#x27;postgres&#x27;, host: &#x27;localhost&#x27;, port: 5432, username: &#x27;postgres&#x27;, password: &#x27;changeme&#x27;, database: &#x27;demo-db&#x27;, entities: [`$&#123;__dirname&#125;/../entity/**/*.&#123;js,ts&#125;`], synchronize: false, logging: [&quot;error&quot;],&#125; 在src/app.module.ts中添加TypeOrm配置： 123456789101112import &#123; Module &#125; from &#x27;@nestjs/common&#x27;;import &#123; TypeOrmModule &#125; from &#x27;@nestjs/typeorm&#x27;;import &#123; typeOrmConfig &#125; from &#x27;./config/typeorm.config&#x27;;@Module(&#123; imports: [ TypeOrmModule.forRoot(typeOrmConfig) ], providers: [],&#125;)export class AppModule &#123;&#125; 然后就可以使用npm run start:dev来进行调试了。 配置应用程序通常在不同的环境中运行，根据环境（Development，Production）的不同，应该使用不同的配置设置。 两种方法： 使用@nestjs/config来实现对.env的key=value对进行解析 使用config库解析yaml格式的文件 官方@nestjs/config最简单的用法：1npm i --save @nestjs/config 配置src/app.module.ts： 12345678910111213import &#123; Module &#125; from &#x27;@nestjs/common&#x27;;import &#123; AppController &#125; from &#x27;./app.controller&#x27;;import &#123; AppService &#125; from &#x27;./app.service&#x27;;import &#123; ConfigModule &#125; from &#x27;@nestjs/config&#x27;;@Module(&#123; imports: [ ConfigModule.forRoot(), ], controllers: [AppController], providers: [AppService],&#125;)export class AppModule &#123;&#125; 然后创建：.env文件： 12DATABASE_USER=testDATABASE_PASSWORD=test123 下面来使用src/app.controller.ts中使用： 123456789101112131415161718import &#123; Controller, Get &#125; from &#x27;@nestjs/common&#x27;;import &#123; ConfigService &#125; from &#x27;@nestjs/config&#x27;;import &#123; AppService &#125; from &#x27;./app.service&#x27;;@Controller()export class AppController &#123; constructor( private readonly appService: AppService, private configService: ConfigService, ) &#123;&#125; @Get() getHello(): string &#123; const dbUser = this.configService.get&lt;string&gt;(&#x27;DATABASE_USER&#x27;); console.log(dbUser); // 这里来测试 return this.appService.getHello(); &#125;&#125; 如果访问localhost:3000即可以看到： 12345678[Nest] 14039 - 2021/03/13 下午9:43:54 [NestFactory] Starting Nest application...[Nest] 14039 - 2021/03/13 下午9:43:54 [InstanceLoader] ConfigHostModule dependencies initialized +95ms[Nest] 14039 - 2021/03/13 下午9:43:54 [InstanceLoader] ConfigModule dependencies initialized +0ms[Nest] 14039 - 2021/03/13 下午9:43:54 [InstanceLoader] AppModule dependencies initialized +1ms[Nest] 14039 - 2021/03/13 下午9:43:54 [RoutesResolver] AppController &#123;&#125;: +7ms[Nest] 14039 - 2021/03/13 下午9:43:54 [RouterExplorer] Mapped &#123;, GET&#125; route +3ms[Nest] 14039 - 2021/03/13 下午9:43:54 [NestApplication] Nest application successfully started +2mstest 进阶玩法 从这里点进去，我们发现ConfigModuleOptions： 1234567891011121314import &#123; ConfigFactory &#125; from &#x27;./config-factory.interface&#x27;;export interface ConfigModuleOptions &#123; cache?: boolean; isGlobal?: boolean; ignoreEnvFile?: boolean; ignoreEnvVars?: boolean; envFilePath?: string | string[]; encoding?: string; validate?: (config: Record&lt;string, any&gt;) =&gt; Record&lt;string, any&gt;; validationSchema?: any; validationOptions?: Record&lt;string, any&gt;; load?: Array&lt;ConfigFactory&gt;; expandVariables?: boolean;&#125; 所支持的参数。 我们可以利用envFilePath配合NODE_ENV来，在不同的启动命令的时候使用不同的配置。 1npm i cross-env 然后添加两个文件：.env.development与.env.production，比如.env.production： 12DATABASE_USER=test1DATABASE_PASSWORD=test123321 下面修改scripts： 1&quot;start:prod&quot;: &quot;cross-env NODE_ENV=production node dist/main&quot;, 可以设置app.module.ts中默认是development： 123456789101112131415161718import &#123; Module &#125; from &#x27;@nestjs/common&#x27;;import &#123; AppController &#125; from &#x27;./app.controller&#x27;;import &#123; AppService &#125; from &#x27;./app.service&#x27;;import &#123; ConfigModule &#125; from &#x27;@nestjs/config&#x27;;const envPath = `.env.$&#123;process.env.NODE_ENV || &#x27;development&#x27;&#125;`;console.log(&#x27;🚀 ~ file: app.module.ts ~ line 7 ~ envPath&#x27;, envPath);@Module(&#123; imports: [ ConfigModule.forRoot(&#123; envFilePath: envPath, &#125;), ], controllers: [AppController], providers: [AppService],&#125;)export class AppModule &#123;&#125; 同样，大家可以启动了测试一下。 1234567891011121314➜ npm run start:prod&gt; nestjs-common-template@0.0.1 start:prod /Users/macos/Projects/nestjs/nestjs-common-template&gt; cross-env NODE_ENV=production node dist/main🚀 ~ file: app.module.ts ~ line 7 ~ envPath .env.production[Nest] 14977 - 2021/03/13 下午11:10:13 [NestFactory] Starting Nest application...[Nest] 14977 - 2021/03/13 下午11:10:13 [InstanceLoader] ConfigHostModule dependencies initialized +34ms[Nest] 14977 - 2021/03/13 下午11:10:13 [InstanceLoader] ConfigModule dependencies initialized +1ms[Nest] 14977 - 2021/03/13 下午11:10:13 [InstanceLoader] AppModule dependencies initialized +1ms[Nest] 14977 - 2021/03/13 下午11:10:13 [RoutesResolver] AppController &#123;&#125;: +6ms[Nest] 14977 - 2021/03/13 下午11:10:13 [RouterExplorer] Mapped &#123;, GET&#125; route +3ms[Nest] 14977 - 2021/03/13 下午11:10:13 [NestApplication] Nest application successfully started +3mstest1 上面打印的test1正是我们设置在.env.production中的内容。 解析yaml格式的配置步骤： 下载js-yaml与@types/js-yaml 12npm i js-yamlnpm i -D @types/js-yaml 创建配置：config.yml 123456789101112http: host: &#x27;localhost&#x27; port: 8080db: postgres: url: &#x27;localhost&#x27; port: 5432 database: &#x27;yaml-db&#x27; sqlite: database: &#x27;sqlite.db&#x27; 配置自定义文件configuration.ts 1234567891011import &#123; readFileSync &#125; from &#x27;fs&#x27;;import * as yaml from &#x27;js-yaml&#x27;;import &#123; join &#125; from &#x27;path&#x27;;const YAML_CONFIG_FILENAME = &#x27;config.yml&#x27;;const filePath = join(__dirname, YAML_CONFIG_FILENAME);export default () =&gt; &#123; return yaml.load(readFileSync(filePath, &#x27;utf8&#x27;));&#125;; 调用forRoot中的load方法 12345678910111213141516import &#123; Module &#125; from &#x27;@nestjs/common&#x27;;import &#123; AppController &#125; from &#x27;./app.controller&#x27;;import &#123; AppService &#125; from &#x27;./app.service&#x27;;import &#123; ConfigModule &#125; from &#x27;@nestjs/config&#x27;;import Configuration from &#x27;./config/configuration&#x27;; // 这里调整@Module(&#123; imports: [ ConfigModule.forRoot(&#123; load: [Configuration], // load方法 &#125;), ], controllers: [AppController], providers: [AppService],&#125;)export class AppModule &#123;&#125; 修改app.controller.ts中的代码： 12345678910111213141516171819import &#123; Controller, Get &#125; from &#x27;@nestjs/common&#x27;;import &#123; ConfigService &#125; from &#x27;@nestjs/config&#x27;;import &#123; AppService &#125; from &#x27;./app.service&#x27;;import &#123; DatabaseConfig &#125; from &#x27;./interface&#x27;;@Controller()export class AppController &#123; constructor( private readonly appService: AppService, private configService: ConfigService, ) &#123;&#125; @Get() getHello(): string &#123; const db = this.configService.get&lt;DatabaseConfig&gt;(&#x27;db&#x27;); console.log(db); return this.appService.getHello(); &#125;&#125; 定义src/interface.ts： 1234567891011121314export interface DatabaseConfig &#123; postgres: PostgresConfig; sqlite: SqliteConfig;&#125;export interface PostgresConfig &#123; url: string; port: number; database: string;&#125;export interface SqliteConfig &#123; database: string;&#125; 最后测试： 1234567891011[Nest] 16960 - 2021/03/13 下午11:34:00 [NestFactory] Starting Nest application...[Nest] 16960 - 2021/03/13 下午11:34:00 [InstanceLoader] ConfigHostModule dependencies initialized +30ms[Nest] 16960 - 2021/03/13 下午11:34:00 [InstanceLoader] ConfigModule dependencies initialized +0ms[Nest] 16960 - 2021/03/13 下午11:34:00 [InstanceLoader] AppModule dependencies initialized +0ms[Nest] 16960 - 2021/03/13 下午11:34:00 [RoutesResolver] AppController &#123;&#125;: +4ms[Nest] 16960 - 2021/03/13 下午11:34:00 [RouterExplorer] Mapped &#123;, GET&#125; route +3ms[Nest] 16960 - 2021/03/13 下午11:34:00 [NestApplication] Nest application successfully started +1ms&#123; postgres: &#123; url: &#x27;localhost&#x27;, port: 5432, database: &#x27;yaml-db&#x27; &#125;, sqlite: &#123; database: &#x27;sqlite.db&#x27; &#125;&#125; 写到这里，应该够用了，代码可以查看本次提交。 使用config库解析步骤： 安装第三方包config 12npm i config -Snpm i cross-env -D 新建 配置文件config/default.json，同样还可以建立development.json, production.json 12345&#123; &quot;server&quot;: &#123; &quot;happy&quot;: &quot;my default value&quot; &#125;&#125; development.json: 12345678&#123; &quot;server&quot;: &#123; &quot;port&quot;: 3001, &quot;host&quot;: &quot;localhost&quot;, &quot;username&quot;: &quot;test&quot;, &quot;password&quot;: &quot;test&quot; &#125;&#125; production.json: 12345678&#123; &quot;server&quot;: &#123; &quot;port&quot;: 3002, &quot;host&quot;: &quot;localhost&quot;, &quot;username&quot;: &quot;prod&quot;, &quot;password&quot;: &quot;prod&quot; &#125;&#125; 在app.controller.ts中使用： 123456789101112131415import &#123; Controller, Get &#125; from &#x27;@nestjs/common&#x27;;import &#123; AppService &#125; from &#x27;./app.service&#x27;;import * as config from &#x27;config&#x27;;@Controller()export class AppController &#123; constructor(private readonly appService: AppService) &#123;&#125; @Get() getHello(): string &#123; const server = config.get(&#x27;server&#x27;); console.log(server); return this.appService.getHello(); &#125;&#125; 配置脚本： 12&quot;start:dev&quot;: &quot;cross-env NODE_ENV=development nest start --watch&quot;,&quot;start:prod&quot;: &quot;cross-env NODE_ENV=production node dist/main&quot;, 运行结果： 1234567891011121314151617181920212223242526272829303132➜ npm run start:dev[Nest] 34580 - 2021/03/14 上午12:50:42 [NestFactory] Starting Nest application...[Nest] 34580 - 2021/03/14 上午12:50:42 [InstanceLoader] AppModule dependencies initialized +34ms[Nest] 34580 - 2021/03/14 上午12:50:42 [RoutesResolver] AppController &#123;&#125;: +6ms[Nest] 34580 - 2021/03/14 上午12:50:42 [RouterExplorer] Mapped &#123;, GET&#125; route +3ms[Nest] 34580 - 2021/03/14 上午12:50:42 [NestApplication] Nest application successfully started +2ms&#123; happy: &#x27;my default value&#x27;, port: 3001, host: &#x27;localhost&#x27;, username: &#x27;test&#x27;, password: &#x27;test&#x27;&#125;➜ npm run start:prod&gt; nestjs-common-template@0.0.1 start:prod /Users/macos/Projects/nestjs/nestjs-common-template&gt; cross-env NODE_ENV=production node dist/main[Nest] 34400 - 2021/03/14 上午12:50:03 [NestFactory] Starting Nest application...[Nest] 34400 - 2021/03/14 上午12:50:03 [InstanceLoader] AppModule dependencies initialized +71ms[Nest] 34400 - 2021/03/14 上午12:50:03 [RoutesResolver] AppController &#123;&#125;: +6ms[Nest] 34400 - 2021/03/14 上午12:50:03 [RouterExplorer] Mapped &#123;, GET&#125; route +2ms[Nest] 34400 - 2021/03/14 上午12:50:03 [NestApplication] Nest application successfully started +2ms&#123; happy: &#x27;my default value&#x27;, port: 3002, host: &#x27;localhost&#x27;, username: &#x27;prod&#x27;, password: &#x27;prod&#x27;&#125; 附上：代码地址 配置验证配置验证，主要是指在应用程序启动时，如果没有提供所需的环境变量或不符合某些验证规则，就会抛出一个异常。@nestjs/config包实现了两种不同的方式来实现这一点。 Joi内置验证器。通过Joi，你可以定义一个对象模式，并根据它验证JavaScript对象 一个自定义的validate()函数，它将环境变量作为输入 Joi用法特别说明： 最新版本的joi需要你运行Node v12或更高版本。旧版本的node请安装v16.1.8。这主要是因为在v17.0.2发布后，在构建的时候会出现错误。更多信息请参考其17.0.0发布说明，点击这里。 joi最好配合官方的@nestjs/config进行使用 步骤： 安装依赖 1npm install --save joi 定义验证Schema： 123456789101112131415161718192021222324252627import &#123; Module &#125; from &#x27;@nestjs/common&#x27;;import &#123; AppController &#125; from &#x27;./app.controller&#x27;;import &#123; AppService &#125; from &#x27;./app.service&#x27;;import * as Joi from &#x27;joi&#x27;;import &#123; ConfigModule &#125; from &#x27;@nestjs/config&#x27;;const envPath = `.env.$&#123;process.env.NODE_ENV || &#x27;development&#x27;&#125;`;@Module(&#123; imports: [ ConfigModule.forRoot(&#123; envFilePath: envPath, // 这里多了一个属性：validationSchema validationSchema: Joi.object(&#123; NODE_ENV: Joi.string() .valid(&#x27;development&#x27;, &#x27;production&#x27;, &#x27;test&#x27;, &#x27;provision&#x27;) .default(&#x27;development&#x27;), PORT: Joi.number().default(3000), DATABASE_USER: Joi.string().required() &#125;), &#125;), ], controllers: [AppController], providers: [AppService],&#125;)export class AppModule &#123;&#125; 验证测试 配置错误脚本： 1&quot;start:dev&quot;: &quot;cross-env NODE_ENV=development PORT=toimc nest start --watch&quot;, 配置正确的脚本： 1&quot;start:dev&quot;: &quot;cross-env NODE_ENV=development PORT=3000 nest start --watch&quot;, 测试命令 1npm run start:dev 错误的提示： 1234567891011121314151617[下午7:33:38] Found 0 errors. Watching for file changes./Users/macos/Projects/nestjs/nestjs-common-template/node_modules/_@nestjs_config@0.6.3@@nestjs/config/dist/config.module.js:61 throw new Error(`Config validation error: $&#123;error.message&#125;`); ^Error: Config validation error: &quot;PORT&quot; must be a number at Function.forRoot (/Users/macos/Projects/nestjs/nestjs-common-template/node_modules/_@nestjs_config@0.6.3@@nestjs/config/dist/config.module.js:61:23) at Object.&lt;anonymous&gt; (/Users/macos/Projects/nestjs/nestjs-common-template/dist/app.module.js:21:35) at Module._compile (internal/modules/cjs/loader.js:1063:30) at Object.Module._extensions..js (internal/modules/cjs/loader.js:1092:10) at Module.load (internal/modules/cjs/loader.js:928:32) at Function.Module._load (internal/modules/cjs/loader.js:769:14) at Module.require (internal/modules/cjs/loader.js:952:19) at require (internal/modules/cjs/helpers.js:88:18) at Object.&lt;anonymous&gt; (/Users/macos/Projects/nestjs/nestjs-common-template/dist/main.js:4:22) at Module._compile (internal/modules/cjs/loader.js:1063:30) 或者修改.env.development中的配置信息： 12DATABASE_USER=DATABASE_PASSWORD=test123 错误提示： 123456789101112131415/Users/macos/Projects/nestjs/nestjs-common-template/node_modules/_@nestjs_config@0.6.3@@nestjs/config/dist/config.module.js:61 throw new Error(`Config validation error: $&#123;error.message&#125;`); ^Error: Config validation error: &quot;DATABASE_USER&quot; is not allowed to be empty at Function.forRoot (/Users/macos/Projects/nestjs/nestjs-common-template/node_modules/_@nestjs_config@0.6.3@@nestjs/config/dist/config.module.js:61:23) at Object.&lt;anonymous&gt; (/Users/macos/Projects/nestjs/nestjs-common-template/dist/app.module.js:21:35) at Module._compile (internal/modules/cjs/loader.js:1063:30) at Object.Module._extensions..js (internal/modules/cjs/loader.js:1092:10) at Module.load (internal/modules/cjs/loader.js:928:32) at Function.Module._load (internal/modules/cjs/loader.js:769:14) at Module.require (internal/modules/cjs/loader.js:952:19) at require (internal/modules/cjs/helpers.js:88:18) at Object.&lt;anonymous&gt; (/Users/macos/Projects/nestjs/nestjs-common-template/dist/main.js:4:22) at Module._compile (internal/modules/cjs/loader.js:1063:30) 结论：使用Joi可以很方便对传入应用程序的参数进行验证，可以限制传入的数据类型。 除了上面写的验证以外，还可以加入以下属性来验证输入的命令参数： 123456789101112131415161718192021@Module(&#123; imports: [ ConfigModule.forRoot(&#123; envFilePath: envPath, validationSchema: Joi.object(&#123; NODE_ENV: Joi.string() .valid(&#x27;development&#x27;, &#x27;production&#x27;, &#x27;test&#x27;, &#x27;provision&#x27;) .default(&#x27;development&#x27;), PORT: Joi.number().default(3000), DATABASE_USER: Joi.string().required() &#125;), validationOptions: &#123; // 这里加 allowUnknown: false, abortEarly: true, &#125;, &#125;), ], controllers: [AppController], providers: [AppService],&#125;)export class AppModule &#123;&#125; @nestjs/config包使用的默认设置是： allowUnknown：控制是否允许在环境变量中使用未知键。默认为true abortEarly：如果为true，则在第一个错误时停止验证；如果为false，则返回所有错误。默认值为false。 注意上面的Joi的用法： 主要是校验process.env传入的参数 主要是校验envFilePath初次加载的时候的参数 使用class-validator步骤： 安装依赖class-validator与class-transformer 1npm i class-validator class-transformer 配置效验文件src/env.validation.ts 1234567891011121314151617181920212223242526272829import &#123; plainToClass &#125; from &#x27;class-transformer&#x27;;import &#123; IsEnum, IsNumber, validateSync &#125; from &#x27;class-validator&#x27;;enum Environment &#123; Development = &quot;development&quot;, Production = &quot;production&quot;&#125;class EnvironmentVariables &#123; @IsEnum(Environment) NODE_ENV: Environment; @IsNumber() PORT: number;&#125;export function validate(config: Record&lt;string, unknown&gt;) &#123; const validatedConfig = plainToClass( EnvironmentVariables, config, &#123; enableImplicitConversion: true &#125;, ); const errors = validateSync(validatedConfig, &#123; skipMissingProperties: false &#125;); if (errors.length &gt; 0) &#123; throw new Error(errors.toString()); &#125; return validatedConfig;&#125; 调整app.module.ts文件 12345678910111213141516171819import &#123; Module &#125; from &#x27;@nestjs/common&#x27;;import &#123; AppController &#125; from &#x27;./app.controller&#x27;;import &#123; AppService &#125; from &#x27;./app.service&#x27;;import &#123; ConfigModule &#125; from &#x27;@nestjs/config&#x27;;import &#123; validate &#125; from &#x27;./env.validation&#x27;;const envPath = `.env.$&#123;process.env.NODE_ENV || &#x27;development&#x27;&#125;`;@Module(&#123; imports: [ ConfigModule.forRoot(&#123; envFilePath: envPath, validate, &#125;), ], controllers: [AppController], providers: [AppService],&#125;)export class AppModule &#123;&#125; 与使用Joi验证结果一致。 小结 使用第三方的包config，可以方便的读取配置信息，但是校验却需要在读取的位置来加，对于不需要验证，而需要全局使用的配置项可以使用这种方式； 官方的@nestjs/config可以方便的导入.env的文件，同时结合js-yaml也可以导入yaml格式的配置。 配置灵活，而且可以配合验证工具Joi进行参数的验证（推荐） 自定义的校验第三方包class-validator这里只是冰山一角，后面在学习数据验证的时候还会使用到它；","categories":[{"name":"nestjs搭建通用业务框架","slug":"nestjs搭建通用业务框架","permalink":"https://www.toimc.com/categories/nestjs%E6%90%AD%E5%BB%BA%E9%80%9A%E7%94%A8%E4%B8%9A%E5%8A%A1%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"https://www.toimc.com/tags/node-js/"},{"name":"nestjs","slug":"nestjs","permalink":"https://www.toimc.com/tags/nestjs/"},{"name":"web框架","slug":"web框架","permalink":"https://www.toimc.com/tags/web%E6%A1%86%E6%9E%B6/"}]},{"title":"什么是依赖注入?","slug":"what-is-dependency-injection","date":"2021-03-12T02:39:50.000Z","updated":"2021-03-12T09:48:11.539Z","comments":true,"path":"what-is-dependency-injection/","link":"","permalink":"https://www.toimc.com/what-is-dependency-injection/","excerpt":"本篇是nestjs系列文章的番外篇，主要是介绍控制反转Invention of Control(IoC)和依赖注入Dependecy Injection(DI)，作为nestjs和angular的核心概念，学习它们有利于更好的进行框架的学习。","text":"本篇是nestjs系列文章的番外篇，主要是介绍控制反转Invention of Control(IoC)和依赖注入Dependecy Injection(DI)，作为nestjs和angular的核心概念，学习它们有利于更好的进行框架的学习。 定义控制反转（Inversion of Control）是一种是面向对象编程中的一种设计原则，用来减低计算机代码之间的耦合度。其基本思想是：借助于“第三方”实现具有依赖关系的对象之间的解耦。 依赖注入是一种用于实现IoC的设计模式，它允许在类外创建依赖对象，并通过不同的方式将这些对象提供给类。使用DI，我们将依赖对象的创建和绑定移到依赖它们的类之外。具体的做法，比如：将实例变量传入到一个对象中去(Dependency injection means giving an object its instance variables) 简单来说它和依赖注入间的区别就是： 控制反转是一种设计思想 依赖注入是一种编程技巧 作用先看个例子：我们希望在通知组件(NotificationComponent)中通过消息服务(MessageService)发送一条消息。 如果不使用依赖注入的话，我们的代码大概长这样： 123456789class NotificationComponent &#123; msg: MessageService; constructor() &#123; this.msg = new MessageService(); &#125; sendMsg(msgType: string, info: string) &#123; this.msg.send(msgType, info); &#125;&#125; 使用依赖注入时： 123456class NotificationComponent &#123; constructor(msg: MessageService) &#123;&#125; // Angular 中注入依赖的方式 sendMsg(msgType: string, info: string) &#123; this.msg.send(msgType, info); &#125;&#125; 经过对比，可以看到使用依赖注入有两个很显然的优点： 代码的行数变少了 NotificationComponent 与 MessageService 间的耦合性降低了 结论在控制反转中，”控制“是指对程序流程的控制，”反转“则是将控制权从程序员的手里反转到了外层框架。 控制反转是一种在软件工程中解耦合的思想，调用类只依赖接口，而不依赖具体的实现类，减少了耦合。控制权交给了容器，在运行的时候才由容器决定将具体的实现动态的“注入”到调用类的对象中。 既然控制反转是一种设计思想，那么作为相应实现方式之一的依赖注入（模板模式也是种实现方式）必然也遵循此思想。 依赖注入是一种设计模式，可以作为控制反转的一种实现方式。依赖注入就是将实例变量传入到一个对象中去(Dependency injection means giving an object its instance variables)。 通过IoC框架，类A依赖类B的强耦合关系可以在运行时通过容器建立，也就是说把创建B实例的工作移交给容器，类A只管使用就可以。","categories":[],"tags":[{"name":"Dependecy Injection(DI)","slug":"Dependecy-Injection-DI","permalink":"https://www.toimc.com/tags/Dependecy-Injection-DI/"},{"name":"Invention of Control(IoC)","slug":"Invention-of-Control-IoC","permalink":"https://www.toimc.com/tags/Invention-of-Control-IoC/"},{"name":"依赖注入","slug":"依赖注入","permalink":"https://www.toimc.com/tags/%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/"},{"name":"架构思维","slug":"架构思维","permalink":"https://www.toimc.com/tags/%E6%9E%B6%E6%9E%84%E6%80%9D%E7%BB%B4/"}]},{"title":"nestjs搭建通用业务框架（3）：核心概念","slug":"nestjs-example-project-3","date":"2021-03-11T01:30:45.000Z","updated":"2021-03-12T03:40:36.290Z","comments":true,"path":"nestjs-example-project-3/","link":"","permalink":"https://www.toimc.com/nestjs-example-project-3/","excerpt":"这是《nestjs搭建通用业务框架》系列的第3篇，主要是介绍nestjs中的核心概念，理解这些概念与使用方法是今后学习上的垫脚石。PS: 对于本篇的学习，你需要有一定的TS的基础，理解起来才会比较顺畅。","text":"这是《nestjs搭建通用业务框架》系列的第3篇，主要是介绍nestjs中的核心概念，理解这些概念与使用方法是今后学习上的垫脚石。PS: 对于本篇的学习，你需要有一定的TS的基础，理解起来才会比较顺畅。 本章的内容不是随意的复制、粘贴官方的译本，这样没有任何学习的价值。所有的内容经过个人的整理，也算是知识的输出，大家且学且手下留情。 其中比较重要的内容：装饰器、装饰器 - 依赖注入，在依赖注入部分因为概念比较难理解，所以后面打算单独再写一篇关于依赖注入（设计模式）的博文！欢迎订阅RSS！ 总览概念先不废话，给大家总结了一张基础概念的思维导图： 大家可以把上面的图，当成是平时查阅概念的一个索引，我们把相关的内容进行了连接与分层，方便大家学习。 装饰器这是nestjs（Angular）学习中非常！非常！非常重要的一部分！可以说是nestjs借用ES高级特性的一个灵魂~，我们将会从以下几个概念出发来进行学习。 在下面的学习中，不乏会有一些代码的内容，看不懂没有关系，先读每一部分的前置的介绍，然后TS代码的内容，主要是了解基础的应用与该装饰器的作用即可。 控制器控制器负责处理传入的 请求 和向客户端返回 响应 。 123456789101112131415161718192021222324252627282930import &#123; Controller, Get &#125; from &#x27;@nestjs/common&#x27;;@Controller(&#x27;cats&#x27;) // Controller - 控制器的装饰器， cats - 路由，或者说是请求的一个前缀，类似于 /api/user /api/test ... 中的/apiexport class CatsController &#123; @Get(&#x27;ab*cd&#x27;) // Get - 请求的类型的装饰器 findAll(@Req() request: Request): string &#123; // 具体对应上面请求的响应函数 return &#x27;This action returns all cats&#x27;; &#125; @Post() @HttpCode(204) // http状态码 @Header(&#x27;Cache-Control&#x27;, &#x27;none&#x27;) // 响应头 create() &#123; return &#x27;This action adds a new cat&#x27;; &#125; @Get(&#x27;docs&#x27;) @Redirect(&#x27;https://docs.nestjs.com&#x27;, 302) // 重定向 getDocs(@Query(&#x27;version&#x27;) version) &#123; if (version &amp;&amp; version === &#x27;5&#x27;) &#123; return &#123; url: &#x27;https://docs.nestjs.com/v5/&#x27; &#125;; &#125; &#125; @Get(&#x27;:id&#x27;) // 参数 - 路径传参使用Param，url传参使用Query，post传参使用Body findOne(@Param() params): string &#123; console.log(params.id); return `This action returns a #$&#123;params.id&#125; cat`; &#125;&#125; 使用如下命令： 1nest g controller [file-name] 来创建一个标准的控制器文件。 路由 - @Controller Request - 如下表： 了解Express的同学应该知道，请求对象req与响应对象res： 装饰器 对应的Express中的对象或者用法 @Request() req @Response() @Res()* res @Next() next @Session() req.session @Param(key?: string) req.params / req.params[key] @Body(key?: string) req.body / req.body[key] @Query(key?: string) req.query / req.query[key] @Headers(name?: string) req.headers / req.headers[name] @Ip() req.ip 资源（请求方法）- @Put() 、 @Delete()、 @Patch()、 @Options()、 @Head()和 @All()。这些表示各自的 HTTP请求方法。 路由通配符 - 设置在上面的资源中的正则表达式，字符 ? 、 + 、 * 以及 () 是它们的正则表达式对应项的子集。连字符 (-) 和点 (.) 按字符串路径解析。如：@Get(&#39;ab*cd&#39;)会匹配成abcd， ab_cd，abecd等。 状态码 - @HttpCode() 响应头 - @Header 提供者提供者是nest借用Angular的设计模式引入的一个概念。 Providers 是 Nest 的一个基本概念，许多基本的 Nest 类可能被视为 provider - service, repository, factory, helper 等等，他们都可以通过 constructor 注入依赖关系。 providers就是在代码组织上抽象的一层存放公共代码的部分，在程序内部交由框架来处理依赖关系，通过providers和@Injectable()注解可以自由的使用这些公共的代码中的逻辑。 服务这张图很好的解释了@Injectable()的作用： 解释： 一个ServiceA被加上@Injectable()的注解之后，就变成了一个可以被其他Component在构造器部分引用的参数，在nest的提供者providers:[]中需要添加对应的ServiceA，如：providers: [ ServiceA ]，以便框架自动来处理依赖关系，并进行必要的实例化。 用法： 1nest generate service [service-name] 依赖注入(重要)主要有三类具体的应用： 管道 - 实现数据的转换与验证 守卫 - 实现流程控制，鉴权管理 拦截器 - 绑定函数执行前后的处理函数，如：请求&amp;响应拦截器、错误统一处理、缓存等 这三类全是@Injectable()修饰的，官方在架构上提供的现成的工具类，管道应实现 PipeTransform 接口，守卫应该实现 CanActivate 接口，拦截器应该实现 NestInterceptor 接口。 要理解依赖注入，要先看个例子：我们希望在通知组件(NotificationComponent)中通过消息服务(MessageService)发送一条消息。 如果不使用依赖注入的话，我们的代码大概长这样： 123456789class NotificationComponent &#123; msg: MessageService; constructor() &#123; this.msg = new MessageService(); &#125; sendMsg(msgType: string, info: string) &#123; this.msg.send(msgType, info); &#125;&#125; 使用依赖注入时： 123456class NotificationComponent &#123; constructor(msg: MessageService) &#123;&#125; // Angular 中注入依赖的方式 sendMsg(msgType: string, info: string) &#123; this.msg.send(msgType, info); &#125;&#125; 经过对比，可以看到使用依赖注入有两个很显然的优点： 代码的行数变少了 NotificationComponent 与 MessageService 间的耦合性降低了 大家先可以去了解一下IoC（Inversion of Control）控制反转，简单来说它和依赖注入（Dependency Injection）间的区别就是： 依赖注入是一种编程技巧 控制反转是一种设计思想 依赖注入就是不通过 new 这种方式来在类（NotificationComponent）的内部创建所依赖类（MessageService）的对象，而是在外部创建好需要依赖的类对象之后通过构造函数等方式注入进来就可以了。 在控制反转中，”控制“是指对程序流程的控制，”反转“则是将控制权从程序员的手里反转到了外层框架。 管道(Pipe) 管道有两个作用: 转换：管道将输入数据转换为所需的数据输出 验证：对输入数据进行验证，如果验证成功继续传递; 验证失败则抛出异常; 按照作用分的类型：内置管道、结构验证、类验证、转换管道 守卫(Guard) 守卫有一个单独的责任，它们根据运行时出现的某些条件（例如权限，角色，访问控制列表等）来确定给定的请求是否由路由处理程序处理。 这通常称为授权。 拦截器(Interceptor) 拦截器具有一系列有用的功能，这些功能受面向切面编程（AOP）技术的启发。它们可以： 在函数执行之前/之后绑定额外的逻辑 转换从函数返回的结果 转换从函数抛出的异常 扩展基本函数行为 根据所选条件完全重写函数 (例如, 缓存目的) 模块模块化的概念无处不在，在nest中，模块是应用程序的基础的组成部分，如下图： 具体特点： 模块是具有 @Module() 装饰器的类。 每个 Nest 应用程序至少有一个模块，即根模块。根模块可能是应用程序中唯一的模块，特别是当应用程序很小时，但是对于大型程序来说这是没有意义的。 在大多数情况下，您将拥有多个模块，每个模块都有一组紧密相关的属性，如下表： @module() 装饰器接受一个描述模块属性的对象： 属性名 解释 providers 由 Nest 注入器实例化的提供者，并且可以至少在整个模块中共享 controllers 必须创建的一组控制器 imports 导入模块的列表，这些模块导出了此模块中所需提供者 exports 由本模块提供并应在其他模块中可用的提供者的子集。 中间件中间件是在路由处理程序 之前 调用的函数，实现 NestMiddleware 接口。 Nest 中间件实际上等价于 express 中间件。 下面是Express官方文档中所述的中间件功能： 中间件函数可以执行以下任务: 执行任何代码。 对请求和响应对象进行更改。 结束请求-响应周期。 调用堆栈中的下一个中间件函数。 如果当前的中间件函数没有结束请求-响应周期, 它必须调用 next() 将控制传递给下一个中间件函数。否则, 请求将被挂起。 异常过滤器内置的异常层负责处理整个应用程序中的所有抛出的异常。当捕获到未处理的异常时，最终用户将收到友好的响应。 开箱即用，此操作由内置的全局异常过滤器执行，该过滤器处理类型 HttpException（及其子类）的异常。每个发生的异常都由全局异常过滤器处理, 当这个异常无法被识别时 (既不是 HttpException 也不是继承的类 HttpException ) , 用户将收到以下 JSON 响应: 1234&#123; &quot;statusCode&quot;: 500, &quot;message&quot;: &quot;Internal server error&quot;&#125; 小结通过本篇的介绍，大家应该有如下的感受： nest大量使用了注解来简化逻辑 nest的程序设计（架构）很丰富，解耦&amp;易用。解耦不用说，从上面的分层就能看出来；易用，主要体现在语义化关键词、强大的CLI命令。 核心的概念：模块 -&gt; 控制器 -&gt; 服务、管道、守卫、拦截器 -&gt; 中间件 -&gt; 异常过滤器。 参考资料推荐一些非官方的，用于去理解“依赖注入”的资料： 详解Angular依赖注入：国人写的案例，还比较有意思，解释的比较清楚的了，本篇引用了部分内容 Angular - 服务与依赖注入简介：这个是Angular的官方解读，也有配图，我感觉还是比较容易搞清楚的 Dependency Injection：虽然是英文，但是非常推荐去读一读","categories":[{"name":"nestjs搭建通用业务框架","slug":"nestjs搭建通用业务框架","permalink":"https://www.toimc.com/categories/nestjs%E6%90%AD%E5%BB%BA%E9%80%9A%E7%94%A8%E4%B8%9A%E5%8A%A1%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"https://www.toimc.com/tags/node-js/"},{"name":"nestjs","slug":"nestjs","permalink":"https://www.toimc.com/tags/nestjs/"},{"name":"web框架","slug":"web框架","permalink":"https://www.toimc.com/tags/web%E6%A1%86%E6%9E%B6/"}]},{"title":"nestjs搭建通用业务框架（2）：初体验","slug":"nestjs-example-project-2","date":"2021-03-09T13:14:10.000Z","updated":"2021-03-12T03:40:49.702Z","comments":true,"path":"nestjs-example-project-2/","link":"","permalink":"https://www.toimc.com/nestjs-example-project-2/","excerpt":"今天是《nestjs搭建通用业务框架》系列的第2篇，主要是介绍如何使用nestjs的CLI工具快速初始化项目，了解项目的启动与调试。PS: 调试技巧非常的重要，有利于后续学习框架的核心的原理。","text":"今天是《nestjs搭建通用业务框架》系列的第2篇，主要是介绍如何使用nestjs的CLI工具快速初始化项目，了解项目的启动与调试。PS: 调试技巧非常的重要，有利于后续学习框架的核心的原理。 node环境准备node与npm的版本 12345➜ node -vnv14.15.1~➜ npm -v6.14.8 大家使用node官方的LTS的版本即可，下载地址 安装可以使用nrm或者npm config set registry https://registry.npm.taobao.org/来进行加速 安装CLI12345// 全局安装cli工具➜ npm i -g @nestjs/cli/Users/macos/.nvm/versions/node/v14.15.1/bin/nest -&gt; /Users/macos/.nvm/versions/node/v14.15.1/lib/node_modules/@nestjs/cli/bin/nest.js+ @nestjs/cli@7.5.6added 15 packages from 4 contributors, removed 1080 packages and updated 262 packages in 12.239s 初始化项目nest new [project-name]： 12345678910111213141516171819202122232425262728293031323334353637~/Projects/nestjs➜ nest new nestjs-common-template⚡ We will scaffold your app in a few seconds..CREATE nestjs-common-template/.eslintrc.js (631 bytes)CREATE nestjs-common-template/.prettierrc (51 bytes)CREATE nestjs-common-template/README.md (3339 bytes)CREATE nestjs-common-template/nest-cli.json (64 bytes)CREATE nestjs-common-template/package.json (1984 bytes)CREATE nestjs-common-template/tsconfig.build.json (97 bytes)CREATE nestjs-common-template/tsconfig.json (339 bytes)CREATE nestjs-common-template/src/app.controller.spec.ts (617 bytes)CREATE nestjs-common-template/src/app.controller.ts (274 bytes)CREATE nestjs-common-template/src/app.module.ts (249 bytes)CREATE nestjs-common-template/src/app.service.ts (142 bytes)CREATE nestjs-common-template/src/main.ts (208 bytes)CREATE nestjs-common-template/test/app.e2e-spec.ts (630 bytes)CREATE nestjs-common-template/test/jest-e2e.json (183 bytes)? Which package manager would you ❤️ to use? (Use arrow keys)❯ npm yarn ▹▹▹▹▸ Installation in progress... ☕🚀 Successfully created project nestjs-common-template👉 Get started with the following commands:$ cd nestjs-common-template$ npm run start Thanks for installing Nest 🙏 Please consider donating to our open collective to help us maintain this package. 🍷 Donate: https://opencollective.com/nest 运行项目： 12345678910111213~/Projects/nestjs took 22s 385ms➜ cd nestjs-common-template/nestjs-common-template on  HEAD [?] is 📦 v0.0.1 via ⬢ v14.15.1➜ npm run start&gt; nestjs-common-template@0.0.1 start /Users/macos/Projects/nestjs/nestjs-common-template&gt; nest start[Nest] 5918 - 2021/03/09 下午11:06:10 [NestFactory] Starting Nest application...[Nest] 5918 - 2021/03/09 下午11:06:10 [InstanceLoader] AppModule dependencies initialized +47ms[Nest] 5918 - 2021/03/09 下午11:06:10 [RoutesResolver] AppController &#123;&#125;: +4ms[Nest] 5918 - 2021/03/09 下午11:06:10 [RouterExplorer] Mapped &#123;, GET&#125; route +2ms[Nest] 5918 - 2021/03/09 下午11:06:10 [NestApplication] Nest application successfully started +1ms 下面可以打开浏览器来访问http://localhost:3000可以看到hello world的字样。 1Hello World! 说明我们的项目启动成功了。 项目目录与package.json先来看看项目的工程目录： 123456789101112131415161718192021222324252627282930.├── README.md├── dist // 打包过后，目标代码│ ├── app.controller.d.ts│ ├── app.controller.js│ ├── app.controller.js.map│ ├── app.module.d.ts│ ├── app.module.js│ ├── app.module.js.map│ ├── app.service.d.ts│ ├── app.service.js│ ├── app.service.js.map│ ├── main.d.ts│ ├── main.js│ ├── main.js.map│ └── tsconfig.build.tsbuildinfo├── nest-cli.json // cli配置文件├── package-lock.json├── package.json // npm项目配置├── src // 源文件│ ├── app.controller.spec.ts // 测试文件│ ├── app.controller.ts // 项目根控制器│ ├── app.module.ts // 项目根模块│ ├── app.service.ts // 项目根服务│ └── main.ts // 主入口文件├── test // 测试配置文件 + 测试文件│ ├── app.e2e-spec.ts│ └── jest-e2e.json├── tsconfig.build.json // ts打包配置└── tsconfig.json // ts配置 然后我们再来看看package.json，其中有两个部分非常需要注意： scripts自定义的脚本： start: 默认启动脚本 start:dev: 开启代码变化监视的启动脚本 start:debug：开启代码debug调试的启动脚本 start:prod：运行最终打包过后的代码 jest配置 123456789101112131415161718192021222324252627282930313233343536&#123; //... &quot;scripts&quot;: &#123; &quot;prebuild&quot;: &quot;rimraf dist&quot;, &quot;build&quot;: &quot;nest build&quot;, &quot;format&quot;: &quot;prettier --write \\&quot;src/**/*.ts\\&quot; \\&quot;test/**/*.ts\\&quot;&quot;, &quot;start&quot;: &quot;nest start&quot;, &quot;start:dev&quot;: &quot;nest start --watch&quot;, &quot;start:debug&quot;: &quot;nest start --debug --watch&quot;, &quot;start:prod&quot;: &quot;node dist/main&quot;, &quot;lint&quot;: &quot;eslint \\&quot;&#123;src,apps,libs,test&#125;/**/*.ts\\&quot; --fix&quot;, &quot;test&quot;: &quot;jest&quot;, &quot;test:watch&quot;: &quot;jest --watch&quot;, &quot;test:cov&quot;: &quot;jest --coverage&quot;, &quot;test:debug&quot;: &quot;node --inspect-brk -r tsconfig-paths/register -r ts-node/register node_modules/.bin/jest --runInBand&quot;, &quot;test:e2e&quot;: &quot;jest --config ./test/jest-e2e.json&quot; &#125;, // .... &quot;jest&quot;: &#123; &quot;moduleFileExtensions&quot;: [ &quot;js&quot;, &quot;json&quot;, &quot;ts&quot; ], &quot;rootDir&quot;: &quot;src&quot;, &quot;testRegex&quot;: &quot;.*\\\\.spec\\\\.ts$&quot;, &quot;transform&quot;: &#123; &quot;^.+\\\\.(t|j)s$&quot;: &quot;ts-jest&quot; &#125;, &quot;collectCoverageFrom&quot;: [ &quot;**/*.(t|j)s&quot; ], &quot;coverageDirectory&quot;: &quot;../coverage&quot;, &quot;testEnvironment&quot;: &quot;node&quot; &#125;&#125; 主程序文件（入口文件）main.ts在项目的src目录中，有整个项目的主程序文件main.ts： 12345678import &#123; NestFactory &#125; from &#39;@nestjs&#x2F;core&#39;;import &#123; AppModule &#125; from &#39;.&#x2F;app.module&#39;;async function bootstrap() &#123; const app &#x3D; await NestFactory.create(AppModule); await app.listen(3000);&#125;bootstrap(); 这主程序文件中： 使用NestFactory初始化了一个Nest实例app 定义服务监听3000端口 使用bootstrap()启动了该服务 我们可以看到该文件引入了一个模块即./app.module，可以从这个文件找到一些整个应用的蛛丝马迹。 12345678910import &#123; Module &#125; from &#x27;@nestjs/common&#x27;;import &#123; AppController &#125; from &#x27;./app.controller&#x27;;import &#123; AppService &#125; from &#x27;./app.service&#x27;;@Module(&#123; imports: [], controllers: [AppController], providers: [AppService],&#125;)export class AppModule &#123;&#125; 这里使用到了TypeScript中的Decorator，引入了一个AppService和AppController，如果熟悉Angular的小伙伴，看到这里就惊讶了。卧槽，这不是Augular吗？是的，官方给出了如下的解释： Nest provides an out-of-the-box application architecture which allows developers and teams to create highly testable, scalable, loosely coupled, and easily maintainable applications. The architecture is heavily inspired by Angular. 这是nestjs的哲学： Nest提供了一个开箱即用的应用架构，允许开发人员和团队创建高度可测试、可扩展、松散耦合和易于维护的应用。该架构深受Angular的启发。 了解到这一点来说之后，方便学习过Angular的同学快速的入手，那么对于没有学过Angular的同学，可以从以下两个角度来思考学习。 对于毫无Angular基础的同学来说： 应用是基础：先学会如何使用，写一些基础的接口，然后再去思考内在的逻辑，免得搞混了； 学习先进框架的概念：官方有一手的介绍，所以一点不用慌，而且这些概念源于Google，都是经过了验证的； 平时开发多问几个为什么：比如，为什么nestjs的入口是main.ts？nestjs是用什么打包的？怎么没有看到webpack的配置？ 对于学过Angular的同学来说： 大致浏览基础示例代码：在清楚核心的概念之后，这样有利于快速入手； 做一些实战项目：工具的学习不能浮于表面，一定要应用于自己的工作中来，对于小项目，可以参考官方的awesome示例页； 下面来回答几个问题： 为什么nestjs的入口是main.ts？下面是我个人的思考路径： package.json中的main属性，有没有？——没有 官方的配置文件中nest-cli.json，有没有？——没有 scripts中的运行脚本，有没有？——有，但是没有指明，只有nest start 运行脚本使用的CLI，CLI的原文件中，有没有？——这里，就需要调试node_modules了 按照上面的路径，可以自己建一个Nodejs的调试项目进行运行与调试！官方提供了--debug脚本，所以可以直接来创建，以VSCode为例：创建.vscode/launch.json 12345678910111213141516171819202122&#123; // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;Launch via NPM&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;runtimeArgs&quot;: [ &quot;run-script&quot;, &quot;start:debug&quot; ], &quot;runtimeExecutable&quot;: &quot;npm&quot;, &quot;skipFiles&quot;: [ &quot;&lt;node_internals&gt;/**&quot; ], &quot;type&quot;: &quot;pwa-node&quot; &#125; ]&#125; 直接使用VSCode的调试工具进行调试，这时候，新的问题来了，断点打在哪里？！学习过我们慕课网《大前端》的同学应该了解到CLI工具的工作原理，有以下几个组成部分： Commander —— 处理传递的参数 Action —— 具体的函数 下面打开node_modules，找到@nestjs/cli映入我们眼帘的是： 这不巧了？怎么有两个文件，很打眼呢？commands与actions，我们来查看一下： 第一个： 第二个： 分别点开： start.command.js中主要是解析命令参数，但是有一个关键方法：this.action.handle(inputs, options) 最终会来执行start.action.js： 1234567891011121314151617181920212223242526272829303132handle(inputs, options) &#123; return __awaiter(this, void 0, void 0, function* () &#123; try &#123; const configFileName = options.find((option) =&gt; option.name === &#x27;config&#x27;) .value; const configuration = yield this.loader.load(configFileName); const appName = inputs.find((input) =&gt; input.name === &#x27;app&#x27;) .value; const pathToTsconfig = get_value_or_default_1.getValueOrDefault(configuration, &#x27;compilerOptions.tsConfigPath&#x27;, appName, &#x27;path&#x27;, options); const binaryToRunOption = options.find((option) =&gt; option.name === &#x27;exec&#x27;); const debugModeOption = options.find((option) =&gt; option.name === &#x27;debug&#x27;); const watchModeOption = options.find((option) =&gt; option.name === &#x27;watch&#x27;); const isWatchEnabled = !!(watchModeOption &amp;&amp; watchModeOption.value); const watchAssetsModeOption = options.find((option) =&gt; option.name === &#x27;watchAssets&#x27;); const isWatchAssetsEnabled = !!(watchAssetsModeOption &amp;&amp; watchAssetsModeOption.value); const debugFlag = debugModeOption &amp;&amp; debugModeOption.value; const binaryToRun = binaryToRunOption &amp;&amp; binaryToRunOption.value; const &#123; options: tsOptions &#125; = this.tsConfigProvider.getByConfigFilename(pathToTsconfig); const outDir = tsOptions.outDir || defaults_1.defaultOutDir; const onSuccess = this.createOnSuccessHook(configuration, appName, debugFlag, outDir, binaryToRun); yield this.runBuild(inputs, options, isWatchEnabled, isWatchAssetsEnabled, !!debugFlag, onSuccess); &#125; catch (err) &#123; if (err instanceof Error) &#123; console.log(`\\n$&#123;ui_1.ERROR_PREFIX&#125; $&#123;err.message&#125;\\n`); &#125; else &#123; console.error(`\\n$&#123;chalk.red(err)&#125;\\n`); &#125; &#125; &#125;); &#125; 这时候，我们就可以打印一个configuration了或者加个断点，使用npm start来跑一下，得到的结果无非如下： 12345678910111213141516🚀 ~ file: start.action.js ~ line 29 ~ StartAction ~ return__awaiter ~ configuration &#123; language: &#x27;ts&#x27;, sourceRoot: &#x27;src&#x27;, collection: &#x27;@nestjs/schematics&#x27;, entryFile: &#x27;main&#x27;, projects: &#123;&#125;, monorepo: false, compilerOptions: &#123; tsConfigPath: &#x27;tsconfig.build.json&#x27;, webpack: true, webpackConfigPath: &#x27;webpack.config.js&#x27;, plugins: [], assets: [] &#125;, generateOptions: &#123;&#125;&#125; 已经让我们看到了entryFile的字样，至此，我们找到了入口文件。还可以顺这这条思路，继续来找： ​ 继续往下找： nestjs是用什么打包的？有了上面调试的技巧，来回答这个问题变得很简单，我们来看看scripts中的打包命令&quot;build&quot;: &quot;nest build&quot;,，所以我们找到对应的command，可以找到这么一个文件build.action.js： 12345678910111213141516171819202122232425262728293031323334runBuild(inputs, options, watchMode, watchAssetsMode, isDebugEnabled = false, onSuccess) &#123; return __awaiter(this, void 0, void 0, function* () &#123; const configFileName = options.find((option) =&gt; option.name === &#x27;config&#x27;) .value; const configuration = yield this.loader.load(configFileName); const appName = inputs.find((input) =&gt; input.name === &#x27;app&#x27;) .value; const pathToTsconfig = get_value_or_default_1.getValueOrDefault(configuration, &#x27;compilerOptions.tsConfigPath&#x27;, appName, &#x27;path&#x27;, options); const &#123; options: tsOptions &#125; = this.tsConfigProvider.getByConfigFilename(pathToTsconfig); const outDir = tsOptions.outDir || defaults_1.defaultOutDir; const isWebpackEnabled = get_value_or_default_1.getValueOrDefault(configuration, &#x27;compilerOptions.webpack&#x27;, appName, &#x27;webpack&#x27;, options); yield this.workspaceUtils.deleteOutDirIfEnabled(configuration, appName, outDir); this.assetsManager.copyAssets(configuration, appName, outDir, watchAssetsMode); if (isWebpackEnabled) &#123; // 与这里的一行代码 const webpackPath = get_value_or_default_1.getValueOrDefault(configuration, &#x27;compilerOptions.webpackConfigPath&#x27;, appName, &#x27;webpackPath&#x27;, options); const webpackConfigFactoryOrConfig = this.getWebpackConfigFactoryByPath(webpackPath, configuration.compilerOptions.webpackConfigPath); return this.webpackCompiler.run(configuration, webpackConfigFactoryOrConfig, pathToTsconfig, appName, isDebugEnabled, watchMode, this.assetsManager, onSuccess); &#125; if (watchMode) &#123; const tsCompilerOptions = &#123;&#125;; const isPreserveWatchOutputEnabled = options.find((option) =&gt; option.name === &#x27;preserveWatchOutput&#x27; &amp;&amp; option.value === true); if (isPreserveWatchOutputEnabled) &#123; tsCompilerOptions.preserveWatchOutput = true; &#125; this.watchCompiler.run(configuration, pathToTsconfig, appName, tsCompilerOptions, onSuccess); &#125; else &#123; // 这里的一行代码 this.compiler.run(configuration, pathToTsconfig, appName, onSuccess); this.assetsManager.closeWatchers(); &#125; &#125;);&#125; 结论： nestjs可以开启webpack打包 或者自己定义的打包，见下图 怎么没有看到webpack的配置？nestjs支持webpack打包，有两种方法启用webpack，然后，就可以在根目录中添加webpack.config.js文件了。 官方的说明： 方法一： 针对于命令：nest build 将应用程序或工作区编译到输出文件夹中。 1$ nest build &lt;name&gt; [options]Copy to clipboardErrorCopied 参数 参数 描述 &lt;name&gt; 要构建的项目的名称。 选项： 选项 描述 --path [path] tsconfig文件的路径。别名: -p --watch 在监视模式下运行（实时重载）别名-w --webpack 使用 webpack 进行编译。 --webpackPath 配置 webpack 的路径。 方法二： 在根目录中的nest-cli.json文件中配置compilerOptions，把webpack设置成true： 1234567&#123; &quot;collection&quot;: &quot;@nestjs/schematics&quot;, &quot;sourceRoot&quot;: &quot;src&quot;, &quot;compilerOptions&quot;: &#123; &quot;webpack&quot;: true &#125;&#125; 关于nest的nest-cli.json配置文件及其使用方式可以参考 这里。","categories":[{"name":"nestjs搭建通用业务框架","slug":"nestjs搭建通用业务框架","permalink":"https://www.toimc.com/categories/nestjs%E6%90%AD%E5%BB%BA%E9%80%9A%E7%94%A8%E4%B8%9A%E5%8A%A1%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"https://www.toimc.com/tags/node-js/"},{"name":"nestjs","slug":"nestjs","permalink":"https://www.toimc.com/tags/nestjs/"},{"name":"web框架","slug":"web框架","permalink":"https://www.toimc.com/tags/web%E6%A1%86%E6%9E%B6/"}]},{"title":"nestjs搭建通用业务框架（1）：基础介绍","slug":"nestjs-example-project-1","date":"2021-03-08T13:05:05.000Z","updated":"2021-03-12T03:40:39.725Z","comments":true,"path":"nestjs-example-project-1/","link":"","permalink":"https://www.toimc.com/nestjs-example-project-1/","excerpt":"在网上看了很多关于nestjs的文章，发现大多数的文章不成体系。所以，打算从应用角度，带领大家一点点的学习nestjs，并架构一套可通用的业务框架，方便大家入门。","text":"在网上看了很多关于nestjs的文章，发现大多数的文章不成体系。所以，打算从应用角度，带领大家一点点的学习nestjs，并架构一套可通用的业务框架，方便大家入门。 本篇是nestjs上手的基础篇，主要从以下的几个角度来谈一谈： What：什么是nestjs Where：什么时候应用nestjs？或者说，什么场景下用它 Why：为什么要用nestjs？nestjs可以与哪些技术集成？官方提供了哪些现成的方案？ How：怎么入手？基础的搭建与入门 nestjs是什么？官方定义下面我们用一张图片来引入，这是nestjs官网的截图： 其中有对nestjs的定义： Hello, nest! A progressive Node.js framework for building efficient, reliable and scalable server-side applications. 翻译过来就是：用于构建高效且可伸缩的服务端应用程序的渐进式 Node.js 框架。 从上面定义我们可以拆解出来nestjs框架的一些基础的特性： Node.js：首先，它基于Node.js的环境，是对前端友好的。前端工程师无需再继续学习其他的语言（PS: 不代表不需要了解框架），即可以上手； 服务端应用程序：nestjs基础的功能是用于开发接口； 高效且可伸缩：这一点，可以看出，nestjs的各个功能模块之间的架构应该是解耦的，而且是易于进行组合的； 渐进式：可简单，可复杂，根据大家自己的项目的复杂度。 nestjs特点除了从上面的定义上我们进行的主观拆解，那nestjs还具有哪些特点呢？ nestjs框架的特点： 完美支持 Typescript 面向 AOP 编程 支持 Typeorm 高并发，异步非阻塞 IO Node.js 版的 spring 构建微服务应用 这些全来自于nestjs中文网首页的介绍。 近年发展近些年来，nestjs从2017年创立的发展非常迅猛，以下是stars增长趋势： 目前已经收获了35,152个点赞，来源：StarTrack 然后再看看npm的趋势与其他的几个库的比较： express 2010年1月发布（点赞52.2k） meteor 2012年发布（自成一套下载安装，非npm，点赞42k） koa 2013年11月发布（点赞30.8k） egg.js 2016年7月发布（点赞16.8k） （截止北京时间2021年03月08日 21:53:36） nestjs应用场景 这个部分我年过很多人写的内容，其实技术上，前端人喜欢看新的特点——技术新、更新勤。 追新不能盲目，而是要从现实的角度出发，解决问题才是最终目的。 基本应用：服务端项目开发完成接口功能； 服务端扩展：安全、鉴权、队列、日志、性能、测试、消息； 技术架构：微服务、TypeORM+序列化对接多种数据库、多环境配置、AOP编程、MVC基本模型； 一些成功的案例： 官方地址：Who is using Nest? 大家可以从其技术特点的角度出发，从自己的团队的技术实力与项目的复杂度出发进行综合考虑。 “convention over configuration”——Jeremy Miller 对于nestjs来说，大多数前端同学可能不习惯的点： MVC分层与模块化思想 ts静态类型检查 + 注解 + AOP编程 ORM框架的概念的理解与使用 服务端架构 与需要考虑到的：安全、日志、性能、监控等 运维相关 nestjs框架关联技术打开nestjs的官方github仓库，可以看到很多官方提供的方案： CLI: 官方的CLI工具 TypeORM: 对接各式各样的数据库 Serverless：微服务 Swagger：用于产生API接口文档 Sequelize：序列化 Mongoose GraphQL Jwt/passport：鉴权模块 ElasticSearch：搜索模块 Config：配置模块，用于多环境配置 …. 从官方的仓库的更新的频次，可以看到社区的活跃。而且，拥有的众多成熟方案 + 丰富的文档，让nestjs在国外的发展非常的好。 而且，从相关概念上来说，对于前端同学走向全栈，可以打开关于服务端架构层面的视野。大家可以关注一下如下的这个资源：相关资料 这个资源是nestjs中文网整理的，包括社区、示例项目、常用库、难点技术集成等，比如：状态管理、代码风格、邮件、API、错误统一处理、Lint、路由、日志 + 监控、国际化、鉴权等。 nestjs的前景怎么样我们先看看使用了的同学们，大家怎么评价： 同学A： \u0011我认为框架有两个优点 第一 蹭了一波 typescript 的热度。 第二 它的标准化使的开发的流程非常方便，特别是针对流动性比较大的公司来说这是个好事，koa 和 express 你非常自由这导致了大家开发的时候有自己的一套开发方式（比如，不同的分层，文件命名，项目整体结构），如果制定项目的人走了，经过几波换人会不会把这个项目改的面目全非？ 同学B： nestjs在国内的未来不见得会很好，因为缺少布道者，另一方面是国内有阿里egg.js、midway的竞争。如果从企业级开发的角度来看，nest.js的理念比其他node.js web框架都好太多了 同学C： nest.js的更新非常非常的频繁，这说明社区活跃度很高。我们团队18年刚开始用的egg.js，我为此开发了上层的框架，后来发现nest.js早就把这些事情都做好了，比如装饰器路由、Exception filters、Pipes、Guards、Interceptors， 同学D： 挺好的，但如果不熟悉 JavaSpring 的话， 上手需要一定成本。不过我觉得挺像 Midway.js，我 IOC 是看 Midway 的，有这一专题的文档，你可以找找看。nestjs 的生态是基于 Express， Midway 是基于 koa 和阿里的 egg。 …. 大家的褒贬不一，总结一下。 优点： 官方社区活跃 框架架构设计合理，对于大型项目非常利于整体的统一； 成熟的官方解决方案 ts加持； 缺点： 上手有一定的难度 后期相关的开发人员的缺乏 nestjs学习资源 官方资源 官方网站 官方文档 API 参考 GitHub Repo 文档 中文文档 （推荐） 相关资料 社区 中文交流群 Gitter Discord Telegram (社区维护) Telegram (俄罗斯社区) Slack (韩语社区) QQ 群 (中文社区) Reddit (社区维护) 下面一篇，我们来介绍使用@nestjs/cli上手nestjs开发。","categories":[{"name":"nestjs搭建通用业务框架","slug":"nestjs搭建通用业务框架","permalink":"https://www.toimc.com/categories/nestjs%E6%90%AD%E5%BB%BA%E9%80%9A%E7%94%A8%E4%B8%9A%E5%8A%A1%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"https://www.toimc.com/tags/node-js/"},{"name":"nestjs","slug":"nestjs","permalink":"https://www.toimc.com/tags/nestjs/"},{"name":"web框架","slug":"web框架","permalink":"https://www.toimc.com/tags/web%E6%A1%86%E6%9E%B6/"}]},{"title":"Flutter 2.0正式发布，支持跨全平台","slug":"flutter-2-is-comming","date":"2021-03-04T12:12:31.000Z","updated":"2021-03-12T03:36:06.832Z","comments":true,"path":"flutter-2-is-comming/","link":"","permalink":"https://www.toimc.com/flutter-2-is-comming/","excerpt":"2021年3月4日，谷歌正式宣布了 Flutter 2 的推出。作为一款用于构建轻巧型移动应用的开源 UI 工具包，Flutter 的第二个大版本增加了对桌面和 Web 应用程序的支持。开发者可借助 Flutter 2 打造开箱即用的应用程序，并且能够为 iOS、Android、Windows、macOS、Linux 和 Web 端套用相同的代码。","text":"2021年3月4日，谷歌正式宣布了 Flutter 2 的推出。作为一款用于构建轻巧型移动应用的开源 UI 工具包，Flutter 的第二个大版本增加了对桌面和 Web 应用程序的支持。开发者可借助 Flutter 2 打造开箱即用的应用程序，并且能够为 iOS、Android、Windows、macOS、Linux 和 Web 端套用相同的代码。 Flutter的愿景Flutter 的目标是改变开发人员对构建应用程序的思路，不是从开发者需要适配的平台开始，而是让开发者从需要完成的用户需求开始实现。 Flutter 可以让你在拥有更好设计效果的情况下，得到更好的用户体验，因为它的运行速度很快，它会将源代码编译为机器代码，但是 Flutter 在开发过程中支持的 hotload，所以也可以在应用程序调试运行时进行更改并立即查看结果。 在这次发布的Flutter 2中，Flutter 正式将从移动框架扩展到了全平台框架，使用 Flutter 2 开发者可以让它的应用直接运用到各种不同的平台而几乎不需要做出什么改变。现在仅 Play 商店就已经有超过15万个Flutter应用程序，并且每个应用程序都可以通过 Flutter 2 进行免升级，因为它们现在可以在不重写的情况下扩展到 Desktop 和Web 。 在 Google 内部也会使用 Flutter 开发，Google 内有近一千多名工程师正在使用 Dart 和Flutter 构建应用程序，其中许多产品都已经发布了，包括：Stadia，Google One和Google Nest Hub 等等。 在几个月前， Google Pay 里的旗舰移动应用就有不少更改为使用 Flutter，它们已经在生产力和质量上取得了重大进步。通过统一的代码库，团队消除了平台之间的功能差异，并清理超过一百万行代码，Google Pay 的报告还提到其工程师的效率要高得多，技术债务大大减少，统一的发布流程（如跨 iOS 和 Android 的安全性审查和试验）得以实现。 Flutter vs RN vs Ionic下面有一张图说明Flutter与现行的RN，Ionic这些跨平台的应用框架的对比： Ionic：Ionic提供了最差的性能，因为它到底是一个封装的web应用。 Flutter、NativeScript和React Native。这三个都为你提供了真正的原生应用（从你的代码中编译），因此，它们提供了比Ionic更好的性能。对这三者中谁是最好的做精确的测量是相当困难的，因为它依赖于你正在构建的应用程序、使用的设备、操作系统和使用的Flutter/ NativeScript/ React Native的版本。Flutter它具有Dart的优势，并且没有JavaScript桥来启动与设备原生组件的交互，它提供的速度是这三者中表现比较好的。 原生：写得好的原生代码应该总是比编译后的原生代码性能更高。 Flutter2.0重大的变化 开发团队表示，Flutter 2.0 有意为 Web 平台提供了非常标准的、以 DOM 为中心的开发方式。尽管效果不错，这么做也可能带来性能方面的阻碍（尤其是更高级的功能）。 过去大约一年时间里，Flutter 团队开始研究基于WebAssembly的Canvas Kit项目，特点是采用了与为Android / Chrome提供支撑的相同的 Skia图形引擎。Tim Sneath 表示：“这意味着我们现在基本上可以绕过核心 HTML，并真正使用 Web 平台上以应用程序为中心的部分，而不会留下（自动完成的）文字或密码、以及让网络保持独特状态的各项特性”。桌面平台方面，谷歌宣布Canonical将在 Flutter 上全力以赴，并使之成为所有未来桌面 / 移动应用程序的默认选项。 上面演示Flutter应用，与原生应用。从上面的演示可以看出，flutter的性能是非常优秀的。 Flutter入门资料【1】官方文档【2】中文文档【3】Flutter环境配置【4】Flutter与前端 我们后续的内容中，也会去更新相关的Flutter学习的路径，请大家关注！~","categories":[{"name":"flutter","slug":"flutter","permalink":"https://www.toimc.com/categories/flutter/"}],"tags":[{"name":"flutter","slug":"flutter","permalink":"https://www.toimc.com/tags/flutter/"}]},{"title":"浏览器http自动跳转https，导致图片访问失败","slug":"image-google-ssl-limit","date":"2021-03-03T01:57:03.000Z","updated":"2021-03-03T03:53:15.522Z","comments":true,"path":"image-google-ssl-limit/","link":"","permalink":"https://www.toimc.com/image-google-ssl-limit/","excerpt":"目前，chrome浏览器https协议的域中访问http自动跳转https，该如何解决呢？思路：给图床添加ssl证书，一般的对象云存储都可以有免费的SSL证书申请；或者，直接在浏览器中关闭阻止不安全的内容来源。","text":"目前，chrome浏览器https协议的域中访问http自动跳转https，该如何解决呢？思路：给图床添加ssl证书，一般的对象云存储都可以有免费的SSL证书申请；或者，直接在浏览器中关闭阻止不安全的内容来源。 方案一： 网上查了好多解决方案，说是缓存或者删除配置之类的，但是都没能解决。 问题原因：https在部分chrome浏览器版本中安全设置项为默认屏蔽不安全内容（针对域名）导致。 解决方法：按下图步骤操作即可 方案二： 本博客采用了七牛云存储，hexo与七牛云的插件还比较好用： 方便设置图片的大小 方便进行图片的上传 方便管理图片资源 流量也不贵 所以，我尝试着使用了一下七牛云的DV证书（免费！免费！免费！），只会收取小部分CDN + HTTPS流量的费用。 下面介绍下步骤： 打开七牛云证书管理，申请DV证书 购买证书。 直接点击确认支付，然后补全个人信息，可以选择部署CDN 这里一定要注意，这个域名最好是子域名，因为DV域名只能申请静态的，而非泛域名; 并且，域名需要备案 证书的签发需要10分钟左右的时间。 打开七牛云CDN，配置域名，在域名管理处添加子域名（比如：static.www.yourdomain.com） 路径：点击CDN -&gt; 域名管理 -&gt; HTTPS配置 如果域名没有备案，则会出现ICP备案提示！！！ 保存之后，配置CNAME CNAME需要在各自的域名服务商配置域名解析： 可以点击后面的帮助 最后，可以测试一下，上传到七牛云对象云存储的图片，有没有转成https的链接：","categories":[],"tags":[{"name":"https","slug":"https","permalink":"https://www.toimc.com/tags/https/"},{"name":"ssl","slug":"ssl","permalink":"https://www.toimc.com/tags/ssl/"}]},{"title":"如何让网站达到ssl评级A+——本站开启tls1.3","slug":"如何让网站达到ssl评级A","date":"2021-03-02T13:47:25.000Z","updated":"2021-03-12T03:36:33.808Z","comments":true,"path":"如何让网站达到ssl评级A/","link":"","permalink":"https://www.toimc.com/%E5%A6%82%E4%BD%95%E8%AE%A9%E7%BD%91%E7%AB%99%E8%BE%BE%E5%88%B0ssl%E8%AF%84%E7%BA%A7A/","excerpt":"本文介绍了使用docker快速创建nginx服务，并介绍了如何配置tls1.3的方法，让网站的ssl","text":"本文介绍了使用docker快速创建nginx服务，并介绍了如何配置tls1.3的方法，让网站的ssl 先上图片： 对如何评到A以及A+不是很理解，这里简单的说明一下。 首页说明一下这个评分，并不仅仅是针对于证书的部署情况而言的，这是一个多方面综合的评级，其中包括了证书、SSL协议、加密套件、漏洞、不安全的外链等等。 具体步骤： docker方式安装Nginx 配置nginx 验证TLS 安装nginx推荐使用这个镜像：docker pull khs1994/nginx:1.19.7-alpine 仓库地址：https://github.com/khs1994-docker/nginx docker-compose配置： 123456789101112version: &quot;3&quot;services: nginx: image: &quot;khs1994/nginx:1.19.7-alpine&quot; ports: - &quot;80:80&quot; - &quot;443:443&quot; environment: - TZ=Asia/Shanghai volumes: - ./conf.d:/etc/nginx/conf.d:ro 其中 ./conf.d 是相对于nginx的配置目录。 配置nginx在 Nginx 的站点配置中，下面是我们推荐的配置内容： 12345ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3;ssl_ciphers &#x27;TLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:TLS13-AES-128-CCM-8-SHA256:TLS13-AES-128-CCM-SHA256:EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+ECDSA+AES128:EECDH+aRSA+AES128:RSA+AES128:EECDH+ECDSA+AES256:EECDH+aRSA+AES256:RSA+AES256:EECDH+ECDSA+3DES:EECDH+aRSA+3DES:RSA+3DES:!MD5&#x27;;add_header Strict-Transport-Security &quot;max-age=31536000&quot;; 包含 TLS13 是 TLS 1.3 新增的 Cipher Suite，加在最前面即可；如果你不打算继续支持 IE8，可以去掉包含 3DES 的 Cipher Suite。 有几点需要注意： 删除TLSv1的支持 添加头部：Strict-Transport-Security 配置ssl_ciphers 验证是否支持 TLS 1.3目前最新版 Chrome 和 Firefox 都支持 TLS 1.3，但需要手动开启： Chrome，将 chrome://flags/ 中的 Maximum TLS version enabled 改为 TLS 1.3（Chrome 62 中需要将 TLS 1.3 改为 Enabled (Draft)，感谢 @TsuranSonoda 指出）； Firefox，将 about:config 中的 security.tls.version.max 改为 4； 推荐： 英文： Qualys SSL Labs’s SSL Server Test 中文： MySSL 也支持验证服务端是否支持 TLS 1.3，非常方便，推荐。","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://www.toimc.com/tags/nginx/"},{"name":"https","slug":"https","permalink":"https://www.toimc.com/tags/https/"},{"name":"docker","slug":"docker","permalink":"https://www.toimc.com/tags/docker/"}]},{"title":"大型项目前端架构设计","slug":"大型项目前端架构设计","date":"2021-03-01T15:59:24.000Z","updated":"2021-03-13T04:39:32.530Z","comments":true,"path":"大型项目前端架构设计/","link":"","permalink":"https://www.toimc.com/%E5%A4%A7%E5%9E%8B%E9%A1%B9%E7%9B%AE%E5%89%8D%E7%AB%AF%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","excerpt":"入门很多年的前端小伙伴，也会遇到工作中需要设计大型项目的时候。如何做好前期的架构设计，对于后期项目的扩展与升级都是非常重要的。 本文不会侧重于具体技术实现，而是尝试从整体角度出发，分析为什么与怎么做，以及成本和产出如何。","text":"入门很多年的前端小伙伴，也会遇到工作中需要设计大型项目的时候。如何做好前期的架构设计，对于后期项目的扩展与升级都是非常重要的。 本文不会侧重于具体技术实现，而是尝试从整体角度出发，分析为什么与怎么做，以及成本和产出如何。 前情提要适用场景：大家前端项目的规模不同，按照本文实践成本收益比也会有所差别。 通常来说，人员越多、项目复杂度越高，可参考的价值越大，所有技术点经过大型项目的论证。 同时对于技术变的发展变迁，可能有部分措施不适用，因此应该根据具体情况来选用。 还是那句话“合适的才是最好的”。 中心思想： 解决问题：前端架构的设计，目的增加项目的可管理性、稳定性、可扩展性。 质量与成本：对于需要额外开发工作量的事务，我们在决定是否去做的时候，应该考虑到两个要素：第一个是花费的人力成本，第二个是未来可能节约的时间和金钱、避免的项目风险与资损、提高对业务的支撑能力以带来在业务上可衡量的更高的价值、以及其他价值。 定性和定量：架构里设计一定要有是可衡量的意义的内容，最好是可以定量的（可以衡量带来的收益或减少的成本），至少是可以定性的（无法用数字阐述收益，但我们可以明确这么做是有意义的），例如：增加安全性降低风险。 数据敏感：专门写这一条强调数据作为依据的重要性。当我们需要说服其他部门/上级管理者，以推动我们设计的内容时，只有数据——特别是跟钱有关的数据，才是最有说服力的证明。如果前期无法有数据支撑，可以安插埋点在系统之中，通过获取用户数据，对项目效果进行宣分析，并以此推动项目的演进。 设计分层：整个架构设计分为：基础层和应用层 基础层偏基础设施建设，与业务相关性较低。 应用层更贴近用户，用于解决某一个问题。 部分两个都沾边的，根据经验划分到其中一个。 其他由于已经谈到架构层级，因此很多内容，并不仅仅只属于前端领域，有很多内容是复合领域（前端、后端、运维、测试），因此需要负责架构的人，技术栈足够全面，对未来发展有足够的前瞻性。 文章的内容结构为：【项目】—&gt;【解决的问题和带来的好处】—&gt;【项目的实际意义】 基础层设计自建Git平台这个是基础，使用Git平台的难度非常低。强烈建议使用Gitlab进行版本管理，自建Gitlab难度并不大，方便管理，包括代码管理、权限管理、提交日志查询，以及联动一些第三方插件。在《大前端》的课程中，有专门的介绍，这里不再累述。 公司代码是公司的重要资产，使用自建Gitlab可以有效保护公司资产。 版本管理的几个关键点： 发布后不可再更改：指当例如1.0.0版本成功发布后，不可再更改1.0.0 tag上的代码，否则可能会导致版本管理混乱。 全自动流程发布；指应避免开发者提交后，手动编译打包等操作。换句话说，开发人员发布后，将自动发布到预发布/生产环境。开发人员不和相关环境直接接触。实现这个需要参考下面的CI/CD平台自动发布。 多版本并存；指当例如发布2.0.0版本后，1.0.0版本的代码应仍保存在线上（例如CDN），这样当出现线上bug时，方便快速回滚到上一个版本。意义：提高项目的可控性。 自动编译发布CI/CD平台这个工具用于在代码发布后，执行一系列流程，例如自动编译打包合并，然后再从Gitlab发布到CDN或者静态资源服务器。 使用这个工具，可以让一般研发人员不关心代码传到Gitlab后会发生什么事情，只需要专心于开发就可以了。 意义：让研发人员专心于研发，和环境、运维等事情脱钩。 纯前端版本发布纯前端版本发布分为两步： 前端发布到生产环境——此时可以通过外网链接加正确的版本号访问到新版本的代码，但页面上的资源还是旧版本； 前端通过配置工具（或者是直接更新html文件），将html中引入的资源，改为新版本。 解决的问题是：当前端需要发布新版本时，可以不依赖于后端（根据实际情况，也可以不依赖于运维）。毕竟有很多需求并不需要后端介入，单纯改个前端版本后就要后端发布一次，显然是一件非常麻烦的事情。 这个需要专门的工具，用于配置版本发布，我最近就在写这个。 意义：提高发布效率，降低发布带来的人员时间损耗（这些都是钱），也可以在前端版本回滚的时候，速度更快。 统一脚手架适用场景：有比较多独立中小项目。 好处：可以减少开发人员配置脚手架带来的时间损耗（特殊功能可以fork脚手架后再自行定制）； 统一项目结构，方便管理，也降低项目交接时带来的需要熟悉项目的时间； 方便统一技术栈，可以预先引入固定的组件库； 意义：提高开发人员在多个项目之间的快速切换能力，提高项目可维护性，统一公司技术栈，避免因为环境不同导致奇怪的问题。 Node中间层适用场景：需要SEO且前端使用React、vue，或前端介入后端逻辑，直接读取后端服务或者数据库的情况。 SEO：仁者见仁智者见智，虽然很多公司已经不做了，但通常认为，还是有一定意义的（特别是需要搜索引擎引流的时候），因此React或者Vue的同构是必须的。并且同构还可以降低首页白屏时间； 前端读取后端服务/数据库：好处是提高前端的开发效率和对业务的支持能力，缺点是可能导致P0级故障。 意义：让前端可以侵入后端领域，质的提升对业务的支持能力。 埋点系统强烈推荐前端做自己的埋点系统。这个不同于后端的日志系统。 前端埋点系统的好处： 记录每个页面的访问量（日周月年的UV、PV）； 记录每个功能的使用量； 捕捉报错情况； 图表化显示，方便给其他部门展示； 埋点系统是前端高度介入业务，把握业务发展情况的一把利剑，通过这个系统，我们可以比后端更深刻的把握用户的习惯，以及给产品经理、运营等人员提供准确的数据依据。当有了数据后，前端人员就可以针对性的优化功能、布局、页面交互逻辑、用户使用流程。 埋点系统应和业务解耦，开发人员使用时注册，然后在项目中引入。然后在埋点系统里查看相关数据（例如以小时、日、周、月、年为周期查看）。 意义：数据是money，数据是公司的生命线，数据是最好的武器。 监控和报警系统监控和报警系统应基于埋点系统而建立，在如以下场景时触发： 当访问量有比较大的变化（比如日PV/UV只有之前20%以下）时，自动触发报警，发送邮件到相关人员邮箱； 比如报错量大幅度上升（比如200%或更高），则触发报警； 当一段时间内没有任何访问量（不符合之前的情况），则触发报警； 每过一段时间，自动汇总访问者/报错触发者的相关信息（例如系统、浏览器版本等）； 建设这个系统的好处在于，提前发现一些不容易发现的bug（需要埋点做的比较扎实）。有一些线上bug，因为用户环境特殊，导致无法被开发人员和测试人员发现。但其中一部分bug又因为不涉及资金，并不会导致资损（因此也不会被后端的监控系统所发现），这样的bug非常容易影响项目里某个链路的正常使用。 意义：提高项目的稳定性，提高对业务的把控能力。降低bug数，降低资损的可能性，提前发现某些功能的bug（在工单到来之前） 安全管理前端的安全管理，通常要依赖于后端，至于只跟单纯有关系的例如dom.innerHTML= ‘xxx ‘这种太基础。 安全管理的很难从架构设计上完全避免，但还是有一定解决方案的，常见安全问题如下： XSS注入：对用户输入的内容，需要转码（大部分时候要server端来处理，偶尔也需要前端处理），禁止使用eval函数； https：这个显然是必须的，好处非常多； CSRF：要求server端加入CSRF的处理方法（至少在关键页面加入）； 意义：减少安全漏洞，避免用户受到损失，避免遭遇恶意攻击，增加系统的稳定性和安全性。 ESLintESLint的好处很多： 降低低级bug（例如拼写问题）出现的概率； 增加代码的可维护性，可阅读性； 硬性统一代码风格，团队协作起来时更轻松； 总的来说，ESLint推荐直接配置到脚手架之中，对我们提高代码的可维护性的帮助会很大。可以考虑在上传到gitlab时，硬性要求ESLint校验，通过的才允许上传。 意义：提高代码的可维护性，降低团队协作的成本。 灰度发布灰度发布是大型项目在发布时的常见方法，指在发布版本时，初始情况下，只允许小比例（比如1~5%比例的用户使用），若出现问题时，可以快速回滚使用老版本，适用于主链路和访问量极大的页面。 好处有以下几点： 生产环境比开发环境复杂，灰度发布时可以在生产环境小范围尝试观察新版本是否可以正常运行，即使出问题，也可以控制损失。 对于大版本更新，可以先灰度一部分，观察埋点效果和用户反馈（即所谓的抢先试用版）。假如效果并不好，那么回滚到老版本也可以及时止损； 当我们需要验证某些想法或问题的时候，可以先灰度一部分，快速验证效果如何，然后查漏补缺或者针对性优化； 灰度发布通常分为多个阶段，灰度发布一定要允许配置某些IP/账号访问时，可以直接访问到灰度版本。 意义：降低风险，提高发布灵活度。 前后端分离这个并不是指常见的前后端分离，而是指在分配前后端管控的领域。 中小项目常见的情况是后端只提供接口和让某个url指向某个html，前端负责html、css、js等静态资源。 但大型项目并不建议这么做，建议前端负责除html以外的静态资源，而html交给后端处理，理由有很多： 后端进行渲染，方便统一插入一些代码和资源，例如埋点js，监控js，国际化文本资源，页面标识符等。这些通常是后端通过调用某些服务直接写入的；当页面需要统一的头尾时（参考淘宝里我的淘宝页面），前端不应该关注这些跟当前页面无关的东西； 某些东西，如果通过html来管理，那么耦合度太高了，违背了解耦和分离的原则； 前端版本发布在后端引入某种功能模块后，可以从单独的页面控制前端发布内容，比更新html更方便，也利于灰度发布； 意义：更规范的进行页面管理，降低页面和功能的耦合度，减少复杂页面的环境配置时间。 MockMock也是常见前端系统之一，用于解决在后端接口未好时，生成返回的数据。 我个人建议DOClever等平台工具来Mock，思路如下： 当在开发环境下，访问链接通常是localhost:8000/index.html，此时设置成为开发中。 当线上接口可以获取到数据后，修改mock系统接口的状态开发已完成，系统会自动切换到生产接口。 意义：在前后端并行开发时，降低沟通交流成本，方便开发完毕后直接对接。 定期备份备份是常被忽略的一件事情，但当我们遇见毁灭性场景时，缺少备份带来的损失是非常大的，常见场景： 服务器损坏，导致存在该服务器上的内容全部完蛋； 触发某致命bug或者错误操作（例如rm -f），导致文件和数据全部消失； 数据库出现错误操作或出现问题，导致用户数据、公司资产遭受严重损失； 总的来说，没人想遇见这样的场景，但我们必须考虑这种极端情况的发生，因此需要从架构层面解决这个问题。常见方法是定期备份、多机备份、容灾系统建设等。 意义：避免在遭遇极端场景时，给公司带来不可估量的损失。 应用层设计多页和单页除了特殊场景，通常推荐使用主流前端框架Vue &amp; React + SSR首屏优化。理由如下： 主流项目的技术已经非常的成熟，受众广，而且文档全 SSR技术有利于提升整体用户感知与体验，对于纯后台的项目不做强制的要求 无论是Vue 还是 React，在跨端跨界部分的生态都建设的非常不错，可以横向进行扩展 意义：降低长期项目迭代维护的难度， 以应用为单位划分前端项目在项目比较大的时候，将所有页面的前端文件放入到同一个代码仓库里，我之前参与过一家企业的前端项目开发，发现其就是这么做的。根据使用经验来看，存在很多问题： 会极大的增加代码的维护难度； 项目会变得很丑陋； 不方便权限管理，容易造成页面误更改或代码泄密； 任何人都有权利改任何他能看到的页面（在合并代码的时候，管理人员并不能确定他本次修改的页面是否是需求里他应该改的页面）； 发布成本高，即使改一个页面，也需要发布所有资源； 因此，我们应该避免这种现象的发生，个人推荐以应用为单位进行开发、发布。所谓应用即指一个业务涉及到的前后端代码，好处很多： 方便进行管理，当某个业务有需求变更时，可以只给研发人员该业务前端应用的developer权限； 在需要发布某业务时，只需要发布该业务的所属应用即可； 意义：规范项目，增加代码的安全性，降低项目维护成本。 基础组件库的建设这个蛮基础的，对于组件库的建设，不建议研发人员较少时去做这件事情，专职前端开发人数少于10人时，建议使用比较靠谱的第三方UI库，例如Antd，这样性价比更高。 设计基础组件库的前提，是要求统一技术栈，这样才能最大化基础组件库的效益。组件库建议以使用以下参考标准： 使用ts； 可扩展性强； 适用程度高； 文档清楚详细； 版本隔离，小版本优化加功能，大改需要大版本更新； 和UI协调统一，要求UI交互参与进来； 总的来说，建设起来后，利大于弊，但是需要专人维护，因此还是有一定成本的。 意义：统一不同/相同产品线之间的风格，给用户更好的体验，减少单次开发中写UI组件时浪费的时间和人力，提高开发效率。 技术栈统一前端有三大主流框架，还有兼容性最强jQuery，以及各种第三方库，UI框架。因此项目需求如果复杂一些，很容易形成一个大杂烩。因此前端的技术栈必须统一，具体来说，建议实现以下举措： 三大框架选型其一，团队水平一般推荐Vue、水平较好推荐React，对外项目选React或者ng； 需要兼容IE8或更老版本时，建议使用jQuery； 组件库自建或者统一选择一个固定的第三方； 一些特殊第三方库统一使用一个版本，例如需要使用地图时，固定使用高德或百度或腾讯地图； 基础设施建设应避免重复造轮子，所有团队尽量共用，并有专门的前端平_台负责统一这些东西，对于特殊需求，可以新建，但应当有说服力； 总的来说，技术栈统一的好处很多，可以有效提高开发效率，降低重复造轮子产生的成本。 意义：方便招人，简化团队成员培养成本，以及提高项目的可持续性。 浏览器兼容常见的问题是IE6、7、8，以及部分小众浏览器（PC和手机）产生的奇怪问题。因此应该考虑统一解决方案，避免bug的重复产生。常见解决方案有：配置postcss，让某些css增加兼容性前缀； 写一个wepback的loader，处理某些特殊场景； 规范团队代码，使用更稳定的写法（例如移动端避免使用fixed进行布局）； 对常见问题、疑难问题，总结解决方案并团队共享； 建议或引导用户使用高版本浏览器（比如chrome）； 意义：避免浏览器环境产生的bug，以及排查此类bug所浪费的大量时间。 内容平台建设为了提高公司内部的沟通效率，总结经验，以及保密原因。应建设一个内部论坛+博客站点。其具备的好处如下： 可以记录公司的历史； 研发同学之间分享经验； 总结转载一些外界比较精品的文章，提高大家的眼界； 增加公司内部同学的交流，有利于公司的团队和文化建设； 对某些技术问题可以进行讨论，减少因没有达成共识带来的沟通损耗； 众所周知，大型互联网公司通常都有这样一个内部论坛和博客站点。其降低了公司的沟通和交流成本，也增加了公司的技术积累。 意义：博客增强技术积累，论坛增强公司内部沟通能力。 权限管理平台当公司内部人员较多时，应有一个专门的平台，来管理、规范用户的权限以及可访问内容。权限管理平台有几个特点： 必然和Server端天然高耦合度，因此需要有专门的控制模块负责处理权限问题（负责Server端开发处理，或者前端通过中间层例如Node层介入处理）； 自动化流程控制，即用户创建、申请、审批、离职自动删除，都应该是由系统推进并提醒相关人士，必要时应能触发报警； 权限应有时效性，减少永久性权限的产生； 审批流程应清晰可见，每一阶段流程应具体明确； 应与公司流程紧密结合，并且提高可修改性，方便公司后期进行流程优化； 意义：使得公司内部流程正规化、信息化。 登录系统设计（单点登录）当公司内部业务线比较复杂但相互之间的耦合度比较高时，我们应该考虑设计添加单点登录系统。具体来说，用户在一处登录，即可以在任何页面访问，登出时，也同样在任何页面都失去登录状态。SSO的好处很多： 增强用户体验； 打通了不同业务系统之间的用户数据； 方便统一管理用户； 有利于引流； 降低开发系统的成本（不需要每个业务都开发一次登录系统和用户状态控制）； 总的来说，大中型web应用，SSO可以带来很多好处，缺点却很少。 意义：用户体验增强，打通不同业务之间的间隔，降低开发成本和用户管理成本。 CDN前端资源的加载速度是衡量用户体验的重要指标之一。 而现实中，因为种种因素，用户在加载页面资源时，会受到很多限制。因此上CDN是非常有意义的，好处如下： 用户来自不同地区，加入CDN可以使用户访问资源时，访问离自己比较近的CDN服务器，降低访问延迟； 降低服务器带宽使用成本； 支持视频、静态资源、大文件、小文件、直播等多种业务场景； 消除跨运营商造成的网络速度较慢的问题； 降低DDOS攻击造成的对网站的影响； CDN是一种比较成熟的技术，各大云平_台都有提供CDN服务，价格也不贵，因此CDN的性价比很高。 意义：增加用户访问速度，降低网络延迟，带宽优化，减少服务器负载，增强对攻击的抵抗能力。 负载均衡目前来看，负载均衡通常使用Nginx比较多，以前也有使用Apache。当遇见大型项目的时候，负载均衡和分布式几乎是必须的。 负载均衡有以下好处： 降低单台server的压力，提高业务承载能力； 方便应对峰值流量，扩容方便（如举办某些活动时）； 增强业务的可用性、扩展性、稳定性； 负载均衡已经是蛮常见的技术了，好处不用多说，很容易理解。 意义：增强业务的可用性、扩展性、稳定性，可以支持更多用户的访问。 多端共用一套接口目前常见场景是一个业务，同时有PC页面和H5页面，由于业务是一样的，因此应避免同一个业务有多套接口分别适用于PC和H5端。 因此解决方案如下： 后端提供的接口，应该同时包含PC和H5的数据（即单独对一个存在亢余数据）； 接口应当稳定，即当业务变更时，应尽量采取追加数据的形式； 只有在单独一端需要特殊业务流程时，设计单端独有接口； 多端共用接口，是减少开发工作量，并且提高业务可维护性的重要解决方案。 意义：降低开发工作量，增强可维护性。 总结由于各个公司具体情况不同，项目也具有特殊性，因此以上设计不可强行套入，应根据自己公司规模、项目进展、人员数量等，先添加比较重要的功能和设计。并需要考虑到长期项目的可维护性和发展需要，对部分基础设施进行提前研发设计。 篇幅所限，因此无法面面俱到，只提了一些我认为比较重要的架构层面需要考虑的内容，欢迎大家补充。大家如果有自己的看法，欢迎回复。","categories":[{"name":"架构","slug":"架构","permalink":"https://www.toimc.com/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[]},{"title":"Redis-cli的常见操作","slug":"Redis数据库的常见操作","date":"2021-02-22T08:44:00.000Z","updated":"2021-03-02T14:48:20.153Z","comments":true,"path":"Redis数据库的常见操作/","link":"","permalink":"https://www.toimc.com/Redis%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/","excerpt":"本文主要介绍Redis及redis-cli的使用方式，介绍redis操作中的一些常见的命令。 分为以下几个部分介绍： docker中的redis如何进入命令模式 redis的常见命令及用法 有哪些比较好的redis连接工具","text":"本文主要介绍Redis及redis-cli的使用方式，介绍redis操作中的一些常见的命令。 分为以下几个部分介绍： docker中的redis如何进入命令模式 redis的常见命令及用法 有哪些比较好的redis连接工具 进入redis的命令模式以下实例讲解了如何启动 redis 客户端： 启动 redis 服务器，打开终端并输入命令redis-cli，该命令会连接本地的redis 服务。 12$ redis-cliredis 127.0.0.1:6379&gt; 如果我们是使用的docker启动的redis，那该怎么办呢？比如下图中的imooc-redis 我们可以使用如下的命令进入redis的命令模式： 方便复制： 1docker exec -it imooc-redis redis-cli 这里的imooc-redis可以换成自己的容器的名称如果自己的redis设置的密码，则输入命令后会出现如下提示： 那么可以使用auth命令进行登录鉴权： redis的常见命令及用法key操作命令获取所有键 语法：keys pattern 12127.0.0.1:6379&gt; keys *1) &quot;toimc&quot; *表示通配符，表示任意字符，会遍历所有键显示所有的键列表，时间复杂度O(n)，在生产环境不建议使用。 获取键总数 语法：dbsize 12127.0.0.1:6379&gt; dbsize(integer) 6 获取键总数时不会遍历所有的键，直接获取内部变量，时间复杂度O(1)。 查询键是否存在 语法：exists key [key …] 12127.0.0.1:6379&gt; exists toimc java(integer) 2 查询查询多个，返回存在的个数。 删除键 语法：del key [key …] 12127.0.0.1:6379&gt; del java toimc(integer) 1 可以删除多个，返回删除成功的个数。 查询键类型 语法： type key 12127.0.0.1:6379&gt; type toimcstring 移动键 语法：move key db 如把toimc移到2号数据库。 123456127.0.0.1:6379&gt; move toimc 2(integer) 1127.0.0.1:6379&gt; select 2OK127.0.0.1:6379[2]&gt; keys *1) &quot;toimc&quot; 查询key的生命周期（秒） 秒语法：ttl key毫秒语法：pttl key 12127.0.0.1:6379[2]&gt; ttl toimc(integer) -1 -1：永远不过期。 设置过期时间 秒语法：expire key seconds毫秒语法：pexpire key milliseconds 1234127.0.0.1:6379[2]&gt; expire toimc 60(integer) 1127.0.0.1:6379[2]&gt; ttl toimc(integer) 55 设置永不过期 语法：persist key 12127.0.0.1:6379[2]&gt; persist toimc(integer) 1 更改键名称 语法：rename key newkey 12127.0.0.1:6379[2]&gt; rename toimc toimc123OK 字符串操作命令字符串是Redis中最基本的数据类型，单个数据能存储的最大空间是512M。 存放键值 语法：set key value [EX seconds] [PX milliseconds] [NX|XX] nx：如果key不存在则建立，xx：如果key存在则修改其值，也可以直接使用setnx/setex命令。 12127.0.0.1:6379&gt; set toimc 666OK 获取键值 语法：get key 12127.0.0.1:6379[2]&gt; get toimc&quot;666&quot; 值递增/递减如果字符串中的值是数字类型的，可以使用incr命令每次递增，不是数字类型则报错。 语法：incr key 12127.0.0.1:6379[2]&gt; incr toimc(integer) 667 一次想递增N用incrby命令，如果是浮点型数据可以用incrbyfloat命令递增。同样，递减使用decr、decrby命令。 批量存放键值 语法：mset key value [key value …] 12127.0.0.1:6379[2]&gt; mset java1 1 java2 2 java3 3OK 获取获取键值 语法：mget key [key …] 123127.0.0.1:6379[2]&gt; mget java1 java21) &quot;1&quot;2) &quot;2&quot; Redis接收的是UTF-8的编码，如果是中文一个汉字将占3位返回。 获取值长度 语法：strlen key127.0.0.1:6379[2]&gt; strlen toimc(integer) 3 追加内容 语法：append key value 12127.0.0.1:6379[2]&gt; append toimc hi(integer) 5 向键值尾部添加，如上命令执行后由666变成666hi 获取部分字符 语法：getrange key start end 12&gt; 127.0.0.1:6379[2]&gt; getrange toimc 0 4&quot;javas&quot; 散列操作命令redis字符串类型键和值是字典结构形式，这里的散列类型其值也可以是字典结构。 存放键值 单个语法：hset key field value 12127.0.0.1:6379&gt; hset user name toimc(integer) 1 多个语法：hmset key field value [field value …] 12127.0.0.1:6379&gt; hmset user name toimc age 20 address chinaOK 不存在时语法：hsetnx key field value 12127.0.0.1:6379&gt; hsetnx user tall 180(integer) 0 获取字段值 单个语法：hget keyfield 12127.0.0.1:6379&gt; hget user age&quot;20&quot; 多个语法：hmget key field [field …] 1234127.0.0.1:6379&gt; hmget user name age address1) &quot;toimc&quot;2) &quot;20&quot;3) &quot;china&quot; 获取所有键与值语法：hgetall key 1234567127.0.0.1:6379&gt; hgetall user1) &quot;name&quot;2) &quot;toimc&quot;3) &quot;age&quot;4) &quot;20&quot;5) &quot;address&quot;6) &quot;china&quot; 获取所有字段语法：hkeys key 12345127.0.0.1:6379&gt; hkeys user1) &quot;name&quot;2) &quot;address&quot;3) &quot;tall&quot;4) &quot;age&quot; 获取所有值语法：hvals key 12345127.0.0.1:6379&gt; hvals user1) &quot;toimc&quot;2) &quot;china&quot;3) &quot;170&quot;4) &quot;20&quot; 判断字段是否存在 语法：hexists key field 12127.0.0.1:6379&gt; hexists user address(integer) 1 获取字段数量 语法：hlen key 12127.0.0.1:6379&gt; hlen user(integer) 4 递增/减 语法：hincrby key fieldincrement 12127.0.0.1:6379&gt; hincrby user tall -10(integer) 170 删除字段 语法：hdel key field [field …] 12127.0.0.1:6379&gt; hdel user age(integer) 1 数据库相关Redis数据库的数量是固定的，并在配置文件中设置。默认情况下，你有16个数据库。每个数据库都由一个数字（而不是名称）来标识。 你可以使用以下命令CONFIG````GET````data``b``as``e``s来了解数据库的数量： 123CONFIG GET databases1) &quot;databases&quot;2) &quot;16&quot; 也可以使用以下命令INFO或者INFO keyspace列出定义了某些键的数据库： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140INFO# Serverredis_version:5.0.8redis_git_sha1:00000000redis_git_dirty:0redis_build_id:ce75a617c591114fredis_mode:standaloneos:Linux 3.10.0-1062.4.1.el7.x86_64 x86_64arch_bits:64multiplexing_api:epollatomicvar_api:atomic-builtingcc_version:8.3.0process_id:1run_id:75ea4375ee7a6f41697f721e268d148dc8af24e8tcp_port:6379uptime_in_seconds:7316762uptime_in_days:84hz:10configured_hz:10lru_clock:2935552executable:&#x2F;data&#x2F;redis-serverconfig_file:​# Clientsconnected_clients:4client_recent_max_input_buffer:2client_recent_max_output_buffer:0blocked_clients:0​# Memoryused_memory:925608used_memory_human:903.91Kused_memory_rss:12644352used_memory_rss_human:12.06Mused_memory_peak:3896552used_memory_peak_human:3.72Mused_memory_peak_perc:23.75%used_memory_overhead:892348used_memory_startup:791296used_memory_dataset:33260used_memory_dataset_perc:24.76%allocator_allocated:917808allocator_active:1163264allocator_resident:3743744total_system_memory:16637751296total_system_memory_human:15.50Gused_memory_lua:37888used_memory_lua_human:37.00Kused_memory_scripts:0used_memory_scripts_human:0Bnumber_of_cached_scripts:0maxmemory:0maxmemory_human:0Bmaxmemory_policy:noevictionallocator_frag_ratio:1.27allocator_frag_bytes:245456allocator_rss_ratio:3.22allocator_rss_bytes:2580480rss_overhead_ratio:3.38rss_overhead_bytes:8900608mem_fragmentation_ratio:14.31mem_fragmentation_bytes:11760736mem_not_counted_for_evict:0mem_replication_backlog:0mem_clients_slaves:0mem_clients_normal:100460mem_aof_buffer:0mem_allocator:jemalloc-5.1.0active_defrag_running:0lazyfree_pending_objects:0​# Persistenceloading:0rdb_changes_since_last_save:7989rdb_bgsave_in_progress:0rdb_last_save_time:1606231526rdb_last_bgsave_status:okrdb_last_bgsave_time_sec:-1rdb_current_bgsave_time_sec:-1rdb_last_cow_size:0aof_enabled:0aof_rewrite_in_progress:0aof_rewrite_scheduled:0aof_last_rewrite_time_sec:-1aof_current_rewrite_time_sec:-1aof_last_bgrewrite_status:okaof_last_write_status:okaof_last_cow_size:0​# Statstotal_connections_received:4006total_commands_processed:81735instantaneous_ops_per_sec:0total_net_input_bytes:3084119total_net_output_bytes:22777832instantaneous_input_kbps:0.00instantaneous_output_kbps:0.00rejected_connections:0sync_full:0sync_partial_ok:0sync_partial_err:0expired_keys:759expired_stale_perc:0.00expired_time_cap_reached_count:0evicted_keys:0keyspace_hits:63631keyspace_misses:2192pubsub_channels:0pubsub_patterns:0latest_fork_usec:0migrate_cached_sockets:0slave_expires_tracked_keys:0active_defrag_hits:0active_defrag_misses:0active_defrag_key_hits:0active_defrag_key_misses:0​# Replicationrole:masterconnected_slaves:0master_replid:7e9137e98814fa2b756aff0e339de997cc1309a1master_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0​# CPUused_cpu_sys:8093.459923used_cpu_user:4547.190025used_cpu_sys_children:0.011915used_cpu_user_children:0.003634​# Clustercluster_enabled:0​# Keyspacedb0:keys&#x3D;7,expires&#x3D;1,avg_ttl&#x3D;177400 查看单个片区： 12345INFO keyspace# Keyspacedb0:keys&#x3D;10,expires&#x3D;0db1:keys&#x3D;1,expires&#x3D;0db3:keys&#x3D;1,expires&#x3D;0 或者使用redis的GUI工具来查看： 推荐redis学习文档更多redis的命令可以参考如下网址： [1] http://doc.redisfans.com/ [2] http://www.redis.cn/","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.toimc.com/tags/Redis/"},{"name":"redis-cli","slug":"redis-cli","permalink":"https://www.toimc.com/tags/redis-cli/"}]},{"title":"windows10家庭版如何添加Hyper-V","slug":"windows10家庭版如何添加Hyper-V","date":"2021-02-22T08:22:45.000Z","updated":"2021-03-02T14:48:20.154Z","comments":true,"path":"windows10家庭版如何添加Hyper-V/","link":"","permalink":"https://www.toimc.com/windows10%E5%AE%B6%E5%BA%AD%E7%89%88%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0Hyper-V/","excerpt":"本文是《大前端》配套介绍图文内容，主要是介绍如何在windows10家庭版如何添加Hyper-V","text":"本文是《大前端》配套介绍图文内容，主要是介绍如何在windows10家庭版如何添加Hyper-V 一、查看电脑是否能运行 Hyper-V打开 cmd 窗口输入命令 “systeminfo” ，查看系统信息中的 Hyper-V要求或者 Win + R 快捷键调出运行对话框，输入 “msinfo32” ，打开系统信息窗口，查看 Hyper-V 要求 Hyper-V - 虚拟机监视模式扩展Hyper-V - 第二级地址转换扩展Hyper-V - 固件中启用的虚拟化Hyper-V - 数据扩展保护 这四项必须全部为“是”，你的电脑才能运行 Hyper-V 虚拟机。 其中固件中启用虚拟化有可能默认是关闭的，首先确认下电脑 CPU 支不支持虚拟化， 如何确认电脑是否支持虚拟化？——参考微软官方文档：https://docs.microsoft.com/zh-cn/virtualization/hyper-v-on-windows/reference/hyper-v-requirements windows的同学可以打开【任务管理器】，切换到【性能】选项卡，在【CPU】一栏的右方就可以看到： 还不知道如何设置的，可以找官网论坛、客服啊，问问。一般现在的电脑都是默认支持的。如果支持，你就可以在 BIOS 设置开启虚拟化，步骤简单，但是不同主板型号进入 BIOS 方式不同，具体度娘都可以完美解决。可以参考： https://www.huaweicloud.com/articles/6db932c231bbfd41a2cf1bc34fca960c.html 步骤： 支持虚拟化技术的可以在BIOS中开启，开启方法如下： 进入BIOS。开机时按F2或F12或DEL或ESC等键（各电脑有所不同）。 进入BIOS后，找到Configuration选项，选择Intel Virtual Technology并回车，将光标移至Enabled，然后再回车，最后按F10保存并退出。 如果找不到Configuration选项，可以试试下面的方法： 某些HP（惠普）电脑进入BIOS后，需要选择SystemConfiguration（系统配置）菜单，然后选择Device Configuration（设备配置），找到Virtualization Technology，设置为Enabled。 某些联想Thinkpad电脑进入BIOS后，需要选择Security菜单，然后选择Virtualization，设置为Enabled。 某些DELL（戴尔）电脑进入BIOS后，需要选择Processor Settings菜单，然后选择VirtualizationTechnology，设置为Enabled。二、添加 Hyper-V 如果你的系统是 WIN10 专业版/企业版 打开 控制面板 -&gt; 程序和功能 -&gt; 启用或关闭Windows功能，勾选 Hyper-V 相关选项，确认，等待配置，提示重启，添加完成 如果你的系统是 WIN10 家庭版： 新建记事本，复制以下命令，后缀改为 .bat 或 .cmd，以管理员身份运行 12345pushd &quot;%~dp0&quot;dir &#x2F;b %SystemRoot%\\servicing\\Packages\\*Hyper-V*.mum &gt;hyper-v.txtfor &#x2F;f %%i in (&#39;findstr &#x2F;i . hyper-v.txt 2^&gt;nul&#39;) do dism &#x2F;online &#x2F;norestart &#x2F;add-package:&quot;%SystemRoot%\\servicing\\Packages\\%%i&quot;del hyper-v.txtDism &#x2F;online &#x2F;enable-feature &#x2F;featurename:Microsoft-Hyper-V-All &#x2F;LimitAccess &#x2F;ALL 命令处理完成后，输入 “Y” 确认重启，进行配置更新添加 Hyper-V 完成顺便说一下，Hyper-V 目前比较完美支持 Windows、Linux 等系统，不太支持苹果等系统，除了 Hyper-V 也可以试试其他软件，比如 VMWare 等。","categories":[],"tags":[{"name":"Hyper-V","slug":"Hyper-V","permalink":"https://www.toimc.com/tags/Hyper-V/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://www.toimc.com/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"}]},{"title":"Vue3中令人兴奋的新功能","slug":"Vue3中令人兴奋的新功能","date":"2020-03-12T16:44:45.000Z","updated":"2020-12-01T02:33:05.214Z","comments":true,"path":"Vue3中令人兴奋的新功能/","link":"","permalink":"https://www.toimc.com/Vue3%E4%B8%AD%E4%BB%A4%E4%BA%BA%E5%85%B4%E5%A5%8B%E7%9A%84%E6%96%B0%E5%8A%9F%E8%83%BD/","excerpt":"在上一篇文章中，我们了解了Vue 3将带来的性能改进。我们已经知道用新的Vue编写的应用程序性能炸裂（运行非常好），但性能并不是最重要的部分。对我们开发人员而言最重要的是，新版本将如何影响我们编写代码的方式。 如今，Vue 3带来了许多令人兴奋的新功能。 值得庆幸的是，Vue团队主要介绍了对当前API的添加和改进，而不是进行重大更改，因此，已经了解Vue 2的大家应该会非常习惯这些变化。 让我们从大多数人可能听说过的API开始…","text":"在上一篇文章中，我们了解了Vue 3将带来的性能改进。我们已经知道用新的Vue编写的应用程序性能炸裂（运行非常好），但性能并不是最重要的部分。对我们开发人员而言最重要的是，新版本将如何影响我们编写代码的方式。 如今，Vue 3带来了许多令人兴奋的新功能。 值得庆幸的是，Vue团队主要介绍了对当前API的添加和改进，而不是进行重大更改，因此，已经了解Vue 2的大家应该会非常习惯这些变化。 让我们从大多数人可能听说过的API开始… 合成API（Composition API）组合API是Vue的下一个主要版本中最常用的讨论和特色语法。这是一种全新的逻辑重用和代码组织方法。 当前，我们使用所谓的Options API构建组件。现在，添加到Vue组件的逻辑通常会采用：如data，methods，computed等这种方法，最大缺点是这是不JavaScript代码原生方式。您需要确切了解模板中可以访问哪些属性，以及this关键字的行为。在后台，Vue编译器需要将此属性转换为工作代码。因此，我们无法通过从自动建议或类型检查中受益（而大家想一想Typescript，马上就会明白了）。 Composition API旨在，通过将组件属性中当前可用的机制公开为JavaScript函数来解决此问题。Vue核心团队将Composition API描述为“一组基于功能的附加API，可以灵活地组合组件逻辑”。用Composition API编写的代码更具可读性，并且都是原生JS，这使它更易于阅读和学习。 让我们来看一个使用新的Composition API理解其工作原理的组件的简单示例。 12345678910111213141516171819202122232425262728&lt;template&gt; &lt;button @click=&quot;increment&quot;&gt; Count is: &#123;&#123; count &#125;&#125;, double is &#123;&#123; double &#125;&#125;, click to increment. &lt;/button&gt;&lt;/template&gt;&lt;script&gt;import &#123; ref, computed, onMounted &#125; from &#x27;vue&#x27;export default &#123; setup() &#123; const count = ref(0) const double = computed(() =&gt; count.value * 2) function increment() &#123; count.value++ &#125; onMounted(() =&gt; console.log(&#x27;component mounted!&#x27;)) return &#123; count, double, increment &#125; &#125;&#125;&lt;/script&gt; 现在，让我们将此代码分解为几部分，以了解发生了什么 1import &#123; ref, computed, onMounted &#125; from &#x27;vue&#x27; 正如之前提到的，Composition API将组件属性公开为函数，因此第一步是导入所需的函数。当前情况下，我们需要使用创建反应式引用ref，使用计算属性创建computed和使用访问生命周期挂钩onMounted。 现在，你可能想知道这种神秘的setup方法是什么？ 12export default &#123; setup() &#123; 简而言之，它只是一个将属性和函数返回到模板的函数，而已。我们在这里声明所有反应性属性、计算属性、观察者和生命周期挂钩，然后将它们返回，以便可以在模板中使用它们。 我们没有从setup函数返回的内容将在模板中不可用。 1const count = ref(0) 根据以上内容，我们声明了响应式的count用ref函数调用，它可以包装任何类型参数或对象，并返回其双向引用，传递的元素的值将保留在value创建的引用的属性中。例如，如果要访问count参考值，则需要明确要求count.value。 12345const double = computed(() =&gt; count.value * 2)function increment() &#123; count.value++&#125; …这正是我们在声明计算属性double以及increment函数时所做的事情。 1onMounted(() =&gt; console.log(&#x27;component mounted!&#x27;)) 使用onMounted钩子，我们会在安装组件时记录一些消息。 12345return &#123; count, double, increment&#125; 最后，我们返回count和double属性with increment方法，以使它们在模板中可用。 12345&lt;template&gt; &lt;button @click=&quot;increment&quot;&gt; Count is: &#123;&#123; count &#125;&#125;, double is &#123;&#123; double &#125;&#125;. Click to increment. &lt;/button&gt;&lt;/template&gt; 现在，我们可以访问setup模板中方法返回的属性和函数，就像通过旧的Options API声明它们一样。 这是一个简单的示例，也可以通过Options API轻松实现。 新的Composition API的修改了编码方式，加强了在重用我们的代码/逻辑时代码块复用性。 使用Composition API进行代码重用 新的Composition API具有更多优点，比如：代码复用。当前，如果我们要在其他组件之间共享一些代码，则有两个可用选项mixins和作用域插槽。两者都有缺点。 假设我们要提取counter功能并将其在其他组件中复用。在下面，您可以看到如何将其与可用的API和新的Composition API结合使用： 让我们从mixins开始： 12345import CounterMixin from &#x27;./mixins/counter&#x27;export default &#123; mixins: [CounterMixin]&#125; mixins的最大缺点是：我们对它实际上添加到我们的组件中一无所知。这不仅使推理变得困难，而且还可能导致名称与现有属性和功能发生冲突。 现在该是作用域插槽了。 123456&lt;template&gt; &lt;Counter v-slot=&quot;&#123; count, increment &#125;&quot;&gt; &#123;&#123; count &#125;&#125; &lt;button @click=&quot;increment&quot;&gt;Increment&lt;/button&gt; &lt;/Counter&gt; &lt;/template&gt; 使用作用域插槽，我们确切地知道可以通过v-slot属性访问哪些属性，因此更容易理解代码。这种方法的缺点是：我们只能在模板中访问它，并且仅在Counter组件范围内可用。 现在是时候使用Composition API了： 12345678910111213141516171819function useCounter() &#123; const count = ref(0) function increment () &#123; count.value++ &#125; return &#123; count, incrememt &#125;&#125;export default &#123; setup () &#123; const &#123; count, increment &#125; = useCounter() return &#123; count, increment &#125; &#125;&#125; 是不是更优雅？我们不受模板和组件范围的限制，并且确切地知道可以从计数器访问哪些属性。另外，我们可以从编辑器中可用的代码完成中受益，因为useCounter它只是一个返回某些属性的函数。幕后没有魔力，因此编辑器可以帮助我们进行类型检查和建议。 这也是使用第三方库的一种更优雅的方式。例如，如果我们要使用Vuex，则可以显式使用useStore函数而不是污染Vue原型（this.$store）。这种方法还可以消除Vue插件的幕后魔力。 1const &#123; commit, dispatch &#125; = useStore() 如果您想了解有关Composition API及其用例的更多信息，我强烈建议您从Vue团队阅读此文档，该文档解释了新API背后的原因并提出了最佳用例。Vue核心团队的ThorstenLünborg 还提供了一个很棒的存储库，其中包含Composition API使用示例。 全局安装/配置API更改我们可以在实例化和配置应用程序的方式上找到另一个重大变化。让我们看看它现在如何工作： 123456789101112import Vue from &#x27;vue&#x27;import App from &#x27;./App.vue&#x27;Vue.config.ignoredElements = [/^app-/]Vue.use(/* ... */)Vue.mixin(/* ... */)Vue.component(/* ... */)Vue.directive(/* ... */)new Vue(&#123; render: h =&gt; h(App)&#125;).$mount(&#x27;#app&#x27;) 当前，我们正在使用全局Vue对象提供任何配置并创建新的Vue实例。对Vue对象所做的任何更改都会影响每个Vue实例和组件。 现在，让我们看看它如何在Vue 3中运行： 123456789101112import &#123; createApp &#125; from &#x27;vue&#x27;import App from &#x27;./App.vue&#x27;const app = createApp(App)app.config.ignoredElements = [/^app-/]app.use(/* ... */)app.mixin(/* ... */)app.component(/* ... */)app.directive(/* ... */)app.mount(&#x27;#app&#x27;) 您可能已经注意到，每个配置都限于使用定义的某个Vue应用程序createApp。 它可以使您的代码更易于理解，并且不易出现由第三方插件引起的意外问题。当前，如果某些第三方解决方案正在修改Vue对象，则它可能以意想不到的方式（尤其是全局混合）影响您的应用程序，而Vue 3则无法实现。 当前在此RFC 中讨论了此API更改，这意味着将来可能会更改。 碎片（Fragments）我们可以在Vue 3中期待的另一个激动人心的附加功能是片段。 您可能会问什么碎片？好吧，如果您创建一个Vue组件，则它只能有一个根节点。 这意味着无法创建这样的组件： 1234&lt;template&gt; &lt;div&gt;Hello&lt;/div&gt; &lt;div&gt;World&lt;/div&gt;&lt;/template&gt; 原因是代表任何Vue组件的Vue实例都需要绑定到单个DOM元素中。创建具有多个DOM节点的组件的唯一方法是通过创建不具有基础Vue实例的功能组件。 事实证明，React社区也有同样的问题。他们提出的解决方案是一个名为Fragment的虚拟元素。看起来或多或少是这样的； 12345678910class Columns extends React.Component &#123; render() &#123; return ( &lt;React.Fragment&gt; &lt;td&gt;Hello&lt;/td&gt; &lt;td&gt;World&lt;/td&gt; &lt;/React.Fragment&gt; ); &#125;&#125; 即使Fragment看起来像一个普通的DOM元素，它也是虚拟的，根本不会在DOM树中呈现。这样，我们可以将组件功能绑定到单个元素中，而无需创建冗余DOM节点。 当前，您可以在带有vue-fragments库的Vue 2中使用片段，而在Vue 3中，您可以立即使用它！ Suspense组件React生态系统中另一个将在Vue 3中采用的好主意是Suspense组件。 挂起将挂起组件渲染并渲染回退组件，直到满足条件为止。在Vue London Evan期间，您简短地谈到了这个主题，并向我们展示了我们可以期望的API。事实证明，Suspense只是具有插槽的组件： 12345678&lt;Suspense&gt; &lt;template &gt; &lt;Suspended-component /&gt; &lt;/template&gt; &lt;template #fallback&gt; Loading... &lt;/template&gt;&lt;/Suspense&gt; 后备内容将一直显示到Suspended-component完全渲染为止。挂起可以等待，直到该组件被下载（如果这是一个异步组件），或者在setup功能上执行一些异步操作。 多个v-model同时使用v-model是一种指令，可用于在给定组件上实现双向绑定。我们可以传递反应性属性并从组件内部对其进行修改。 我们v-model从表单元素非常了解： 1&lt;input v-model=&quot;property /&gt; 但是您知道您可以使用v-model每个组件吗？内幕v-model只是传递value属性和侦听input事件的捷径。将以上示例重写为以下语法将具有完全相同的效果： 1234&lt;input v-bind:value=&quot;property&quot; v-on:input=&quot;property = $event.target.value&quot;/&gt; 我们甚至可以使用components model属性更改默认属性和事件的名称： 1234model: &#123; prop: &#x27;checked&#x27;, event: &#x27;change&#x27;&#125; 正如上面所示，vue2.x中采用v-model时，如果我们希望在组件中进行双向绑定，那么伪指令可能是一个非常有用的语法求和者。不幸的是，v-model每个组件只能有一个组件。 幸运的是，在Vue 3中这不会成为问题！您将能够提供v-model属性名称，并根据需要拥有任意数量的属性。在下面，您可以v-model在表单组件中找到两个的示例： 1234&lt;InviteeForm v-model:name=&quot;inviteeName&quot; v-model:email=&quot;inviteeEmail&quot;/&gt; 当前在此RFC 中讨论了此API更改，这意味着将来可能会更改。 Portals组件（魔法提示类组件）Portals是特殊的组件，旨在在当前组件之外呈现某些内容。这也是React本身实现的功能之一(https://pl.reactjs.org/docs/portals.html)。这就是React文档关于门户的内容： “Portals provide a first-class way to render children into a DOM node that exists outside the DOM hierarchy of the parent component.“ 这是处理模态框、弹出窗口和通常显示在页面顶部的组件的一种非常好的方法。通过使用Portals，您可以确保没有任何主机组件CSS规则，会影响您要显示的组件，并使您免于使用进行讨厌的黑客攻击z-index。 对于每个门户，我们需要指定它的目标目标，在其中将呈现提示类型内容。在下面，您可以看到portal-vue库的实现，该实现将此功能添加到Vue 2： 1234567891011&lt;portal to=&quot;destination&quot;&gt; &lt;p&gt;This slot content will be rendered wherever thportal-target with name &#x27;destination&#x27; is located.&lt;/p&gt;&lt;/portal&gt;&lt;portal-target name=&quot;destination&quot;&gt; &lt;!-- This component can be located anywhere in your App. The slot content of the above portal component wilbe rendered here. --&gt;&lt;/portal-target&gt; Vue 3将附带对门户的开箱即用支持！ 新的自定义指令API自定义指令API在Vue 3中将略有变化，以更好地与组件生命周期保持一致。这项更改将使API更加直观，从而使新手更容易理解和学习API。 这是当前的自定义指令API： 1234567const MyDirective = &#123; bind(el, binding, vnode, prevVnode) &#123;&#125;, inserted() &#123;&#125;, update() &#123;&#125;, componentUpdated() &#123;&#125;, unbind() &#123;&#125;&#125; ……这就是Vue 3中的样子。 12345678const MyDirective = &#123; beforeMount(el, binding, vnode, prevVnode) &#123;&#125;, mounted() &#123;&#125;, beforeUpdate() &#123;&#125;, updated() &#123;&#125;, beforeUnmount() &#123;&#125;, // new unmounted() &#123;&#125;&#125; 即使这是一项重大更改，也应该使用Vue兼容性构建轻松涵盖。 当前在此RFC 中讨论了此API更改，这意味着将来可能会更改。 摘要除了Composition API（它是Vue 3中最大的主要新API）之外，我们还可以找到很多较小的改进。我们可以看到，Vue正在朝着更好的开发人员体验和更简单，更直观的API迈进。也很高兴看到Vue团队决定采用许多想法，而这些想法目前只能通过第三方库提供给框架的核心。 上面的列表仅表示主要的API更改和改进。如果您对其他应用程序感到好奇，可以看一下Vue RFCs存储库。。","categories":[],"tags":[{"name":"Vue3","slug":"Vue3","permalink":"https://www.toimc.com/tags/Vue3/"},{"name":"Vuejs","slug":"Vuejs","permalink":"https://www.toimc.com/tags/Vuejs/"}]},{"title":"Vue3将带来巨大的性能提升","slug":"Vue3将带来巨大的性能提升","date":"2020-03-12T16:11:04.000Z","updated":"2021-03-02T15:36:52.405Z","comments":true,"path":"Vue3将带来巨大的性能提升/","link":"","permalink":"https://www.toimc.com/Vue3%E5%B0%86%E5%B8%A6%E6%9D%A5%E5%B7%A8%E5%A4%A7%E7%9A%84%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87/","excerpt":"即将发布的Vue.js的第三个主要版本。 通过下面的讨论，虽然还不能确定所有内容，但是我们可以放心地认为，它将是对当前版本（已经非常出色）的巨大改进。Vue团队在改进框架API方面做得非常出色。Evan You将Vue 3的目标描述为： 让它更快 让它更小 使它更易于维护 使原生目标更容易 让您的生活更轻松 通过查看RFC，我确信上述所有目标都将毫无问题地实现。在本文中，我将引导您完成一些对我来说最有趣的更改，这些更改对我的影响和可能性而言。","text":"即将发布的Vue.js的第三个主要版本。 通过下面的讨论，虽然还不能确定所有内容，但是我们可以放心地认为，它将是对当前版本（已经非常出色）的巨大改进。Vue团队在改进框架API方面做得非常出色。Evan You将Vue 3的目标描述为： 让它更快 让它更小 使它更易于维护 使原生目标更容易 让您的生活更轻松 通过查看RFC，我确信上述所有目标都将毫无问题地实现。在本文中，我将引导您完成一些对我来说最有趣的更改，这些更改对我的影响和可能性而言。 性能优化在探究某些API之前，作为性能怪胎，我想谈一谈Vue 3的性能。还有很多事情要讨论！我们几乎可以在每个表面上找到明显的改进！ 让我们从Vue 3的捆绑包大小开始。 当前最小化和压缩的Vue运行时权重约为20kB（当前2.6.10版本为22.8kB）。Vue 3捆绑包估计重约一半，因此只有〜10kB！ 全局API分块（Tree Shake机制）诸如更好的模块化之类的许多其他优化之上，Vue 3源代码将加入tree-shake。这意味着，如果您不使用其某些功能（例如component或者v-show指令），它们将不会包含在您的基础包中。 当前，无论我们从Vue核心使用什么功能，它们最终都会出现在生产代码中，因为Vue实例被导出为单个对象，并且捆绑程序无法检测到该对象的哪些属性在代码中使用。 12345 // Vue 2.x - whole `Vue` object is bundled for production import Vue from &#x27;vue&#x27;Vue.nextTick(() =&gt; &#123;&#125;)const obj = Vue.observable(&#123;&#125;) 为了使全局API可以进行代码分块，Vue团队决定通过命名导出导入其中的大多数方法，以便捆绑程序可以检测和删除未使用的代码： 12345 // Vue 3.x - only imported properties are bundledimport &#123; nextTick, observable &#125; from &#x27;vue&#x27;nextTick(() =&gt; &#123;&#125;)const obj = observable(&#123;&#125;) 这是一个重大变化，因为以前的全局API现在只能通过命名的导出才能使用。此更改影响： Vue.nextTick Vue.observable Vue.version Vue.compile （仅完整版本） Vue.set （仅在2.x兼容版本中，您很快会找到原因） Vue.delete （同上） 我们需要一段时间才能完全受益于此功能，因为它需要在生态系统中采用。Vue团队将发布兼容性版本，因此我们应该能够使用也使用旧API的插件，但会降低性能。 除了tree shake的JavaScript API以外，还有很多其他功能。在后台，Vue编译器（将Vue模板转换为呈现功能的工具）将检测模板中使用的指令，并对其进行树状摇动。例如下面的模板： 123&lt;transition&gt; &lt;div v-show=&quot;ok&quot;&gt;hello&lt;/div&gt;&lt;/transition&gt; 在被Vue编译器处理后，看起来或多或少是这样的： 1234567import &#123; h, Transition, applyDirectives, vShow &#125; from &#x27;vue&#x27;export function render() &#123; return h(Transition, [ applyDirectives(h(&#x27;div&#x27;, &#x27;hello&#x27;), this, [vShow, this.ok]) ])&#125; 每个人都会从Global API tree shake中受益（尤其是我们的用户），但是我认为制作小型轻量级网站，比如：仅使用Vue功能子集进行交互的人（最能替代jQuery之类的库）的人。 基于代理的响应式机制捆绑包的大小可能会严重影响您的应用加载时间，但是下载后，捆绑包的大小也应能够快速呈现且运行流畅。 Vue核心团队非常了解这一点，这就是为什么我们在运行时性能上也有很大改进的原因。 让我们从基于JavaScript Proxies的最具影响力的新反应系统之一开始。当前的Vue反应系统是基于的Object.defineProperty，这有一些限制。最常见和令人沮丧的一个事实是Vue 无法跟踪反应对象的属性添加/删除。为此，我们需要使用Vue.set并Vue.delete保持反应系统正常运行。使用JS Proxies，我们终于可以摆脱这种丑陋的解决方法。 1234// Adding a new property to reacitve object in Vue 2.xVue.set(this.myObject, key, value) // Adding a new property to reactive object in Vue 3this.myObject[key] = value 代理的真正影响可以从更快的组件初始化和修补中看出。根据测试，速度大约快2倍！ 由于以下事实，这种改进的原因尤为重要，那就是Vue必须使用吸气剂/设置剂来递归地遍历所有对象及其属性并对其进行转换。使用代理，此过程变得容易得多。 值得一提的是，使用JS Proxies Vue 3会放弃对Internet Explorer（不是Edge）的支持，但是请不要担心-对于希望支持IE的用户来说，将会建立兼容的版本。 时间分片根据Evan You的推文更新此功能不会包含在Vue 3中。 Vue 3的另一个真正令人兴奋但很少提及的性能功能是对时间切片的实验支持。 我将用一个隐喻来解释什么是时间切片，我想让你想象一条冰淇淋生产线，很长的一个，因为那是镇上最好的冰淇淋。提供一个人之后，就会出现另一个人，等等。由于某种原因，没有关于可用口味的信息。要获取此信息，您需要询问直接出售冰淇淋的女士。 在这种情况下，我们可能最终会得到2条记录-其中一条给确信要购买冰淇淋的人（耐心等待），另一条给希望了解有关口味的更多信息的人，然后再决定是否要购买冰淇淋或不，最新的应该尽快获得此信息。不幸的是，只有一位女士在卖冰淇淋，她在为“主”线上的所有客户提供服务之前不会回答任何问题。 对于尚未被说服的客户来说，这并不是最好的体验，他们中的大多数人可能会发现不值得等待。为了解决这个问题，这位女士可以每2-3个服务对象回答一次问题。两组都应该对此解决方案感到满意。 这正是CPU与Web应用程序一起工作的方式。我们有一条“主”行（称为“主线程”），需要完成其所有主要任务（脚本，渲染等），然后才能响应用户交互。对于某些页面，这可能会导致非常糟糕的用户体验，具体取决于Vue组件加载或重新呈现所需的时间。 为了使其更可靠，最好将此脚本评估“切割”成碎片，然后查看每个脚本之后是否有要处理的用户输入。这样，无论需要进行多少次渲染或重新渲染，应用程序都将保持响应状态。这就是在Vue 3中的工作方式。 这是Evan在Vue 3中展示时间分片功能的方式。请注意脚本执行时间轴中的小间隙，这些间隙旨在处理用户输入。 能够轻松识别为什么重新渲染组件工具与开箱即用的性能同等重要。 据此，我们可以在Vue 3中看到一个新的生命周期挂钩-renderTriggered。我们可以使用它来跟踪和消除不必要的组件重新渲染，当将其与Time Slicing结合使用时，这是在运行时性能优化中非常强大的武器。 123456const Component = &#123; // other properties renderTriggered (event) &#123; console.log(`Re-render of ` + this.$options.name + ` component`, event) &#125;&#125; 还有什么除了上面在Vue 3中看到的内容以外，还有很多内容，但是这些可能是影响最大的更改。大多数未提及的改进将隐藏在Vue编译器生成的代码中，或者与实现细节和算法绑定在一起 不过，有几项改进值得一提： 输出代码将更易于针对JavaScript编译器进行优化 输出代码通常会更好地进行优化 由于改进了补丁算法，可以避免不必要的父母/孩子重新渲染 另外，在接下来的几天里，您可以期待Evan You撰写的一篇深入的文章，介绍他们专门针对Vue编译器进行的性能优化（一旦发布，我将使用链接更新该文章）。 摘要尽管Vue已经确立为目前性能最佳的框架之一，但我们仍将在第三版中看到重大改进。特别是在捆绑包大小和运行时性能方面，还进行了无数次微优化。我认为Vue 3非常适合现代移动优先和性能导向的网络。 不要忘记Vue是唯一由社区完全驱动的主要框架。这篇文章（以及更多）中列出的所有变化都在RFC社区讨论。您可以帮助核心团队，表达您对有效RFC的意见，甚至可以提出自己的改进建议。让我们一起让Vue更好。 下一步是什么在下一篇文章中，我们将探讨新的Vue 3 API将如何影响我们编写Web应用程序的方式。我们将研究各种API，包括最近流行的Composition API，并了解如何使用它编写更好和更可维护的代码。 原文：[Exciting new features in Vue 3](https://vueschool.io/articles/vuejs-tutorials/exciting-new-features-in-vue-3/?utm_source=drip&amp;utm_medium=email&amp;utm_campaign=My+presentation+on+the+new+Vue+3+features&amp;utm_campaign=My presentation on the new Vue 3 features&amp;utm_medium=email&amp;utm_source=drip)","categories":[],"tags":[{"name":"Vue3","slug":"Vue3","permalink":"https://www.toimc.com/tags/Vue3/"},{"name":"Vue","slug":"Vue","permalink":"https://www.toimc.com/tags/Vue/"}]},{"title":"引领未来，走出自己的前端之路","slug":"引领未来，走出自己的前端之路","date":"2019-12-27T08:36:38.000Z","updated":"2021-03-02T15:36:20.104Z","comments":true,"path":"引领未来，走出自己的前端之路/","link":"","permalink":"https://www.toimc.com/%E5%BC%95%E9%A2%86%E6%9C%AA%E6%9D%A5%EF%BC%8C%E8%B5%B0%E5%87%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%89%8D%E7%AB%AF%E4%B9%8B%E8%B7%AF/","excerpt":"在今天开始分享之前，我来说一下这一次分享的准备，我开始问了我的很多学生，比如：讲什么选题、大家想听什么、大家觉得学习了前端这么久想听听什么….很多的问题，都集中在一个问题上，这么多的未知，这么多的技术，我该怎么办？这就像是一个哲学问题，问“我从哪里来，我要到哪里去”一样——人生这一躺旅程，如果想不清楚前路，那最最关键的是抓住现在。老师，最多只是引路人是灯塔，自己的路要靠自己的脚走出来。","text":"在今天开始分享之前，我来说一下这一次分享的准备，我开始问了我的很多学生，比如：讲什么选题、大家想听什么、大家觉得学习了前端这么久想听听什么….很多的问题，都集中在一个问题上，这么多的未知，这么多的技术，我该怎么办？这就像是一个哲学问题，问“我从哪里来，我要到哪里去”一样——人生这一躺旅程，如果想不清楚前路，那最最关键的是抓住现在。老师，最多只是引路人是灯塔，自己的路要靠自己的脚走出来。 前言在今天开始分享之前，我来说一下这一次分享的准备，我开始问了我的很多学生，比如：讲什么选题、大家想听什么、大家觉得学习了前端这么久想听听什么….很多的问题，都集中在一个问题上，这么多的未知，这么多的技术，我该怎么办？这就像是一个哲学问题，问“我从哪里来，我要到哪里去”一样——人生这一躺旅程，如果想不清楚前路，那最最关键的是抓住现在。老师，最多只是引路人是灯塔，自己的路要靠自己的脚走出来。 一、路在何方——前端千变万化，如何不变应万变 相信大家都有选择技术的一个理由，但是更多是迷茫。对知识的渴望，加上工作的压力，让这种求学的心情变得迫切。每当有同学问我，老师，我该不该学前端、前端难不难、前端怎么学的时候，我都会问他（她）这样一个问题：你喜欢不喜欢技术？ 对于那些模棱两可的人，我会给他们泼冷水，告诉他们：“前端天天都在变化，你会每天坚持学习吗？”“前端不是人人都能高薪，你能接受生活给你的磨砺，忍辱负重的成长吗？”“前端说简单也简单，说难也难，你的目标在哪里，你的高度才会有多高”…. 前端真的是千变万化，前两年还在JQuery，到今年的时候，我问同事，他说现有的项目（React）已经不用了，很少需要用JQ来操作DOM；再前些年，还在用DW、PS切页面，现在还流行吗？不流行了，因为效率不高…一方面技术过时的快，另一方面新技术的出现快，Flutter、WebAssembly、Serverless火爆发展，对前端人的要求在变高，需要学习各种技术，对接不同的角色的人，甚至去充当不同角的人…那么，就要有全面的知识储备与技能。大前端，需要的是宽阔的视野、扩展的能力、基础的技能，同学们不缺的是第三块，而扩展和视野是同学们缺的，也很少去思考的。 那怎么办？ 在我的课程中说到过一个观念：不推荐大家学习红宝书，不是一定在大厂才有优秀的人。这两点如果没有深刻体会的人，我来举两个例子：你看看你的周围有没有进步非快的人，再看看你下载的那些资料、买过的那些书&amp;视频的进度，你就初步体会这两点的涵义了。学习，是一个延迟满足非常长的事情，需要有一颗平常心来对待每天的学习&amp;工作。 记住，平常心，三个字。 有句话大家都听过，“机会是给有准备的人”。这句话，要辩证的来看，这个准备是指心态上的准备，很多技术是可以现学现卖的，这才是核心。举个例子，我给大家来讲课，学习了FCP只用了一周，就上手开始剪了，实践让我获得了大量的“真知”…这种事情在我身上发生了很多次。那些追求极致完美的“处女座”同学们，很多东西在一开始，不用学习的那种的精巧，设计的那么的完美。这其实是人的本性啊，人不是圣人，肯定会犯错。但是，辩证的看，同样的不能一开始全部都马马虎虎，这两个极端都不可取。 记住，辩证，这两个字。 路在何方？就像那首歌一样的，路在自己的脚下。有同学就跳跳出来了，说，老师你说了一句废话。我现在即不能说，未来5年，大家来学什么什么就能发大财行大运、XXX技术就能火、XXX能学XXX不能学，适合自己的才是最好的不是吗？我也是一路寻找，走了2年的弯路，才找自己自己的兴趣。生命中，总有那么多的奇迹让我们感动，就像小时候不明白父母的苦，只有自己成为父母，才能感受到。这不就是生命的美妙吗？所以，不要慌，你会明白的，你也会找到自己的方向。单身的人，就像那个属于你的人，也会在不远的地方等待着你一样。 记住，兴趣，这两个字。 有了平常心，大家就不会去追逐新的技术，人云亦云了；有了平常心，大家就不会迷茫，知道当下才是最重要的了；有了平常心，大家就不会去攀比，而会扎实的自己每天进步一点点，与自己为“敌”，其乐无比。 有了辩证的思考，就会看清很多问题的本质，找到属于自己的解决方案。 有了兴趣，做的自己喜欢事，才是适合自己的。 前端千变万化的是技术，不变是我们，不变是我们的初心。 二、对症下药——前端开发过程中的痛点，少走弯路，才能事半功倍 前面我们提了很多心态上的问题，这里就不再赘述。下面，我们除去心态上的问题，我们来谈谈技术。 大家或多或少的了解一个项目开发的过程，但是，有多少人去思考过，为什么需求分析，讨论来讨论去好长时间；为什么组长在这么安排开发，感觉效率不高啊；为什么大家都在推责任，感觉不要团队的氛围啊…. 一个完整的项目，从项目初期立项到项目交付，会经历：需求分析、详细需求分析、项目开发前准备、项目开发&amp;测试、初验（迭代）终验，这么几个基本的过程。不论内外部项目，都有一个共同点，就是有一个既定的目标。大家的KPI与目标的结果挂钩，那么问题来了，倘若这个目标没有实现，KPI会不会考虑说前端没有问题，就还是给你打个高KPI？倘若这个目标实现的一般般，客户让你们改来改去，KPI考核打了个基本分，客户会不会买单？倘若这个目标实现了，前端贡献一般般，KPI考核也会考虑一点点，但是这个份额会大吗？ 总结一下，有需求分析的问题，有沟通的问题，也有效率问题… 这些是技术开发过程中的问题，再来谈一谈新人&amp;老人都会面对的问题——面试与择业。 都说“男怕入错行，女怕嫁错郎”，这句话就是生活的写照啊。在中国，这么物质的社会，还有多少纯洁的感情。在激烈竞争的互联网行业，还有多少蓝海？没有了，红利也还有，但是没有以前那么多了，因为门槛在变低，人工成本一直是企业前进的绊脚石。 所以，先要养活自己，再去思考更长远的事情。这一点，一定要清楚。 在企业中，大家要有“主人翁”的心态，现在很多企业都是“摸着石头过河”，也有一些“不要脸的”（会Copy的），那么其实大家学习这种方法又何尝不可呢？再一点，我们很多时候，会少问那一句“为什么”？心中充满着疑问又不想着解决的办法，那就错过了很多学习的机会。比如：项目目标没有完成，可以找找问题的原因，看看下次有没有什么办法规避；客户改来改去需求，可不可以通过一些手法明确下来；团队中，被弱化的前端团队，怎么才能体现自己的价值，是缺少宣传，还是实力不允许？如果是后者，那么，就思考一下是不是效率上有问题，是不是沟通上有问题…这样顺藤摸瓜，就能找到好多答案。 在找寻“真理”的过程中，肯定不是一蹴而就的，那么就要有“水滴石穿”的精神，不断的摸索着前进。 每个人的问题可能都不一样，再技艺精湛的厨师，也不能保证，每一道菜都合大家的味口。就像我们小时候会打预防针一样，我们会尽量多的去接触各式各样的“疫苗”（其实就是身体在试错），这样才能“抵御”外界的“侵扰”，对吧？ 三、技术蜕变——从前端小白到高阶前端的成长路径 对于新人来说，我之前问过我的一个同事，我深感认同，大家平时工作中，碰到问题了，最想做的事情，就是找个人一问，或者一搜索，就有现成的代码可以Copy，美滋滋~是吧？ 先把这个情况我们放一话。 那题外话一下，那大家知道中年危机是怎么来的吗？谁都知道有中年危机，什么35岁程序员的一到坎之类的….说着说着就心态爆炸了，什么年龄大了，干不了了啊；什么精力跟不上，不能熬夜了啊；什么家里事多，身体抗不住了啊… 但是，我身边那些35岁以上的程序员活的挺好啊，他们身上有一个共同的特点：就是有危机意识。 再回到上面的情况，如果一直都是Copy别人的“答案”，5年后，加入公司的小白看到了你的解决方案之后，1个月就能上手你写的代码了，然后，老板一看，那个小伙子一个月2K，你一个月10K，是人家的5倍，老板怎么想？ 好，这个时候，我们不要倘若，就来说说我身边的&gt;35岁的程序员。他们一进公司1-2年熟悉公司的业务，快速成长了起来，随着团队人员的增加，他们承担了一部分公司的扩展业务（比如：移动端、测试、后台等）；到了3-5年的时候，他们又开始做效率、制度、标准化的事情；到了6-8年的时候，基本上人人都成为了主管，有自己的小团队，在外面接着大小的活，利用公司的资源，一方面扩展了公司的业务（所以老板睁一支眼，闭一支眼），另一方面，提升了自己的地位（那是根深蒂固的），团队少不了这样的核心人物。再退一步说，即使失业了，他们马上还能找到更好的工作。 说到这里，大家能明白什么吗？ 都知道跳槽能加薪，那怎么跳，凭什么跳？写了两年的代码，就可以跳到更高的位置？不是的，而且时间久了，马脚也会露出来，不是吗？ 那怎么办？ 这里有给不同的人，接地气的解决方案： 对于入门前端的同学来说，首先，是摆正自己的心态。从基础的环境、基本的技能、基本的业务入手。 基础的环境是什么？好多同学，在学习前端的过程中，在环境上吃了大亏，花了很多的时间。 有的同学就会问，老师不就是浏览器+Nodejs吗？错，现在的前端的要求，已经从静态页面的开发变化了，需要对服务器环境、数据库环境、自动化环境，要会使用。比如：老板说，你把你的代码部署一下吧，你就build了一下，发给了后台，结果，后台那边说，我们的项目运行了xxx目录下，你这里资源加载有问题… 基本的技能是什么？除了基本的3“剑客”，还需要有IDE使用、NPM加速(除了CNPM，还有Yarn）、真机调试等方面的知识。 基本的业务是什么？比如登录鉴权、长列表、动态列表、多功能表单…等。这些，我相信，已经有不少的同学买过相应的课程，也能对标自己的工作的实际业务，但是，我想说明一点的，前端与JAVA这类的后端不一样，前端的业务其实很单纯，技术也很单一，不像后台JAVA学一套业务设计适合于一套业务，但是其他的业务需要重新考量与设计。而在前端中，比如Vue框架就可以通吃，各类前台、后台项目。这是前端与后端学习之中，大家需要非常明白的一点——前端不是学的业务场景越多越好，关键是要熟练&amp;了解技术的应用场景。 这个阶段，需要有一个好的引路人，才能走的事半功倍。 那么，过了这个阶段（大概会花1-3年），进入到中期之后。不仅大家熟悉了公司、团队的业务，而且有一定的框架使用经验，可以解决实际问题了。那么，就要从效率出发。学习工程化、组件化、接口&amp;后台的知识，为自己的前端之路作后续的铺垫。 这个阶段是很多同学不喜欢的一个阶段，很痛苦，为什么？因为，首先在思想上就是一道坎。很多前端的同学，觉得前端就是做做页面就好了，很多事情可以交给后台，比如：数据结构不好整理交给后台，下载功能不好做交给后台，接口太难设计交给后台…结果就是后台的兄弟技术突飞猛进，自己一事无成，还在写页面。 这个阶段，要学习Linux知识，学习框架的原理，去啃平时那些所谓“难啃的骨头”，甚至要去涉及一部分后台的知识，才能打开视野，突破瓶颈。 人生有很多次选择，但是一次正确的选择，可以决定整个人生的走向。所以，在一开始的时候，就要多去尝试，多去感受这前端的那么多方向，才会找到属于自己的方向。 任何的质变都是量变的结果，进入到高阶之后。从技术上，应该要达到可以应对不同的业务场景的开发，那么就回到了初始的问题，自己的初心是什么？喜欢技术的，往技术更深的地方走，架构、数据库、自动化&amp;运维；喜欢管理的，往产品经理、项目经理方向走，学习产品规划、需求分析、文档管理，以达到效率的团队推动；喜欢测试的…喜欢UI的… 同样的，上面的所述的内容，在我们的课程中，也有完整的视频介绍。 跨过了第三阶段的同学，已经不需要我们的帮助了，我也收到了很多同学的回复，找到了自己心仪的工作，少走了多少弯路；也有我的学生，成为了我的助手，加入了我的团队，一起筑“梦”。 四、前端大局观——从前到端，高薪工作=高价值输出=多端开发 心灵鸡汤预警…. 我们都想要更好的生活，羡慕别人的同时，又很少看到别人的付出。薪酬是与能力&amp;责任成正比的。 责任这一点很好理解，即份内的事情要做好做漂亮。做好是基本的，做漂亮是很难的。我们都知道那个“梗”，两个人被安排去买土豆，A说土豆买不到了，B说土豆买不到了，但是其他的菜是xxx价，从我们日常的分析上来看…. 多从领导者的角度出发去看问题，就会发现好多不一样的处事结果。 再回到前端，做技术的能力是指什么？学习能力？沟通能力？理解能力？…都对，我觉得最重要的是解决问题的能力，包括了上面的其他的能力。这一点，又感觉很空，但是实则是“没有人，天生就会解决问题，都是后天培养出来的”。主动的担责，才会有更多机会培养自己的能力。 随着技术的演进，前端的边界已经变得非常的模糊了。那么，自己的“一亩三分地”，可能在不久的将来就被瓜分走了，企业会去留住那些成倍价值的人才，那如何去增加自己的价值？ 前端，“前”代表着设计、需求、交互、产品…这些用户侧的能看得见摸得着的，“端”代表着接口、测试、自动化、运维、后台….大家很多时候忽略的部分。我们的价值，就要像一把尖刀一样，深深地插入这些痛点的地方、这些被忽略的地方… 有了一个对“端的”的认识之后，可以去设置自己近期与远期的目标，然后动手做起来。有了知识了填补，那个“短板”补齐后的水桶，才能接满水。具体的做法：1. 可以思考团队效率开发，做一些技术导入；2. 可以主动去承担需求分析的工作，熟悉业务、接触客户，锻炼文字和文档能力；3. 可以参与一些“端”的开发，无论是后台还是跨端应用，把自己的定位设置的更高一点。… 最后，提一点。我们的价值，不要从牺牲自己的时间上（加班中）体现出来，要把自己的思考与行动结合起来，变成有价值的工作。告别平凡（重复和单调），其实真的很简单，从一件件小事做起，改变自己的状态，才能堆砌出“万丈高楼”。 当你不再需要站在“巨人”肩膀上的时候，当你成为了“巨人”，你的薪水还会低吗？ 五、挑战即是机遇——诱惑很多，挑战很大，拒绝说“不” 为什么说2019年是互联网最差的一年？因为，真的有很多人失业。为什么说未来的10年是互联网的寒冬？因为，技术的门槛越来越低了，人工的成本在下降。 前端在未来的几年的发展，有几点是确定了的。第一，TypeScript 的大规模普及和流行，TypeScript 的普及会反向推动 ES6（ECMAScript 6.0）的进步和发展；第二，跨端能力进一步增强；比如小程序，不断涌现出各种转译实现，例如小程序、移动端的Flutter、桌面端的Electron（已经7.x版本了，短短2年时间）等；第三，微服务、组件化、人工智能，其实都是在解决效率问题，大小团队的短板都需要提效，就是单人创造的价值要更多，那么反过来就对性能、高可用有了更高的要求。… 这些都是未来的必定的挑战，站在了风口浪尖，只有很出手的人，才能把握先机。 企业越来越喜欢那些复合型的人才了，为什么？因为经济下行的大趋势下，必须要降成本，以前2个人干1个人的活，现在1个人干3个人的活，那么必然会有惨烈的竞争，这个社会就是这么弱肉强食，企业的根本要是生存，不是做公益。 前端这个行业又就是一个非常特殊的行业，前端工程师可以成为产品经理、可以成为UI设计（别小瞧设计，我一个UI设计朋友玩玩做做，通过做兼职，在外玩了1年）、可以成为项目经理…还可以自己出来做产品。因为前端可以接触到各式各样的角色，不要当这些是无用功，要把自己面对的每一次挑战，都当成是一次机会，一次去感受不一样的技术面的机会，一次去感觉不一样的业务的机会，一次去感觉不一样开发的机会… 所以，下次有机会的时候，请不要再说“我不懂运维”，“我不会测试”，“我写不好文档”，“我不会总结”…也不要说“我年龄大了”，要说“我可以学”，“我来试试”，“我尽量来做”… 时间是我们最宝贵的财富，但是心境是比时间更难能可贵的。有的人才20出头就已经看淡了生活，有的人30岁了还没有人生的方向，也有的人40岁了还在转行在学习，有的人50岁了还在写着代码….生活，是由一些平凡的事情所组成的，我们就要做这些平凡的事情的“编织者”，你的人生由你来书写。 最后，记住两句话。 活在当下，珍惜时间。 不忘初心，方得始终。 课程公众号： 课程链接：慕课网职场进阶成长系列课-大前端","categories":[],"tags":[]},{"title":"使用harbor搭建私有docker仓库","slug":"使用harbor搭建私有docker仓库","date":"2019-04-21T03:17:39.000Z","updated":"2021-03-12T03:40:01.749Z","comments":true,"path":"使用harbor搭建私有docker仓库/","link":"","permalink":"https://www.toimc.com/%E4%BD%BF%E7%94%A8harbor%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89docker%E4%BB%93%E5%BA%93/","excerpt":"小伙伴们，想不想自己建立自己的 docker 私库。本篇介绍了什么是 Harbor，如何安装。来，动起手来。 本篇介绍了使用官方在线/离线安装包，进行 Harbor 的安装的过程。","text":"小伙伴们，想不想自己建立自己的 docker 私库。本篇介绍了什么是 Harbor，如何安装。来，动起手来。 本篇介绍了使用官方在线/离线安装包，进行 Harbor 的安装的过程。 什么是 Harbor? Harbor——Manage and serve container images in a secure environment. 这是关于 Harbor 的官方介绍，用来管理与服务容器，说白了就是私仓。 Harbor 是一个开源的云容器仓库，用于存储、签名和扫描容器映像以查找漏洞。 Harbor 通过提供信任、合规性、性能和互操作性来解决容器的共性问题。它填补了无法使用公有云、基于云容器或者是想获得跨云的一致体验的企业们和应用程序之间的空白。 链接：Harbor 官网 安装 Harbor安装方法简介 在线安装方式 主要是从 Docker Hub 下载 Harbor 镜像，所以这种安装方式，对于空间的要求非常小。 离线安装方式 当没有网络的时候，可以使用这种安装方法，离线包里面有预打包的容器，所以比较大。 Kubernetes 安装方式 需要Kubernetes v1.6.5 and Harbor v1.2.0，参考：Integration with Kubernetes 硬件环境 资源 最小配置 描述 CPU &gt;2 CPU 4 CPU 最好 Mem(内存) &gt;4GB 8GB 最好 Disk(硬盘) &gt;40GB 160GB 最好 软件环境 软件环境 版本 描述 Python &gt;2.7 有一些 Linux 发行版是没有默认安装 Python 的，需要自己手动安装 Docker engine &gt;1.10 安装 Docker，请参考我们的另一个博文：Docker 入门之安装教程；官方教程：Install Docker CE Docker Compose &gt;1.6.0 请参考安装教程：docker-compose 命令安装方法；官方教程：Install Docker Compose Openssl lastest 用于产生证书与密钥(一般 Linux 发行版会默认安装) 网络端口 端口 协议 描述 443 HTTPS Harbor portal 和 core API 将会使用 443 接口用于 HTTPS 协议 4443 HTTPS 当 Notray 使用时，Harbor 使用这个端口用于 Docker 中可信任内容的传输。 80 HTTP Harbor portal 和 core API 将会使用 80 接口用于 HTTP 协议 安装步骤 基本的安装步骤 下载安装包，在release页面进行下载 配置harbor.cfg 运行install.sh 使用如下命令进行解压 Online installer: 1$ tar xvf harbor-online-installer-&lt;version&gt;.tgz Offline installer: 1$ tar xvf harbor-offline-installer-&lt;version&gt;.tgz 配置 Harbor Required parameters Optional parameters 其中，Required parameters 有： hostname：使用 ip 或者域名，切忌使用localhost或者127.0.0.1 ui_url_protocol：默认为http协议（可选https或者http），如果需要配置SSL证书，请参考HTTPS 配置 db_password：数据库 PostgreSQL 的 root 密码 max_job_workers：默认为10，根据现有的任务数量需要进行更改，每个任务会占用network/CPU/IO资源，所以分配了之后注意观察。 customize_crt：默认为on，可以设置成off。harbor 会自动生成证书与密钥对，如果需要自己生成，请参考：Customize Harbor token service with your key and certificate ssl_cert：SSL 证书路径，只有当设置成 https 生效。 ssl_cert_key：SSL 密钥，同上。 secretkey_path：用于加密或者解密远程仓库的密钥路径(去访问其他仓库使用的密钥) log_rotate_count：如果设置成0，则老旧的日志文件就会被清除掉，而不是进行滚动增加。 log_rotate_size：滚动日志的大小，默认单位是kb，可以设置成100M或者是100G http_proxy：http 代理路径 https_proxy：https 代理 no_proxy：不需要代理的地址或者域名，如：127.0.0.1 使用vi命令对harbor.cfg文件进行编辑 其中，Optional parameters 有： Email settings 参考如下配置： email_server = smtp.mydomain.com email_server_port = 25 email_identity = email_username = sample_admin@mydomain.com email_password = abc email_from = admin sample_admin@mydomain.com email_ssl = false email_insecure = false harbor_admin_password：管理员密码 auth_mode：默认是db_auth，可选ldap_auth或者db_auth 重要提示：当从已有的 Harbor 进行升级时，要确保auth_mode与harbor.cfg中的配置是一样的。 ldap_url：LDAP 入口地址：e.g.ldaps://ldap.mydomain.com，只有ldap_auth模式下才有效 ldap_searchdn：DN 用户，e.g. uid=admin,ou=people,dc=mydomain,dc=com ldap_search_pwd：搜索用户的密码 ldap_basedn：基础用户，e.g. ou=people,dc=mydomain,dc=com ldap_filter：搜索过滤，e.g. (objectClass=person) ldap_uid：用于在搜索的时候，对用于进行匹配：可以是 uid, cn, email 或者是其他属性。 ldap_scope：搜索的范围：0-LDAP_SCOPE_BASE, 1-LDAP_SCOPE_ONELEVEL, 2-LDAP_SCOPE_SUBTREE. 默认是 2. ldap_timeout：超时时长，默认是 5. ldap_verify_cert：是否从 LDAP 服务器进行认证，默认是 true. ldap_group_basedn：基础的搜索组， e.g. ou=group,dc=mydomain,dc=com ldap_group_filter：组过滤 ldap_group_gid：组属性，如 cn, name ldap_group_scope：搜索的范围：0-LDAP_SCOPE_BASE, 1-LDAP_SCOPE_ONELEVEL, 2-LDAP_SCOPE_SUBTREE.默认是 2. self_registration： (on or off. Default is on) 是否允许自注册，一般来说auth_mode被设置成ldap_auth模式的时候，自注册是被关闭的。 token_expiration：默认的 token 过期时长，默认 30 分钟。 project_creation_restriction：设置哪些用户可以创建项目，默认是允许所有的用户进行创建，当设置成adminonly时，只允许管理员进行创建。 以下是示例配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197## Configuration file of Harbor## Configuration file of Harbor#This attribute is for migrator to detect the version of the .cfg file, DO NOT MODIFY!_version = 1.5.0#The IP address or hostname to access admin UI and registry service.#DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.hostname = test.wayearn.cn#The protocol for accessing the UI and token/notification service, by default it is http.#It can be set to https if ssl is enabled on nginx.ui_url_protocol = https#Maximum number of job workers in job servicemax_job_workers = 50#Determine whether or not to generate certificate for the registry&#x27;s token.#If the value is on, the prepare script creates new root cert and private key#for generating token to access the registry. If the value is off the default key/cert will be used.#This flag also controls the creation of the notary signer&#x27;s cert.customize_crt = off#The path of cert and key files for nginx, they are applied only the protocol is set to httpsssl_cert = /home/ssh/fullchain.cerssl_cert_key = /home/ssh/wayearn.cn.key#The path of secretkey storagesecretkey_path = /data#Admiral&#x27;s url, comment this attribute, or set its value to NA when Harbor is standaloneadmiral_url = NA#Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated.log_rotate_count = 50#Log files are rotated only if they grow bigger than log_rotate_size bytes. If size is followed by k, the size is assumed to be in kilobytes.#If the M is used, the size is in megabytes, and if G is used, the size is in gigabytes. So size 100, size 100k, size 100M and size 100G#are all valid.log_rotate_size = 200M#Config http proxy for Clair, e.g. http://my.proxy.com:3128#Clair doesn&#x27;t need to connect to harbor ui container via http proxy.http_proxy = socks5://192.168.4.250:2080https_proxy = socks5://192.168.4.250:2080no_proxy = 127.0.0.1,localhost,ui#NOTES: The properties between BEGIN INITIAL PROPERTIES and END INITIAL PROPERTIES#only take effect in the first boot, the subsequent changes of these properties#should be performed on web ui#************************BEGIN INITIAL PROPERTIES************************#Email account settings for sending out password resetting emails.#Email server uses the given username and password to authenticate on TLS connections to host and act as identity.#Identity left blank to act as username.email_identity =email_server = email-smtp.us-east-1.amazonaws.comemail_server_port = 587email_username = AKIAJ3A3D3R5NMUUEBJAemail_password = Amz5jvLaeq13VLk5j4QtmTRJhZ/AnxEnmuHUB4DsQ+opemail_from = liwei &lt;admin@wayearn.com&gt;email_ssl = trueemail_insecure = false##The initial password of Harbor admin, only works for the first time when Harbor starts.#It has no effect after the first launch of Harbor.#Change the admin password from UI after launching Harbor.harbor_admin_password = 2239hOb2tVgOSwoW123FDs23vs324hmuy7667ghfbv32FGDS43##By default the auth mode is db_auth, i.e. the credentials are stored in a local database.#Set it to ldap_auth if you want to verify a user&#x27;s credentials against an LDAP server.auth_mode = db_auth#The url for an ldap endpoint.ldap_url = ldaps://ldap.mydomain.com#A user&#x27;s DN who has the permission to search the LDAP/AD server.#If your LDAP/AD server does not support anonymous search, you should configure this DN and ldap_search_pwd.#ldap_searchdn = uid=searchuser,ou=people,dc=mydomain,dc=com#the password of the ldap_searchdn#ldap_search_pwd = password#The base DN from which to look up a user in LDAP/ADldap_basedn = ou=people,dc=mydomain,dc=com#Search filter for LDAP/AD, make sure the syntax of the filter is correct.#ldap_filter = (objectClass=person)# The attribute used in a search to match a user, it could be uid, cn, email, sAMAccountName or other attributes depending on your LDAP/ADldap_uid = uid#the scope to search for users, 0-LDAP_SCOPE_BASE, 1-LDAP_SCOPE_ONELEVEL, 2-LDAP_SCOPE_SUBTREEldap_scope = 2#Timeout (in seconds) when connecting to an LDAP Server. The default value (and most reasonable) is 5 seconds.ldap_timeout = 5#Verify certificate from LDAP serverldap_verify_cert = true#The base dn from which to lookup a group in LDAP/ADldap_group_basedn = ou=group,dc=mydomain,dc=com#filter to search LDAP/AD groupldap_group_filter = objectclass=group#The attribute used to name a LDAP/AD group, it could be cn, nameldap_group_gid = cn#The scope to search for ldap groups. 0-LDAP_SCOPE_BASE, 1-LDAP_SCOPE_ONELEVEL, 2-LDAP_SCOPE_SUBTREEldap_group_scope = 2#Turn on or off the self-registration featureself_registration = on#The expiration time (in minute) of token created by token service, default is 30 minutestoken_expiration = 30#The flag to control what users have permission to create projects#The default value &quot;everyone&quot; allows everyone to creates a project.#Set to &quot;adminonly&quot; so that only admin user can create project.project_creation_restriction = everyone#************************END INITIAL PROPERTIES************************###### #Harbor DB configuration section######## The address of the Harbor database. Only need to change when using external db.db_host = mysql# The password for the root user of Harbor DB. Change this before any production use.db_password = root123# The port of Harbor database hostdb_port = 3306# The user name of Harbor databasedb_user = root##### End of Harbor DB configuration######## The redis server address. Only needed in HA installation.# address:port[,weight,password,db_index]redis_url = redis:6379###### ####Clair DB configuration############# Clair DB host address. Only change it when using an exteral DB.clair_db_host = postgres# The password of the Clair&#x27;s postgres database. Only effective when Harbor is deployed with Clair.# Please update it before deployment. Subsequent update will cause Clair&#x27;s API server and Harbor unable to access Clair&#x27;s database.clair_db_password = password# Clair DB connect portclair_db_port = 5432# Clair DB usernameclair_db_username = postgres# Clair default databaseclair_db = postgres###### ####End of Clair DB configuration############# The following attributes only need to be set when auth mode is uaa_authuaa_endpoint = uaa.mydomain.orguaa_clientid = iduaa_clientsecret = secretuaa_verify_cert = trueuaa_ca_cert = /path/to/ca.pem### Docker Registry setting# registry_storage_provider can be: filesystem, s3, gcs, azure, etc.registry_storage_provider_name = filesystem# registry_storage_provider_config is a comma separated &quot;key: value&quot; pairs, e.g. &quot;key1: value, key2: value2&quot;.# Refer to https://docs.docker.com/registry/configuration/#storage for all available configuration.registry_storage_provider_config = 配置完成之后，在当前的解压缩的目录下，运行sudo ./install.sh 是否可以在解压缩的目录下找到相应的文件install.sh？如果找不到，可以使用find命令或者是ls命令。 安装完成之后，就可以访问之前设置的域名或者 IP 地址了，比如上例中的test.toimc.com 常见问题 如何推送镜像？ 12docker login test.toimc.comdocker push test.toimc.com/myproject/myrepo:mytag 如何申请证书，如何设置 SSL？ 有两个先决条件：(1)需要有一个域名； (2)使用 acme 或者 caddy 这种服务进行申请证书。 安装 Notary, 安装 Clair, 安装 chart repository service 安装 Notary，使用如下命令：sudo ./install.sh --with-notary 安装 Clair，使用如下命令：sudo ./install.sh --with-clair 安装 Chart repository service，使用如下命令：sudo ./install.sh --with-chartmuseum PS： 可以这样使用：sudo ./install.sh --with-notary --with-clair --with-chartmuseum Harbor 生命周期的管理： 直接使用docker-compose管理命令进行管理(PS:需要cd到之前的 Harbor 的解压目录，即install目录) 停止 Harbor: 12345678910$ sudo docker-compose stopStopping nginx ... doneStopping harbor-portal ... doneStopping harbor-jobservice ... doneStopping harbor-core ... doneStopping registry ... doneStopping redis ... doneStopping registryctl ... doneStopping harbor-db ... doneStopping harbor-log ... done 重启 Harbor： 12345678910$ sudo docker-compose startStarting log ... doneStarting registry ... doneStarting registryctl ... doneStarting postgresql ... doneStarting core ... doneStarting portal ... doneStarting redis ... doneStarting jobservice ... doneStarting proxy ... done 当修改了 Harbor 的配置文件后，需要使用如下的方式更新镜像： 1234$ sudo docker-compose down -v$ vim harbor.cfg$ sudo prepare$ sudo docker-compose up -d 删除 Harbor 镜像，但是保留文件系统的做法： 1$ sudo docker-compose down -v 需要全部删除时(包括镜像、文件、仓库)——重装需要/卸载需要 12$ rm -r /data/database$ rm -r /data/registry 日志文件路径：/var/log/harbor 自定义端口： 修改docker-compose.yml修改”80”端口到一个指定的用户端口, e.g. 8888:80. 1234567891011121314151617181920proxy: image: goharbor/nginx-photon:v1.6.0 container_name: nginx restart: always volumes: - ./common/config/nginx:/etc/nginx:z ports: - 8888:80 - 443:443 depends_on: - postgresql - registry - core - portal - log logging: driver: &quot;syslog&quot; options: syslog-address: &quot;tcp://127.0.0.1:1514&quot; tag: &quot;proxy&quot; 修改harbor.cfg文件中的 hostname 属性： 1hostname = 192.168.0.2:8888 参考上面的管理 harbor 的生命周期的内容，对 Harbor 进行更新。 同理，对于 HTTPS 协议，参考： 打开 HTTPS 协议，并配置 SSL 证书：参考guide. 修改docker-compose.yml修改”443” 端口为用户自定义端口, e.g. 8888:443. 1234567891011121314151617181920proxy: image: goharbor/nginx-photon:v1.6.0 container_name: nginx restart: always volumes: - ./common/config/nginx:/etc/nginx:z ports: - 80:80 - 8888:443 depends_on: - postgresql - registry - core - portal - log logging: driver: &quot;syslog&quot; options: syslog-address: &quot;tcp://127.0.0.1:1514&quot; tag: &quot;proxy&quot; 修改harbor.cfg文件中的 hostname 属性： 1hostname = 192.168.0.2:8888 参考上面的管理 harbor 的生命周期的内容，对 Harbor 进行更新。","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.toimc.com/tags/Docker/"}]},{"title":"慕课网《前端跳槽面试必备技巧》——总结","slug":"慕课网《前端跳槽面试必备技巧》——总结","date":"2019-04-06T15:20:06.000Z","updated":"2019-04-07T01:27:03.000Z","comments":true,"path":"慕课网《前端跳槽面试必备技巧》——总结/","link":"","permalink":"https://www.toimc.com/%E6%85%95%E8%AF%BE%E7%BD%91%E3%80%8A%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7%E3%80%8B%E2%80%94%E2%80%94%E6%80%BB%E7%BB%93/","excerpt":"本篇介绍的是课程总结的内容。原课程链接：前端跳槽面试必备技巧","text":"本篇介绍的是课程总结的内容。原课程链接：前端跳槽面试必备技巧 JD描述 对于社招一定要看，对于校招可以忽略 简历 对照JD改写出相吻合的简历，对于未掌握的技术栈快速复习、理解 自我介绍 一定要打草稿，展示什么优势、描述什么项目，切忌临场发挥 一面 重基础、懂原理，要思考、知进退、势不可挡 二面 横向扩展、项目结合，做到有的放矢 三面 有经验、懂合作、有担当、懂规矩、察言观色 终面 会沟通、要上进、好性格、有主见、强逻辑、无可挑剔 复盘 胜不骄、败不馁、总结经验、步步为营、多拿几个Offer 相关资料： 基础知识：http://www.w3school.com.cn 算法题：https://leetcode.com/preblemset/algorithms","categories":[{"name":"前端跳槽面试必备技巧","slug":"前端跳槽面试必备技巧","permalink":"https://www.toimc.com/categories/%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"前端面试","slug":"前端面试","permalink":"https://www.toimc.com/tags/%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"name":"技巧总结","slug":"技巧总结","permalink":"https://www.toimc.com/tags/%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/"}]},{"title":"慕课网《前端跳槽面试必备技巧》——终面/HR面","slug":"慕课网《前端跳槽面试必备技巧》——终面-HR面","date":"2019-04-06T15:01:25.000Z","updated":"2019-04-06T15:19:22.000Z","comments":true,"path":"慕课网《前端跳槽面试必备技巧》——终面-HR面/","link":"","permalink":"https://www.toimc.com/%E6%85%95%E8%AF%BE%E7%BD%91%E3%80%8A%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7%E3%80%8B%E2%80%94%E2%80%94%E7%BB%88%E9%9D%A2-HR%E9%9D%A2/","excerpt":"本篇介绍的是面试的终面，即HR面准备的内容。原课程链接：前端跳槽面试必备技巧","text":"本篇介绍的是面试的终面，即HR面准备的内容。原课程链接：前端跳槽面试必备技巧 面试技巧： 乐观积极 主动沟通(重要) 逻辑顺畅 上进有责任心 有主张、做事果断 HR考察是性格、公司文化、团队协作、有没有责任心、做事是不是纠结。HR有一票否决权！很重要！ 内容分布： 职业竞争力 业务能力 可以做到行业第一 思考能力 对同一件事可以从不同角度去思考，找到最优解 学习能力 不断学习新的业务和技术，沉淀、总结 无上限的付出 对于无法解决的问题可以熬夜、加班 职业规划 目标是什么 在业务上成为专家，在技术上成为行业大牛 近阶段的目标 不断的学习积累各方面的经验，以学习为主 长期目标 做几件很有价值的事情，如开源作品、技术框架等 方式方法 先完成业务上的主要问题，做到极致，然后逐步向目标靠拢","categories":[{"name":"前端跳槽面试必备技巧","slug":"前端跳槽面试必备技巧","permalink":"https://www.toimc.com/categories/%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"前端面试","slug":"前端面试","permalink":"https://www.toimc.com/tags/%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"name":"技巧总结","slug":"技巧总结","permalink":"https://www.toimc.com/tags/%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/"}]},{"title":"慕课网《前端跳槽面试必备技巧》——综合面/业务面","slug":"慕课网《前端跳槽面试必备技巧》——综合面-BOSS面","date":"2019-04-06T12:39:21.000Z","updated":"2019-04-09T05:09:02.000Z","comments":true,"path":"慕课网《前端跳槽面试必备技巧》——综合面-BOSS面/","link":"","permalink":"https://www.toimc.com/%E6%85%95%E8%AF%BE%E7%BD%91%E3%80%8A%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7%E3%80%8B%E2%80%94%E2%80%94%E7%BB%BC%E5%90%88%E9%9D%A2-BOSS%E9%9D%A2/","excerpt":"本篇介绍的是面试的四/五面，即综合面/BOSS面准备的内容。原课程链接：前端跳槽面试必备技巧","text":"本篇介绍的是面试的四/五面，即综合面/BOSS面准备的内容。原课程链接：前端跳槽面试必备技巧 面试技巧： 准备要充分(背后的技术问题与难点) 描述要演练 引导找时机(不能很生硬，投机的时候/对方不知道怎么去问你了) 优势要发挥 回答要灵活 面试模拟需要突显这几方面的能力： 业务能力(非常重要) 团队协作能力(重要) 事务推动能力(重要) 带人能力 其他能力 业务能力：主动描述/被动回答： 我做过什么业务？(用一两句来描述) 例：独立负责360数据彩票走势图开发 负责的业务有什么业绩？(用数据来说话) 例：在车里3周完成所有采彩种开发，用户量上涨15% 使用了什么技术方案？ 例：区别常规canvas方案，使用vml+svg方案 突破了什么技术难点？ 例：解决了走势图高级绘图板的开发 遇到了什么问题？ 例：橡皮擦的问题、动态连线计算等 最大的收获是什么？ 例：对业务的理解更加深入、对技术图表更有把控 团队协作能力主动描述： 对彩足彩的奖金算法有深入研究，业内第一 为H5、客户端讲解算法并协助完成开发 和PHP、PM同学在一天的时间内快速支持足彩竞猜活动 和Leader独立负责彩票PC站 事务推动能力主动描述： 对历史算法更新换代 推动专题的CMS架构 主导客服系统的建设 完成多项专利的申请 带人能力主要描述： 带一个社招完成数字彩的开发和维护 带一个实习生完成专题活动的开发 代码规范、Review 其他能力 组织能力 学习能力 行业经验","categories":[{"name":"前端跳槽面试必备技巧","slug":"前端跳槽面试必备技巧","permalink":"https://www.toimc.com/categories/%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"前端面试","slug":"前端面试","permalink":"https://www.toimc.com/tags/%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"name":"技巧总结","slug":"技巧总结","permalink":"https://www.toimc.com/tags/%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/"}]},{"title":"慕课网《前端跳槽面试必备技巧》——关于业务技术面","slug":"慕课网《前端跳槽面试必备技巧》——关于业务技术面","date":"2019-04-06T06:50:01.000Z","updated":"2021-03-02T15:36:13.626Z","comments":true,"path":"慕课网《前端跳槽面试必备技巧》——关于业务技术面/","link":"","permalink":"https://www.toimc.com/%E6%85%95%E8%AF%BE%E7%BD%91%E3%80%8A%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7%E3%80%8B%E2%80%94%E2%80%94%E5%85%B3%E4%BA%8E%E4%B8%9A%E5%8A%A1%E6%8A%80%E6%9C%AF%E9%9D%A2/","excerpt":"本篇介绍的是面试的二/三面，即业务技术面需要准备的内容。原课程链接：前端跳槽面试必备技巧","text":"本篇介绍的是面试的二/三面，即业务技术面需要准备的内容。原课程链接：前端跳槽面试必备技巧 面试技巧 知识面要广 理解要深刻 内心要诚实 态度要谦虚 回答要灵活 要学会赞美 本篇重点内容： 渲染机制 JS运行机制 页面性能 错误监控 渲染机制 什么是DOCTYPE及作用 DTD(document type definition,文档类型定义)是一系列的语法规则，用来定义XML或者(X)HTML文件类型。浏览器会使用它来判断文档类型，决定使用何种协议来解析，以及切换浏览器模式。 DOCTYPE是用来声明文档类型和DTD规范的，一个主要的用途便是文件的合法性验证。如果文件代码不合法，那么浏览器解析时便会出一些差错。 12345678HTML5&lt;!DOCTYPE html&gt;HTML 4.01 Strict # 该DTD包含所有HTML元素和属性，但不包括展示性和弃用的元素(比如font)&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTC HTML 4.01//EN&quot; &quot;http://www.w3.org/TR/html4/strict.dtd&quot;&gt;HTML 4.01 Transitional # 该DTD包含所有HTML元素和属性，但包括展示性和弃用的元素(比如font)&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTC HTML 4.01//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt; 浏览器渲染过程 DOM tree： CSS tree: Render tree: Layout: 重排Reflow 定义：DOM结构中的各个元素都有自己的盒子(模型)，这些都需要浏览吕根据各种样式来计算并根据计算结果将元素放到它该出现的问题，这个过程称之为reflow。 触发Reflow： 当你增加、删除、修改DOM结点时，会导致Reflow或Repaint 当你移动DOM的位置，或是搞个动画的时候 当你修改CSS样式的时候 当你Resize窗口的时候(移动端没有这个问题)，或者是滚动的时候 当你修改网页的 最常问：如何减少Reflow?或者避免Reflow？ 重绘Repaint 定义：当各种盒子的位置、大小以及其他属性，例如颜色、字体大小等都确定下来后，浏览器于是便把这些元素都按照各自的特性绘制了一遍，于是页面的内容出现了，这个过程称之为repaint。 页面要呈现的内容，通通都绘制到页面上。 触发Repaint DOM改动 CSS改动 最常问：如何避免最小程序的Repaint？ 布局Layout JS运行机制 如何理解JS的单线程？ 什么是任务队列(分同步任务，异步任务) 什么是Event Loop 案例来说明： 12345678console.log(1)setTimeout(function()&#123; console.log(3)&#125;,0)console.log(2)输出：123 js是单线程，那么异步在js中是如何实现的呢？其实，就是任务队列。 setTimeout是一个异步任务，异步任务要挂起。 1234567console.log(&#x27;A&#x27;)while(true)&#123; &#125;console.log(&#x27;B&#x27;)输出：A # 页面会卡死 如果是下面： 123456789console.log(&#x27;A&#x27;)setTimeout(function()&#123; console.log(&#x27;B&#x27;)&#125;,0)while(1)&#123; &#125;输出：A # 页面会卡死 另外再来看看下面的题目： 1234567891011for(var i=0; i &lt; 4; i++) &#123; setTimeout(function()&#123; console.log(i) &#125;,1000)&#125;输出：4444# 总运行时间1s 有哪些异步任务？ setTimeout和setInterval DOM事件 ES6中的Promise 页面性能题目：提升页面性能的方法有哪些？ 资源压缩合并，减少HTTP请求(开启gzip) 非核心代码异步加载—&gt;异步加载方式—&gt;异步加载的区别 利用浏览器缓存—&gt;缓存的分类—&gt;缓存的原理 使用CDN 预解析DNS 12&lt;meta http-equiv=&quot;x-dns-prefetch-control&quot; content=&quot;on&quot;&gt;&lt;link rel=&quot;dns-prefetch&quot; href=&quot;//host_name_to_prefetch.com&quot;&gt; 关于异步加载： 异步加载的方式 动态脚本加载 defer async 异步加载的区别 defer是在HTML解析完之后才会执行，如果是多个，按照加载的顺序依次执行 async是在加载完成之后立即执行，如果是多个，执行顺序和加载顺序无关 示例代码： Index.html文件： 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Defer&lt;/title&gt; &lt;script src=&quot;./defer1.js&quot; defer&gt;&lt;/script&gt; &lt;script src=&quot;./defer2.js&quot; defer&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt; test&lt;/div&gt;&lt;script type=&quot;text/javascript&quot;&gt; document.write(&#x27;&lt;span&gt;write&lt;/span&gt;&#x27;)&lt;/script&gt;&lt;script&gt; for(var i=0; i &lt; 200000; i++) &#123; if (i % 20000 === 0) &#123; console.log(i) &#125; &#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 两个Deferjs中只有一句console.log(&#39;defer&#39;) 同理，可以尝试一下async属性 关于缓存的分类 强缓存 HTTP 头： 123Expires Expires: Thu, 21 Jan 2017 23:39:02 GMTCache-Control Cache-Control:max-age=3600 协商缓存 123Last-Modified If-Modified-Since Last-Modified: Web, 26 Jan 2017 00:35:11 GMTEtag If-None-Match 错误监控 前端错误的分类 即时运行错误：代码错误 资源加载错误 错误的捕获方式 即时运行错误的捕获方式 (1) try….catch (2) window.onerror window.onerror只能捕获及时运行错误，不能捕获资源加载错误 资源加载错误的捕获方式 (1) boject.onerror (2) performance.getEntries() 123456# console窗口中执行performance.getEntries().foreach((item)=&gt;&#123; console.log(item)&#125;)#即可以打印网页上加载的资源 (3) Error事件捕获 示例： 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Error&lt;/title&gt; &lt;script&gt; window.addEventListener(&#x27;error&#x27;, function (e) &#123; console.log(&#x27;捕获&#x27;, e) &#125;, true) &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;script src=&quot;//baidu.com/fdsfdsfds.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 延伸：跨域的js运行错误可以捕获吗？错误提示什么，应用怎么处理？ 解析：跨域的js运行错误也是可以捕获的 在script标签增加crossorigin属性 设置资源响应头Access-Control-Allow-Origin:* 上报错误的基本原理 采用Ajax通信的方式上报 利用Image对象上报 12// 只需要一行代码就可以实现(new Image().src=&#x27;http://baidu.com/test?r=data&#x27;)","categories":[{"name":"前端跳槽面试必备技巧","slug":"前端跳槽面试必备技巧","permalink":"https://www.toimc.com/categories/%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"前端面试","slug":"前端面试","permalink":"https://www.toimc.com/tags/%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"name":"技巧总结","slug":"技巧总结","permalink":"https://www.toimc.com/tags/%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/"}]},{"title":"慕课网《前端跳槽面试必备技巧》——关于基础面","slug":"慕课网《前端跳槽面试必备技巧》——关于基础面","date":"2019-03-30T08:11:53.000Z","updated":"2021-03-02T15:35:31.764Z","comments":true,"path":"慕课网《前端跳槽面试必备技巧》——关于基础面/","link":"","permalink":"https://www.toimc.com/%E6%85%95%E8%AF%BE%E7%BD%91%E3%80%8A%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7%E3%80%8B%E2%80%94%E2%80%94%E5%85%B3%E4%BA%8E%E5%9F%BA%E7%A1%80%E9%9D%A2/","excerpt":"本篇介绍的是面试的一/二面，即基础面需要准备的内容。原课程链接：前端跳槽面试必备技巧","text":"本篇介绍的是面试的一/二面，即基础面需要准备的内容。原课程链接：前端跳槽面试必备技巧 一面/二面（基础知识面） 这一面的面试技巧： 准备要充分 知识要系统 沟通要简洁 内心要诚实 态度要谦虚 回答要灵活 切忌： 基础面相对答案相对统一，所以要简洁回答；而相比于第二/三面，可以多回答一点，但是要注意成体系，有逻辑性。 诚实的回答，不要自己说“我看过，我忘记了”这种，不会就是不会，可以去请教面试官。 关于知识，不要说话太死或者太满，评价一个事情的时候，由于我们往往认识不足，才会得到一个片面的观点。 页面布局题目：假设调试已知，请写出三栏布局，其中左栏、右栏宽度各为300px,中间自适应。 回答技巧： 题干的要求真的是这么简单吗？ 解析：浮动+绝对定位是基础答案。加分项：第三种是Flex布局，第四种是Table布局，第五种网格布局Grid布局。 这道题的答案应该怎么写？技巧在哪里？ 如果我要证明我的实力，我应该答上几种答案。 下面是答案： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt;&lt;title&gt;Document&lt;/title&gt;&lt;style media=&quot;screen&quot;&gt; html * &#123; padding: 0; margin: 0; &#125; .layout article div &#123; min-height: 100px; &#125; .layout &#123; margin-top: 10px; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;!-- 浮动 --&gt;&lt;section class=&quot;layout float&quot;&gt; &lt;style media=&quot;screen&quot;&gt; .layout.float .left &#123; float: left; width: 300px; background: red; &#125; .layout.float .right &#123; float: right; width: 300px; background: blue; &#125; .layout.float .center &#123; background: yellow; &#125; &lt;/style&gt; &lt;article class=&quot;left-right-center&quot;&gt; &lt;div class=&quot;left&quot;&gt;&lt;/div&gt; &lt;div class=&quot;right&quot;&gt;&lt;/div&gt; &lt;div class=&quot;center&quot;&gt; &lt;h1&gt;浮动解决方案&lt;/h1&gt; 1. 这是三栏布局中间部分 2. 这是三栏布局中间部分 &lt;/div&gt; &lt;/article&gt;&lt;/section&gt;&lt;!-- 绝对定位 --&gt;&lt;section class=&quot;layout absolute&quot;&gt; &lt;article class=&quot;left-center-right&quot;&gt; &lt;style media=&quot;screen&quot;&gt; .layout.absolute .left-center-right&gt;div &#123; position: absolute; &#125; .layout.absolute .center &#123; left: 300px; right: 300px; background: yellow; &#125; .layout.absolute .left &#123; left: 0; width: 300px; background: red; &#125; .layout.absolute .right &#123; right: 0; width: 300px; background: blue &#125; &lt;/style&gt; &lt;div class=&quot;left&quot;&gt;&lt;/div&gt; &lt;div class=&quot;right&quot;&gt;&lt;/div&gt; &lt;div class=&quot;center&quot;&gt; &lt;h2&gt;这是绝对定位的解决方案&lt;/h2&gt; 1. 这是三栏布局绝对定位中间部分 2. 这是三栏布局绝对定位中间部分 &lt;/div&gt; &lt;/article&gt;&lt;/section&gt;&lt;!-- flex布局 --&gt;&lt;section class=&quot;layout flexbox&quot;&gt; &lt;style media=&quot;screen&quot;&gt; .layout.flexbox &#123; margin-top: 120px; &#125; .layout.flexbox .left-center-right &#123; display: flex; &#125; .layout.flexbox .left &#123; width: 300px; background: red; &#125; .layout.flexbox .center &#123; flex: 1; background: yellow; &#125; .layout.flexbox .right &#123; width: 300px; background: blue; &#125; &lt;/style&gt; &lt;article class=&quot;left-center-right&quot;&gt; &lt;div class=&quot;left&quot;&gt;&lt;/div&gt; &lt;div class=&quot;center&quot;&gt; &lt;h2&gt;这是flex布局的解决方案&lt;/h2&gt; 1. 这是三栏布局flex中间部分 2. 这是三栏布局flex中间部分 &lt;/div&gt; &lt;div class=&quot;right&quot;&gt;&lt;/div&gt; &lt;/article&gt;&lt;/section&gt;&lt;!-- 表格布局 --&gt;&lt;section class=&quot;layout table&quot;&gt; &lt;style media=&quot;screen&quot;&gt; .layout.table .left-center-right &#123; width: 100%; display: table; height: 100px; &#125; .layout.table .left-center-right &gt; div &#123; display: table-cell; &#125; .layout.table .left &#123; width: 300px; background: red; &#125; .layout.table .center &#123; background: yellow; &#125; .layout.table .right &#123; width: 300px; background: blue; &#125; &lt;/style&gt; &lt;articcle class=&quot;left-center-right&quot;&gt; &lt;div class=&quot;left&quot;&gt;&lt;/div&gt; &lt;div class=&quot;center&quot;&gt; &lt;h2&gt;这是table布局的解决方案&lt;/h2&gt; 1. 这是三栏布局table中间部分 2. 这是三栏布局table中间部分 &lt;/div&gt; &lt;div class=&quot;right&quot;&gt;&lt;/div&gt; &lt;/articcle&gt;&lt;/section&gt;&lt;!-- grid布局 --&gt;&lt;section class=&quot;layout grid&quot;&gt; &lt;style media=&quot;screen&quot;&gt; .layout.grid .left-center-right &#123; display: grid; width: 100%; grid-template-rows: 100px; grid-template-columns: 300px auto 300px; &#125; .layout.grid .left &#123; background: red; &#125; .layout.grid .right &#123; background: blue; &#125; .layout.grid .center &#123; background: yellow; &#125; &lt;/style&gt; &lt;article class=&quot;left-center-right&quot;&gt; &lt;div class=&quot;left&quot;&gt;&lt;/div&gt; &lt;div class=&quot;center&quot;&gt; &lt;h2&gt;网络布局解决方案&lt;/h2&gt; 1. 这是三栏布局grid中间部分 2. 这是三栏布局grid中间部分 &lt;/div&gt; &lt;div class=&quot;right&quot;&gt;&lt;/div&gt; &lt;/article&gt;&lt;/section&gt;&lt;/body&gt;&lt;/html&gt; 答完题之后，面试可能最会问的是: 怎么延伸，这一种方案的优缺点; 把高度去掉，中间的高度比较高，需要左右一样会撑开。 Table、Flex布局可以自适应。 兼容性怎么样。 对于浮动缺点：常见需要清除浮动；优点，兼容性比较好。 绝对定位缺点：脱离了文档流；优点：快捷； flex布局：在移动端适配比较好； 表格布局：优点，对于高度的适应比较好，兼容性比较好；缺点：当其中一个单元格高度超出了之后，会改变其他的单元格的高度； 网格布局：优点代码量简化；缺点：兼容性对于IE不是友好。 浮动解决方案，为什么中间内容比较高，超出了左侧元素后，为什么会浮动到左侧？ 使用浮动布局的时候，不让元素超出自己的边界，自动延伸（答案：创建BFC，见CSS盒模型） 页面布局小结 语义化掌握到位（不要通篇DIV） 页面布局理解深刻（理解原理） CSS基础知识扎实（table, flex, grid基础知识） 思维灵活且积极上进 代码书写规范 页面布局的变通/变种 三栏布局 左右宽度固定，中间自适应 上下高度固定，中间自适应 两栏布局 左宽度固定，右自适应 右宽度固定，左自适应 上高度固定，下自适应 下高度固定，上自适应 只有多思考，多准备，才能建立知识体系。 CSS盒模型题目：谈谈你对CSS盒模型的认识 准备的知识： 基本概念：标准模型 + IE模型 标准模型与IE模型的区别（宽高不同） CSS如何设置这两种模型 JS如何设置获取盒模型对应的宽和高 实例题（根据盒模型解释边距重叠） BFC（Block Formatting Context-块级格式化上下文，边距重叠解决方案） IFC(Inline Formatting Context-行级格式化上下文) BFC布局规则： 内部的Box会在垂直方向，一个接一个地放置。 Box垂直方向的距离由margin决定。属于同一个BFC的两个相邻Box的margin会发生重叠 每个元素的margin box的左边， 与包含块border box的左边相接触(对于从左往右的格式化，否则相反)。即使存在浮动也是如此。 BFC的区域不会与float box重叠，常用来清除浮动和布局。 BFC就是页面上的一个隔离的独立容器，容器里面的子元素不会影响到外面的元素。反之也如此。 计算BFC的高度时，浮动元素也参与计算 IFC布局规则： 框会从包含块的顶部开始，一个接一个地水平摆放。 摆放这些框的时候，它们在水平方向上的外边距、边框、内边距所占用的空间都会被考虑在内。在垂直方向上，这些框可能会以不同形式来对齐：它们可能会把底部或顶部对齐，也可能把其内部的文本基线对齐。能把在一行上的框都完全包含进去的一个矩形区域，被称为该行的行框。水平的margin、padding、border有效，垂直无效。不能指定宽高。 行框的宽度是由包含块和存在的浮动来决定。行框的高度由行高计算这一章所描述的规则来决定。 回答技巧： 基本概念： 标准模型与IE模型的区别，IE模型包含Padding进行计算Content内部部分的宽； 设置模型的方式： 123box-sizing: content-box; # 标准模型（浏览器默认）box-sizing: border-box; # IE模型 JS有几种方式： 1234567dom.style.width/height，取的是内联属性，如果是link的样式取不到的。dom.currentStyle.width/height 只有IE支持window.getComputedStyle(dom).width/heightdom.getBoundingClientRect().width/height 实例题： 元素重叠要注意： 兄弟元素的重叠，重叠的原则取最大值 空元素，取margin-top,margin-bottom一个最大值作为边距 BFC解决边距重叠解决方案： BFC基本概念 BFC原理（垂直方向会重叠，不会清除FLEX布局，不会影响外面的元素，Float元素会参与计算） 如何创建BFC（overflow:hidden/visible，float不为None，position值不为relative或者static，display属性table/table-cell） BFC使用场景 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; html * &#123; padding: 0; margin: 0; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;section id=&quot;sec&quot;&gt; &lt;style media=&quot;screen&quot;&gt; #sec &#123; background: red; /* overflow: hidden; */ &#125; .child &#123; height: 100px; margin-top: 10px; background: yellow; &#125; &lt;/style&gt; &lt;article class=&quot;child&quot;&gt;&lt;/article&gt; &lt;/section&gt; &lt;!-- 例子2，关于Margin --&gt; &lt;section id=&quot;margin&quot;&gt; &lt;style&gt; #margin &#123; background: pink; overflow: hidden; &#125; #margin &gt; p &#123; margin: 5px auto 25px; background: red; &#125; &lt;/style&gt; &lt;p&gt;1&lt;/p&gt; &lt;p&gt;2&lt;/p&gt; &lt;p&gt;3&lt;/p&gt; --------- &lt;p&gt;1&lt;/p&gt; &lt;!-- 套一个DIV，使用BFC方式 --&gt; &lt;div style=&quot;overflow:hidden&quot;&gt; &lt;p&gt;2&lt;/p&gt; &lt;/div&gt; &lt;p&gt;3&lt;/p&gt; &lt;/section&gt; &lt;!-- BFC的应用 --&gt; &lt;section id=&quot;layout&quot;&gt; &lt;style&gt; #layout &#123; background: red; &#125; #layout .left &#123; float: left; width: 100px; height: 100px; background: pink; &#125; #layout .right &#123; height: 110px; background: gray; overflow: auto; # 这一行，使right的元素可以向下延伸，而不会向左进行延伸 &#125; &lt;/style&gt; &lt;div class=&quot;left&quot;&gt;&lt;/div&gt; &lt;div class=&quot;right&quot;&gt;&lt;/div&gt; &lt;/section&gt; &lt;!-- BFC子元素，即使是float也会参与高度计算 --&gt; &lt;section id=&quot;float&quot;&gt; &lt;style&gt; #float &#123; background: red; /* overflow: auto; */ /* float: none; */ &#125; #float .float&#123; float: left; &#125; &lt;/style&gt; &lt;div class=&quot;float&quot;&gt; 我是浮动元素 &lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; DOM事件 基本概念：DOM事件的级别； DOM事件类 事件级别 DOM0 element.onclick=function(){} DOM2 element.addEventListener(‘click’, function(){}, false) DOM3 element.addEventListener(‘keyup’,function(){}, false) IE中attachListener; DOM3增加了一些事件类型，鼠标、键盘事件； DOM事件模型（冒泡、捕获） 捕获是从上往下，冒泡是从下至上； 捕获代码演示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt; &lt;title&gt;Event&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=&quot;ev&quot;&gt; &lt;style&gt; #ev &#123; width: 300px; height: 100px; background: red; color: #fff; text-align: center; line-height: 100px; &#125; &lt;/style&gt; 目标元素 &lt;/div&gt; &lt;script&gt; var ev = document.getElementById(&#x27;ev&#x27;) window.addEventListener(&#x27;click&#x27;, function()&#123; console.log(&#x27;window capture&#x27;) &#125;, true) document.addEventListener(&#x27;click&#x27;, function()&#123; console.log(&#x27;document capture&#x27;) &#125;, true) document.documentElement.addEventListener(&#x27;click&#x27;, function()&#123; console.log(&#x27;html capture&#x27;) &#125;, true) document.body.addEventListener(&#x27;click&#x27;, function()&#123; console.log(&#x27;body capture&#x27;) &#125;, true) ev.addEventListener(&#x27;click&#x27;, function()&#123; console.log(&#x27;ev capture&#x27;) &#125;, true) &lt;/script&gt;&lt;/body&gt; 在console里面打印的信息： 12345window capturedocument capturehtml capturebody captureev capture 上面的输出顺序不受定义先后顺序的影响，说明捕获的流程是从上至下，一层又一层。冒泡是相反的，可以把true全改成false来试验一下。 DOM事件流； 事件流是指用户侧触发了事件之后，事件是如何传递并最终在目标对象上触发相应的操作的。 一个完整的事件流包含：1. 捕获阶段；2. 目标阶段；3. 冒泡阶段 描述DOM事件捕获的具体流程； window -&gt; document -&gt; html标签 -&gt; body -&gt; 父元素 -&gt; 子元素 -&gt; 目标元素 Event对象的常见应用 event.preventDefault()阻止默认事件 event.stopPropagation() 阻止冒泡 event.stopImmediatePropagation() 事件响应优先级，A,B同时绑定在某元素上，如果在A触发中，加入该方法，即B元素上的事件就不会触发 event.currentTarget事件委托，多个元素，给父级元素绑定事件的时候，currentTarget代表的是绑定事件的父级元素 event.target获取被点击的元素 参考资料1： the currentTarget refers to the element that the event listener directly attached to while the target still refers to the specific &lt;a&gt; we clicked. JavaScript Event Delegation, and event.target vs. event.currentTarget 参考资料2: e.target = The thing under the mouse (as ben says… the thing that triggers the event). e.currentTarget = The thing before the dot… (see below) Difference between e.target and e.currentTarget 自定义事件 12345var eve = new Event(&#x27;customEventName&#x27;)elem.addEventListener(&#x27;customEventName&#x27;, function()&#123; console.log(&#x27;customEventName&#x27;)&#125;)elem.dispatchEvent(eve) Event对象可以指定事件名，但是当需要给事件再传递一些数据的时候使用CustomEvent对象； HTTP协议 HTTP协议的主要特点 简单快速：UII统一资源符，资源是是固定的 灵活：HTTP头部分有数据类型，通过HTTP协议可以完成不同类型的数据传输 无连接：连接一次就会断掉 无状态：客户端与服务端是相对独立的，服务端没有记录客户的状态的 服务端通过session的方式来记录用户信息与HTTP协议本身无关，HTTP协议未记录客户端的相关信息 HTTP报文的组成部分 HTTP报文组成有请求报文 + 响应报文； 请求报文有请求行（HTTP方法、页面地址、HTTP协议及版本）、请求头（key-value值及类型）、空行、请求体； 响应报文有状态行、响应头、空行、响应 体； HTTP方法 GET 获取资源 POST 传输资源 PUT 更新资源 DELETE 删除资源 HEAD 获得报文首部 POST和GET的区别 GET在浏览器回退时无害的，而POST会再次请求 GET产生的URL地址可以被收藏，而POST不可以 GET请求会被浏览器主动缓存，而POST不会，除非手动设置 GET请求只能URL编码，而POST支持多种编码方式 GET请求参数会完整保留在浏览器历史记录里，而POST中的参数不会被保留 GET请求在URL中传递的参数有长度限制（基本是2KB），而POST没有限制 对参数的数据类型，GET只接受ASCII字符，而POST没有限制 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息 GET参数通过URL传递，POST放在Request Body中 HTTP状态码 1xx: 指示信息-表示请求已接收，继续处理 2xx：成功-表示请求已被成功接收 3xx：重定向-要完成请求必须进行更进一步的操作 4xx：客户端错误-请求有语法错误或请求无法实现 5xx：服务器错误-服务器未能实现合法的请求 常见的状态码： 200 OK：客户端请求成功 206 Partial Content：客户发送了一个带有Range头的GET请求，服务器完成了它 301 Moved Permanently：所请求的页面已经转移至新的URL 302 Found：所请求的页面已经临时转移至新的URL 304 Not Modified：客户端有缓冲的文档并发出了一个条件性的请求，服务器告诉客户，原来缓冲的文档还可以继续使用 400 Bad Request：客户端请求有语法错误，不能被服务器所理解 401 Unauthorized：请求未经制空权，这个 状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden：对被请求的页面被禁止 404 Not Found: 请求资源不存在 500 Internal Server Error：服务器发生不可预期的错误原来缓冲的文档还可以继续使用 503 Server Unavailable：请求未完成，服务器临时过载或当机，一段时间可能恢复正常 什么是持久连接 HTTP协议采用“请求-应用”模式，当使用普通模式，即非Keep-Alive模式时，每个请求/应答客户和服务器都要新建立一个连接，完成之后立即断开连接（HTTP协议为无连接的协议） 当使用Keep-Alive模式（又称持久连接、连接重用）时，Keep-Alive功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive功能避免了建立或者重新建立连接。 HTTP协议1.1版本才开始支持Keep-Alive模式 什么是管线化 在使用持久连接的情况下，某个连接上的消息的传递类似于： 请求1-&gt;响应1-&gt;请求2-&gt;响应2-&gt;请求3-&gt;响应3 某个连接上的消息变成了类似这样 请求1-&gt;请求2-&gt;请求3-&gt;响应1-&gt;响应2-&gt;响应3 管线化的特点： 管线化机制通过持久连接完成，仅HTTP/1.1支持此技术 只有GET和HEAD请求可以进行管线化，而POST则有所限制 初次创建连接时，不应启动管线机制，因为对方（服务器）不一定支持HTTP/1.1版本的协议 管线化不会影响响应到来的顺序，如上面的例子所示，响应返回的顺序并未改变 HTTP/1.1 要求服务器端支持管线化，但并不要求服务器端也对响应进行管线化处理，只是要求对于管线化的请求不失败即可 由于上面提到的服务端问题，开启管线化很可能并不会带来大幅度的性能提升，而且很多服务器端和代理程序对管线化的支持并不好，因为现代浏览器如Chrome和Firefox默认并未开启管线化支持 面向对象内容部分 原型链 创建对象有几种方法 方法一： 12var o1 = &#123; name: &#x27;o1&#x27;&#125;var o11 = new Object(&#123; name: &#x27;o11&#x27;&#125;) 方法二： 12var M = function()&#123;this.name = &#x27;o2&#x27;&#125;var o2 = new M() 方法三：(这个是很多同学答不上来的一种方法) 1var P = &#123; name: &#x27;o3&#x27; &#125; 原型、构造函数、实例、原型链 任何函数都可以当作是构造函数 只要是函数被new使用了，后面的就是一个构造函数 构造函数可以通过New来生成一个实例 函数都有一个prototype属性，这个是JS引擎给函数初始化的一个属性。 原型链的基本功能：任何一个实例对象，通过原型链找到它上面的原型对象的方法和属性都是被实例所共享的。 一个简单的例子： 12345678910&lt;script&gt;var M = function(name)&#123;this.name= name&#125;var o3 = new M(&#x27;o3&#x27;)M.prototype.say = function() &#123; console.log(&#x27;say hi&#x27;)&#125;var o5 = new M(&#x27;o5&#x27;)&lt;/script&gt; 函数才有prototype，对象是没有prototype的；只有实例对象才有__proto__对象。 instanceof的原理 上面实例中的例子： 123456789101112o3 instanceof M 返回true，原因，o3是M的是一实例。o3 instanceof Object返回true，原因，只要是原型链上的构造函数，都被看成是o3的一个构造函数o3.__proto === M.prototype返回trueM.prototype.__proto__ === Object.prototype返回trueo3.__proto__.constructor === M返回trueo3.__proto__.contructor === Object返回false new运算符 按照New原理，写一个New2方法： 123456789var new2 = function(func)&#123; var o = Object.create(func.prototype) var k = func.call(o) if (typeof k === &#x27;object&#x27;) &#123; return k &#125; else &#123; return o &#125;&#125; Console里面试验一下： 12345678910111213o6 = new2(M)这里的M.__proto__: Objecto6 instanceof M返回true，o6是M的一个实例o6 instanceof Object返回trueo6.__proto__.constructor === M返回trueM.prototype.walk = function()&#123;console.log(&#x27;walk&#x27;)&#125;o6.walk()返回walko3.walk()返回walk 面向对象类 类与实例 类的声明 123456789101112131415/*** 类的声明*/function Animal () &#123; this.name = &#x27;name&#x27;&#125;/*** ES6中的Class的声明*/class Animal2 &#123; constructor () &#123; this.name = name; &#125;&#125; 生成实例 1234/*** 实例化*/console.log(new Animal(), new Animal2()) 类与继承 如何实现继承 12345678910111213141516171819202122/*** 借助构造函数实现继承*/function Parent1 () &#123; this.name = &#x27;parent1&#x27; this.play = [1,2,3]&#125;Parent1.prototype.say = function () &#123; console.log(&#x27;say Parent&#x27;)&#125;function Child1 () &#123; Parent1.call(this) // apply 改变了函数执行的上下文 this.type = &#x27;child1&#x27;&#125;console.log(new Child1())var s1 = new Child2()var s2 = new Child2()console.log(s1.play, s2.play)s1.play.push(4)console.log(s1.play, s2,play)输出[1,2,3,4] 使用构造函数实现的继承，缺点：无法继承父类原型对象上的方法，而是只能继承构建函数内的属性 1234567891011/*** 借助原型链实现继承*/function Parent2 () &#123; this.name = &#x27;parent2&#x27;&#125;function Child2 () &#123; this.type = &#x27;child2&#x27;&#125;Child2.prototype = new Parent2()console.log(new Child2()) console中来验证一下： 1new Child2().__proto === Child2.prototype 缺点：因为子类是继承了父类的prototype，那么当改变父类的原型对象的值的时候，所有的实例都会跟着变化 1234567891011121314151617/*** 组合方式*/function Parent3 () &#123; this.name = &#x27;parent3&#x27; this.play = [1,2,3]&#125;function Child3 () &#123; Parent3.call(this) this.type = &#x27;child3&#x27;&#125;Child3.prototype = new Parent3()var s3 = new Child3()var s4 = new Child3()console.log(s3.play, s4.play)s3.play.push(4)console.log(s3.play, s4.play) Console中打印： 1(4) [1, 2, 3, 4] (3) [1, 2, 3] 思考一下，有什么缺点？ Child3 new会实例化父类，prototype中又会实例化父类，父类的实例化执行了多次。 1234567891011121314151617181920/** * 组合继承的优化 */function Parent4 () &#123; this.name = &#x27;parent4&#x27; this.play = [1,2,3]&#125;function Child4 () &#123; Parent4.call(this) this.type = &#x27;child4&#x27;&#125;Child4.prototype = Parent4.prototypevar s5 = new Child4()var s6 = new Child4()console.log(s5.play, s6.play)s5.play.push(4)console.log(s5.play, s6.play)console.log(s5 instanceof Child4, s5 instanceof Parent4)console.log(s5.constructor) Console中打印 12(3) [1, 2, 3] (3) [1, 2, 3](4) [1, 2, 3, 4] (3) [1, 2, 3] 这种方式有没有不足？ 不能通过instanceof来判断s5,s6是Child的实例，还是Parent直接实例出来的 1234567891011121314151617181920/*** 组合继承优化2*/function Parent5 () &#123; this.name = &#x27;parent5&#x27; this.play = [1,2,3]&#125;function Child5 () &#123; Parent5.call(this) this.type = &#x27;child5&#x27;&#125;Child5.prototype = Object.create(Parent5.prototype) // __proto__/*这样不仅实现了继承，而且还实现了原型对象的隔离*/Child5.prototype.constructor = Child5var s7 = new Child5()var s8 = new Child5()console.log(s7 instanceof Child5, s7 instanceof Parent5)console.log(s7.constructor) 继承的几种方式 构建函数 + 原型链 通信跨域通信、普通的通信 什么是同源策略及限制 同源策略限制从一个源加载的文档或脚本如何与来自另一个源的资源进行交互。这是一个用于隔离潜在恶意文件的关键的安全机制。 源：协议 + 域名 + 端口 Cookie、LocalStorage和IndexDB无法读取 DOM无法获得 AJAX请求不能发送 前后端如何通信 (1)AJAX (2)WebSocket (3)CORS “跨域资源共享”（Cross-origin resource sharing） 如何创建Ajax(Asynchronous JavaScript and XML) (1)XMLHttpRequest对象的工作流程 (2)兼容性处理 (3)事件的触发条件 (4)事件的触发顺序 跨域通信的几种方式 (1)JSONP 参考源码：jsonp.js 原理是什么？怎么实现的？ 主要原理是：客户端告诉服务端Callback(回调函数名称，比如：jsonp)，客户端定义一个全局的jsonp函数，通过执行jsonp函数，获取函数里面的数据。 12345678910111213141516171819202122232425262728293031323334/** * [function jsonp] * @param &#123;[type]&#125; url [description] * @param &#123;[type]&#125; onsucess [description] * @param &#123;[type]&#125; onerror [description] * @param &#123;[type]&#125; charset [description] * @return &#123;[type]&#125; [description] */util.jsonp = function (url, onsuccess, onerror, charset) &#123; var callbackName = util.getName(&#x27;tt_player&#x27;); window[callbackName] = function () &#123; if (onsuccess &amp;&amp; util.isFunction(onsuccess)) &#123; onsuccess(arguments[0]); &#125; &#125;; var script = util.createScript(url + &#x27;&amp;callback=&#x27; + callbackName, charset); script.onload = script.onreadystatechange = function () &#123; if (!script.readyState || /loaded|complete/.test(script.readyState)) &#123; script.onload = script.onreadystatechange = null; // 移除该script的 DOM 对象 if (script.parentNode) &#123; script.parentNode.removeChild(script); &#125; // 删除函数或变量 window[callbackName] = null; &#125; &#125;; script.onerror = function () &#123; if (onerror &amp;&amp; util.isFunction(onerror)) &#123; onerror(); &#125; &#125;; document.getElementsByTagName(&#x27;head&#x27;)[0].appendChild(script);&#125;; (2)Hash 参考源码：Ajax参考 12345678// 利用hash，场景是当前页面 A 通过iframe或frame嵌入了跨域的页面 B// 在A中伪代码如下：var B = document.getElementsByTagName(&#x27;iframe&#x27;);B.src = B.src + &#x27;#&#x27; + &#x27;data&#x27;;// 在B中的伪代码如下window.onhashchange = function () &#123;var data = window.location.hash;&#125;; (3)postMessage 123456789// postMessage// 窗口A(http:A.com)向跨域的窗口B(http:B.com)发送信息Bwindow.postMessage(&#x27;data&#x27;, &#x27;http://B.com&#x27;);// 在窗口B中监听Awindow.addEventListener(&#x27;message&#x27;, function (event) &#123; console.log(event.origin); console.log(event.source); console.log(event.data);&#125;, false); (4)Websocket 1234567891011121314151617// Websocket【参考资料】http://www.ruanyifeng.com/blog/2017/05/websocket.htmlvar ws = new WebSocket(&#x27;wss://echo.websocket.org&#x27;);ws.onopen = function (evt) &#123; console.log(&#x27;Connection open ...&#x27;); ws.send(&#x27;Hello WebSockets!&#x27;);&#125;;ws.onmessage = function (evt) &#123; console.log(&#x27;Received Message: &#x27;, evt.data); ws.close();&#125;;ws.onclose = function (evt) &#123; console.log(&#x27;Connection closed.&#x27;);&#125;; (5)CORS 123456789// CORS【参考资料】http://www.ruanyifeng.com/blog/2016/04/cors.html// url（必选），options（可选）fetch(&#x27;/some/url/&#x27;, &#123; method: &#x27;get&#x27;,&#125;).then(function (response) &#123;&#125;).catch(function (err) &#123; // 出错了，等价于 then 的第二个参数，但这样更好用更直观&#125;); 安全安全分类分CSRF——跨站请求伪造（英语：Cross-site request forgery）, XSS——跨域脚本攻击(英语：Cross-site scripting) CSRF可能会考到： 基本概念与缩写 攻击原理 防御措施 (1)Token验证 (2)Referer验证 (3)隐藏令牌 XSS可能会考到： 攻击原理 防御措施 参考：Web安全-XSS XSS是向页面注入JS，让JS去做它想做的事情；CSRF利用漏洞去执行接口，CSRF依赖用户需要登录网站。 算法基本的算法题： 排序 堆栈、队列、链表 递归 波兰式和逆波兰式 排序相关资料： 快速排序 选择排序 希尔排序 递归相关资料： 递归 波兰式与逆波兰式 理论 源码 如何准备？ 基本功 理解题目(如果不会，可以问问面试官，解释一下题目) 想到哪里写到哪里 如果不会，可以问一下(这里我知道怎么做，需要用XX什么原理，但是我这时不知道接下来怎么做了)","categories":[{"name":"前端跳槽面试必备技巧","slug":"前端跳槽面试必备技巧","permalink":"https://www.toimc.com/categories/%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"前端面试","slug":"前端面试","permalink":"https://www.toimc.com/tags/%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"name":"技巧总结","slug":"技巧总结","permalink":"https://www.toimc.com/tags/%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/"}]},{"title":"Docker入门之安装教程","slug":"docker入门之安装教程","date":"2019-03-28T01:30:33.000Z","updated":"2019-12-27T08:58:30.000Z","comments":true,"path":"docker入门之安装教程/","link":"","permalink":"https://www.toimc.com/docker%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/","excerpt":"本篇介绍了在Mac OS, Windows, Linux下的Docker安装方法。","text":"本篇介绍了在Mac OS, Windows, Linux下的Docker安装方法。 先来一个官方的介绍： Docker Engine is available for Linux (CentOS, Debian, Fedora, Oracle Linux, RHEL, SUSE, and Ubuntu) or Windows Server operating systems and is based on containerd - the open source container runtime project that Docker donated to the Cloud Native Computing Foundation (CNCF) in 2017. It is available as both a free community-supported engine and as a commercially-supported enterprise engine (Docker Engine-Enterprise) that also forms the foundation for an enterprise container platform. 基本上全平台已经覆盖，英文好的同学，可以自取。 Mac OS上的Docker安装方法方法一官方dmg： 官方下载地址： Docker Descktop for Mac 对系统的要求： Requires Apple Mac OS Sierra 10.12 or above. Download Docker Toolbox for previous OS versions. 只要系统是 Mac OS Sierra 10.12以上即可。 下载完Docker.dmg安装包之后，双击即可以安装，可能需要系统管理员权限，输入密码即可。 运行过后，小图标： 安装完之后，在终端工具中，使用docker version来查看Docker版本。 设置中国区加速地址： 阿里云加速：Docker 镜像加速器 方法二brew cask： 123456brew update brew cask install docker# 删除的方法, 还需要手动删除Docker.appbrew cask uninstall docker 上面的命令将会把Docker安装在Applications目录下。 Windows上Docker安装官方下载地址：Docker Desktop for Windows 对系统的要求： Requires Microsoft Windows 10 Professional or Enterprise 64-bit. For previous versions get Docker Toolbox. 需要Windows 10专业版及企业的64位版本，在Windows server 2016以上亲测是可用的。Windows 8/7/Vista/Xp之类的，就别想了，老实去装Windows 10或者虚拟机中去使用。 Linux上Docker安装Centos中Docker安装方法 先删除旧的版本(如果没有可以跳过) 12345678$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 安装必须的依赖： 123$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 添加stable的Docker-ce的源： 123$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 安装docker-ce: 1$ sudo yum install docker-ce docker-ce-cli containerd.io 选择指定的安装版本(可选) 123456$ yum list docker-ce --showduplicates | sort -rdocker-ce.x86_64 3:18.09.1-3.el7 docker-ce-stabledocker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stabledocker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stabledocker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stable 我们来举个例子，比如我们要安装3:18.09.1-3.el7这个版本，使用如下命令结构： 1$ sudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io 命令说明： 第一部分是docker-ce，第二部分是版本号18.09.1，看明白了吗？就是这样子： 1$ sudo yum install -y docker-ce-18.09.1 docker-ce-cli-18.09.1 启动服务并测试一下： 12345678910111213141516171819202122232425262728293031# 启动服务sudo systemctl start docker# 来一个Hello World吧sudo docker run hello-worldUnable to find image &#x27;hello-world:latest&#x27; locallylatest: Pulling from library/hello-world1b930d010525: Pull completeDigest: sha256:2557e3c07ed1e38f26e389462d03ed943586f744621577a99efb77324b0fe535Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 如果看到上面的提示，说明Docker已经成功安装并运行了了。 关于升级&amp;删除： 升级： 12345# 更新所有yum -y update# 更新指定yum -y update docker-ce docker-ce-cli containerd.io 删除： 1234sudo yum remove docker-ce# 删除文件系统sudo rm -rf /var/lib/docker Debian中Docker的安装方法 删除旧的版本(可跳过) 1$ sudo apt-get remove docker docker-engine docker.io containerd runc 安装依赖： 123456789101112131415161718$ sudo apt-get update$ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg2 \\ software-properties-common # 添加GPG key$ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -$ sudo apt-key fingerprint 0EBFCD88pub 4096R/0EBFCD88 2017-02-22 Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid Docker Release (CE deb) &lt;docker@docker.com&gt;sub 4096R/F273FCD8 2017-02-22 使用stable安装源： x86_64 / amd64armhfarm641234$ sudo add-apt-repository \\&quot;deb [arch=amd64] https://download.docker.com/linux/debian \\$(lsb_release -cs) \\stable&quot;1234$ sudo add-apt-repository \\&quot;deb [arch=armhf] https://download.docker.com/linux/debian \\$(lsb_release -cs) \\stable&quot;1234$ sudo add-apt-repository \\&quot;deb [arch=arm64] https://download.docker.com/linux/debian \\$(lsb_release -cs) \\stable&quot; 安装docker-ce： 123$ sudo apt-get update$ sudo apt-get install docker-ce docker-ce-cli containerd.io 安装指定的版本：(可选) 1234567$ apt-cache madison docker-ce docker-ce | 5:18.09.1~3-0~debian-stretch | https://download.docker.com/linux/debian stretch/stable amd64 Packages docker-ce | 5:18.09.0~3-0~debian-stretch | https://download.docker.com/linux/debian stretch/stable amd64 Packages docker-ce | 18.06.1~ce~3-0~debian | https://download.docker.com/linux/debian stretch/stable amd64 Packages docker-ce | 18.06.0~ce~3-0~debian | https://download.docker.com/linux/debian stretch/stable amd64 Packages ... 安装格式： 1$ sudo apt-get install docker-ce=&lt;VERSION_STRING&gt; docker-ce-cli=&lt;VERSION_STRING&gt; containerd.io 举例说明：比如要安装5:18.09.1~3-0~debian-stretch 版本的docker的话： 1$ sudo apt-get install docker-ce=18.09.1 docker-ce-cli=18.09.1 containerd.io 启动服务并测试： 123456$ sudo service docker start# 查看Docker运行状态$ sudo service docker status$ sudo docker run hello-world Ubuntu中Docker安装方法 删除旧的版本(可跳过) 1$ sudo apt-get remove docker docker-engine docker.io containerd runc 安装依赖： 123456789101112131415161718$ sudo apt-get update$ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common # 添加GPG key$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -$ sudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid [ unknown] Docker Release (CE deb) &lt;docker@docker.com&gt;sub rsa4096 2017-02-22 [S] 使用stable安装源： x86_64/amd64armhfarm64ppc64le (IBM Power)s390x (IBM Z)1234$ sudo add-apt-repository \\ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot;1234$ sudo add-apt-repository \\ &quot;deb [arch=armhf] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot;1234$ sudo add-apt-repository \\ &quot;deb [arch=arm64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot;1234$ sudo add-apt-repository \\ &quot;deb [arch=ppc64el] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot;1234$ sudo add-apt-repository \\ &quot;deb [arch=s390x] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot; 安装docker-ce： 123$ sudo apt-get update$ sudo apt-get install docker-ce docker-ce-cli containerd.io 安装指定的版本：(可选) 1234567$ apt-cache madison docker-ce docker-ce | 5:18.09.1~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:18.09.0~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18.06.1~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18.06.0~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages ... 安装格式： 1$ sudo apt-get install docker-ce=&lt;VERSION_STRING&gt; docker-ce-cli=&lt;VERSION_STRING&gt; containerd.io 举例说明：比如要安装5:18.09.1~3-0~ubuntu-xenial版本的docker的话： 1$ sudo apt-get install docker-ce=18.09.1 docker-ce-cli=18.09.1 containerd.io 启动服务并测试： 123456$ sudo service docker start# 查看Docker运行状态$ sudo service docker status$ sudo docker run hello-world Docker-compose集合命令Compose工具是一个批量工具，用于运行与管理多个docker容器。 官方文档：Install Docker Compose 在Mac/Windows中，已经集成了docker-compose命令 在WindowsServer中先启动PowerShell 1[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 然后运行如下命令： 1Invoke-WebRequest &quot;https://github.com/docker/compose/releases/download/1.23.2/docker-compose-Windows-x86_64.exe&quot; -UseBasicParsing -OutFile $Env:ProgramFiles\\Docker\\docker-compose.exe 然后测试一下：docker-compose --version Linux中： 123456789# 下载docker-composesudo curl -L &quot;https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose# 给予执行权限sudo chmod +x /usr/local/bin/docker-compose# 测试命令$ docker-compose --versiondocker-compose version 1.23.2, build 1110ad01","categories":[{"name":"Docker入门","slug":"Docker入门","permalink":"https://www.toimc.com/categories/Docker%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.toimc.com/tags/Docker/"}]},{"title":"常用vps测试脚本/Linux软硬件测试脚本","slug":"vps测试脚本-Linux软硬件测试脚本","date":"2019-03-27T16:11:04.000Z","updated":"2019-12-27T08:58:30.000Z","comments":true,"path":"vps测试脚本-Linux软硬件测试脚本/","link":"","permalink":"https://www.toimc.com/vps%E6%B5%8B%E8%AF%95%E8%84%9A%E6%9C%AC-Linux%E8%BD%AF%E7%A1%AC%E4%BB%B6%E6%B5%8B%E8%AF%95%E8%84%9A%E6%9C%AC/","excerpt":"这里有各种测试VPS硬件/网络/IO的脚本，比如：bench,Superbench,Zbench,LemonBench,etc，快来试试吧。","text":"这里有各种测试VPS硬件/网络/IO的脚本，比如：bench,Superbench,Zbench,LemonBench,etc，快来试试吧。 下面我们会在一台阿里云的4core 8G 2M的Centos 7.6的服务器上进行测试，即本站使用VPS。 Bench.sh脚本运行 12345wget -qO- bench.sh | bash# 或者 curl -Lso- bench.sh | bash 如果提示没有wget或者curl命令，使用yum install -y wget或者apt-get install -y wget即可。 Github地址：https://github.com/teddysun/across/blob/master/bench.sh 还有其他的一些Teddysun大神写的脚本，在上级目录中。 特点： 显示当前测试的各种系统信息； 取自世界多处的知名数据中心的测试点，下载测试比较全面； 支持 IPv6 下载测速； IO 测试三次，并显示平均值。 缺点： 感觉耗时比较长。 截止博文时间最近的一次更新：2018年6月3日 结果截图： SuperBench(推荐)老鬼的测试脚本：https://www.oldking.net/350.html 下载地址：https://github.com/oooldking/script/blob/master/superbench.sh 使用方法： 12345wget -qO- --no-check-certificate https://raw.githubusercontent.com/oooldking/script/master/superbench.sh | bash# 或者curl -Lso- -no-check-certificate https://raw.githubusercontent.com/oooldking/script/master/superbench.sh | bash 特点： 改进了显示的模式，基本参数添加了颜色，方面区分与查找。 I/O测试，更改了原来默认的测试的内容，采用小文件，中等文件，大文件，分别测试IO性能，然后取平均值。 速度测试替换成了 Superspeed 里面的测试，第一个默认节点是，Speedtest 默认，其他分别测试到中国电信，联通，移动，各三个不同地区的速度。 截止博文时间最近的一次更新：2018.10.25 v1.1.3 增加TCP拥塞控制检测 最新的一次更新 本VPS测试结果： · http://www.speedtest.net/result/8144104023.png · https://paste.ubuntu.com/p/Jhh2FFvYQf/ 结果截图： Zbench脚本由漏水和kirito，基于Oldking大佬 的 SuperBench，然后加入Ping以及路由测试的功能，还能生成测评报告，分享给其他人查看测评数据 github地址：https://github.com/FunctionClub/ZBench 使用方法： 中文版： 1wget -N --no-check-certificate https://raw.githubusercontent.com/FunctionClub/ZBench/master/ZBench-CN.sh &amp;&amp; bash ZBench-CN.sh 英文版： 1wget -N --no-check-certificate https://raw.githubusercontent.com/FunctionClub/ZBench/master/ZBench.sh &amp;&amp; bash ZBench.sh 截止博文时间最近的一次更新：2018年6月31号 优点： 可以生成测试报告，见Demo测试地址：https://www.zhujiboke.com/zbench-example.html 缺点： 耗时比较久，建立使用screen。 结果截图： LemonBench(推荐)由于LemonBench还在开发中，程序的功能可能会做适当添加与删除。 所以目前的版本品质仅供参考！LemonBench目前涵盖了如下测试： 服务器基础信息 (CPU信息/内存信息/Swap信息/磁盘空间信息等) Speedtest网速测试 (本地到最近源及国内各地域不同线路的网速) 磁盘测试 (4K块/1M块 直接写入测试) 路由追踪测试 (追踪到国内和海外不同线路的路由信息) Spoofer测试 (获取详细网络信息，快速判断服务器接入线路) LemonBench使用起来非常简单，只需要复制粘贴再来个回车就可以轻松启动测试。 使用方法： 1curl -fsSL https://ilemonrain.com/download/shell/LemonBench.sh | bash 如果你的服务器上安装有 wget 工具，请使用以下命令执行脚本： 1wget -qO- https://ilemonrain.com/download/shell/LemonBench.sh | bash 提示： 12345678910111213141516171819202122[root@imooc bench]# wget -qO- https://ilemonrain.com/download/shell/LemonBench.sh | bash -s [TestMode] -f LBench 服务器测试工具 LemonBench Server Test Toolkit 20190206 BetaVersion &gt; 帮助文档 HelpDocument 使用方法 Usage ： (1) wget -qO- https://ilemonrain.com/download/shell/LemonBench.sh | bash -s [TestMode] (2) curl -fsSL https://ilemonrain.com/download/shell/LemonBench.sh | bash -s [TestMode] 可选测试参数 Available Parameters : -f, --fast, fast 执行快速测试 -F, --full, full 执行完整测试 spfast, --speedtest-fast 仅执行Speedtest网速测试 (快速测试) spfast, --speedtest-fast 仅执行Speedtest网速测试 (完整测试) dtfast, --disktest-fast 仅执行磁盘性能测试 (快速测试) dtfast, --disktest-fast 仅执行磁盘性能测试 (完整测试) btfast, --besttrace-fast 仅执行路由追踪测试 (快速测试) btfast, --besttrace-full 仅执行路由追踪测试 (完整测试) spf, --spoofer 仅执行Spoofer测试 使用快速测试: 1wget -qO- https://ilemonrain.com/download/shell/LemonBench.sh | bash -s fast 结果截图： UnixBench性能测试也是TeddySun的作品。 UnixBench是一个类unix系（Unix，BSD，Linux）统下的性能测试工具，一个开源工具，被广泛用与测试linux系统主机的性能。Unixbench的主要测试项目有：系统调用、读写、进程、图形化测试、2D、3D、管道、运算、C库等系统基准性能提供测试数据。 使用方法： 12345678# 下载脚本wget --no-check-certificate https://github.com/teddysun/across/raw/master/unixbench.sh# 给权限chmod +x unixbench.sh# 执行./unixbench.sh 内存检测脚本检测VPS真实可分配内存的小工具，适用于检测VPS超售情况。本程序检测的可分配内存指的是用户使用时最大能占用的内存量。 使用方法： 123456#CentOS / RHELyum install wget -yyum groupinstall &quot;Development Tools&quot; -ywget https://raw.githubusercontent.com/FunctionClub/Memtester/master/memtester.cppgcc -l stdc++ memtester.cpp./a.out 123456#Ubuntu / Debianapt-get updateapt-get install wget build-essential -ywget https://raw.githubusercontent.com/FunctionClub/Memtester/master/memtester.cppgcc -l stdc++ memtester.cpp./a.out Linux中查看本机IP的方法使用方法： 1curl [下面的链接] 例如： 使用cip.cc： 12345678910[root@imooc ~]# curl cip.ccIP : 47.105.212.161地址 : 中国 山东 青岛运营商 : 阿里云/电信/联通/移动/铁通/教育网数据二 : 浙江省杭州市 | 阿里云数据三 : 中国浙江省杭州市 | 阿里巴巴URL : http://www.cip.cc/47.105.212.161 使用ipinfo.io： 1234567891011[liwei@MBP ~]$ curl ipinfo.io&#123; &quot;ip&quot;: &quot;173.242.117.48&quot;, &quot;hostname&quot;: &quot;173.242.117.48.16clouds.com&quot;, &quot;city&quot;: &quot;Los Angeles&quot;, &quot;region&quot;: &quot;California&quot;, &quot;country&quot;: &quot;US&quot;, &quot;loc&quot;: &quot;34.0584,-118.2780&quot;, &quot;postal&quot;: &quot;90017&quot;, &quot;org&quot;: &quot;AS25820 IT7 Networks Inc&quot;&#125; 使用ip.cn和ipip.net(不准)： 12345[root@imooc ~]# curl https://ip.cn当前 IP: 47.105.212.161 来自: 山东省青岛市 阿里云[liwei@MBP ~]$ curl myip.ipip.net当前 IP：173.242.117.48 来自于：美国 加利福尼亚州 洛杉矶 it7.net 几个网址也非常好记忆 ip.cn (推荐) ipinfo.io (推荐) cip.cc (推荐) ifconfig.me myip.ipip.net Screen大法好由于测试用时较长，为防止发生SSH断线意外，推荐放在screen中运行！** 1234567891011121314# Centos中yum install -y screen# Debian &amp; Ubuntuapt-get install -y screen# 创建screen会话screen -S mytest# 使用Ctrl + a d退出Screen会话，或者直接exit命令# 返回screenscreen -r mytest# screen 列表screen -ls","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.toimc.com/tags/Linux/"},{"name":"vps","slug":"vps","permalink":"https://www.toimc.com/tags/vps/"}]},{"title":"慕课网《前端跳槽面试必备技巧》——如何看待面试","slug":"慕课网《前端跳槽面试必备技巧》——如何看待面试","date":"2019-03-24T15:28:54.000Z","updated":"2021-03-02T15:35:52.138Z","comments":true,"path":"慕课网《前端跳槽面试必备技巧》——如何看待面试/","link":"","permalink":"https://www.toimc.com/%E6%85%95%E8%AF%BE%E7%BD%91%E3%80%8A%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7%E3%80%8B%E2%80%94%E2%80%94%E5%A6%82%E4%BD%95%E7%9C%8B%E5%BE%85%E9%9D%A2%E8%AF%95/","excerpt":"面试，字面意思，面对面的考试。面试是一场糟心设计的对面试者的考察活动。通过课程的学习笔记，整理相关的资料与大家分享。原课程链接：前端跳槽面试必备技巧","text":"面试，字面意思，面对面的考试。面试是一场糟心设计的对面试者的考察活动。通过课程的学习笔记，整理相关的资料与大家分享。原课程链接：前端跳槽面试必备技巧 前置导学面试环节有哪些 面试过程是严肃的，知道了基础，会做项目，不一定会拿到Offer。面试过程中，如何进行表述，把自己学习到的知识能展现出来是很重要的。 所以，对于面试者来说，如何写好简历是很重要的。因为面试官会从你的简历去挑一些他感兴趣的内容去问，去挖掘你的潜在可能，去了解你的知识与解决问题的能力。一份好的简历往往是走入职场的敲门砖！ 对于应聘生，积累一些解决问题的经验，加强基础知识的掌握(这也是更容易被考察的)； 对于社招，实际解决问题的能力+对应的业务/相似的业务背景+技能抽象/发展前景。 面试环节的设置： 基础知识测试 基础知识(HTML语义话、CSS等) 能力测试(在基础上的延伸) 基本的原理(缓存、原型链等) 简历的引导，自我介绍引导 负责人沟通(校招不会有，原因：人太多) 特色业务 项目背景 团队能力 HR面试 沟通 性格 潜力(技术生涯) 职位描述分析阅读职位描述，这是一个知己知彼的过程。 京东金融——前端工程师： 职位描述： 负责京东金融企业业务PC端与移动端相关的前端开发工作 解析：本岗位，PC+移动端相互交叉，对技术栈的要求是不一样的。 负责企业金融App H5开发，完成前端界面与后端交互开发 解析：是不是需要了解一下Hybird开发？JSbridge? 负责与后端工程师沟通协作，调试数据接口 解析：Mock数据开发 负责京东金融前端组件库的建立(相比与前3条，最重要的一条) 解析：1.原生js/css的理解；2.前端组件库的经验；3.通读/了解其他的UI库的组件，读过源码； 负责对现有系统 的优化与重构 解析：对现有工作与业务的需求；可以拿自己公司的系统或者项目作为例子，有哪些问题？是否需要重构？为什么需要重构？怎么去重构？这里去考查思考与判断能力。 面试准备的第一个初衷：判断该职位适合不适合自己，判断自己喜欢不喜欢，能不能Hold住；第二初衷， 技术准备需要做哪些？了解该企业需要什么样的人才？准备到一个什么样的程度？ 任职要求： 3年以上相关工作经验，精通HTML5我，了解HTML5最新规范，能够熟练去用HTML5特性构建移动端的WebApp; 解析：首先，对于3年的经验，这个不重要，如果说没有3年的经验，但是有足够好的项目或者能力的展示，是可以破格录取的。然后，对于H5的描述，再次说明了H5的重要性；隐藏的意思：看看这个人是否对新知识有学习的劲头，看看是否是对新技术是否有追求。 如何考察自己是否达到？很简单，问自己几个问题，看自己能不能答上来； 熟悉当前流行的JavaScript类库，熟悉JavaScript面向对象编程方法； 解析：面向对象编程，包括原型链也要比较熟悉。 熟悉Web标准，对表现与数据分离，HTML语义化等有一定的理解，至少熟悉一种前端MVC框架并且有实际经验(不限React，Vue，Angular等)； 解析：熟悉对新的web标准；理解表现与数据分离；准备一个自己做过的项目进行演示；语义话要避免DIV DIV DIV这样的全是DIV的写法；至少熟悉一种 + 实际经验，学习不等于实战经验。可能会问，遇到过什么开发问题，怎么解决的，这种问题。 具有前端架构分析与设计能力，一贯坚持编写易读、易维护、高质量、高效率的代码，习惯于OOP开发方式； 解析：对于架构分析针对的是高级的工程师，所以不面向初级的开发人员。因为刚刚入门的人，刚刚开始做的基本是业务。怎么去考虑？拿一个项目来进行分析：（1）目录结构怎么设计；（2）复用性怎么设计；（3）模块化怎么设计；（4）自动化测试怎么测；（5）上线的流程是什么？这些基础的东西都要想的非常清楚，非常周到。 写易读、易维护、高质量、高效率：很容易考察出来，这个可能会让你自己写代码，要学习代码规范。能抽象的尽量抽象，函数名不要写在一堆。 对用户可用性、用户体验，用户研究等相关知识有深入的了解和实践经验； 解析：不是考察技术的本身，是考察的完成这些功能，还是说考虑了这个功能是否好用、卡不卡？回答的思路：以往的项目怎么完成了任务，在完成的过程中，进行了什么样的思考，为了增强用户的体验。 对Web前端技术有强烈兴趣，能对Web前沿技术研究和新技术调研，有良好的学习能力和团队合作精神； 解析：注意“强烈”两个字，对团队的一种认可，对企业文化、公司文化的一种要求。去github上去看看排名靠前的github的项目，去看看用了哪些技术与工具。 了解Css预编译语言如Sass、less等； 解析：这个简单，也是基础。 熟悉Web构建工具Grunt\\Gulp，能够自己搭建前端构建环境； 解析：这个要一定好好准备，了解/熟悉/精通是三个概念。可以准备一下这些构建工具的区别在哪里，技术特点在哪里。 有服务端(不限语言)开发经验者优先。 解析：可以忽略，有时间也可以去看看。这里是对Nodejs的考察。不要轻易说自己精通，除非是自己真的擅长。 总结： 快速识别是否自己喜欢的。 能不能Hold住这个岗位，或者短期的准备能否达到要求。 职位描述，是强调对工作的工作职责，职位要求对技术深度的要求。 艺龙——前端工程师： 岗位描述： 负责艺龙酒店业务前端开发、使用系统化设计提高开发效率； 分析：说的很笼统；系统化设计：模块化设计、前后端分离； 负责推广运营活动的HTML5，采用canvas、css3、JS相关前端技术； 分析：这里的HTML5没有具体PC、移动端；明确canvas、css3、JS技术，如果做广告，可能是对做动画的技术的一些要求。普通的动画是DOM+CSS，或者是SVG做动画，第三种就是Canvas，可以做2D或者3D效果，用webGL的不多。 去了解一下GPU加速，Canvas的API，常用的一些动画的设计。 负责艺龙微信项目； 分析：去看看艺龙的微信小程序、微信公众号，了解微信自定义标签，对微信支付去了解一下。微信开发中遇到的一些坑。 艺龙前端框架的开发与维护、协助业务方解决应用问题。 分析：与京东的第4条类似。开发与维护说明，已经有一套内部的框架，需要升级维护。 岗位要求： 精通各种Web前端技术、包括HTML/CSS/Javascript等，3年以上工作经验； 分析：这点有一点点扯，不可能做到样样精通。 深刻理解Web标准，对可用性、可访问性等相关知识实际的了解和实践经验； 分析：同样是Web标准，主要是ES6。可用性、可访问性是指性能方面的准备，如何反馈给前端错误码，如何捕获异常。通常是JS运行异常，资源加载错误。 熟练使用工程化工具，熟悉webpack\\grunt\\sass优先； 分析：这里一样需要准备gulp。关于前端工程化，是前端开发人员必会的基础知识。 具有良好的代码风格、接口设计与程序架构； 分析：比较虚。 至少熟悉一门非web前端脚本的语言（如Java/Python)或Node.js，有实践经验； 分析：对后端的要求，说的是熟悉，所以要准备Node.js，不需要去准备如PHP。有教程可以快速过一下！认识有艺龙的同事，可以去问问里面的同事。这一条说明是全栈开发。 个性乐观开朗，逻辑性强，善于和各种背景的人合作。 分析：有深意的一点，对表述能力的要求。比如：在以往与哪些人怎么合作的，你们有没有通力解决什么问题？ 目的：通过职位描述去了解你不了解的公司的工作职责和技术要求，有针对性的面试，可以快速过滤自己不相关的岗位。 业务分析或实战模拟职位分析更偏向于方向与知识面，这一块，更加具体的分析公司的技术栈，业务特色，知识点的侧重。 下面看一下京东金融。 轮播，导航，页面布局，鼠标Hover效果（css3效果） 内容列表：理财，股票，购物（懒加载），保险，优惠券 技术细节从Chrome中的DevTools来看： 视频录制时间可以看到如下内容： webpack(source map没有关) vue jquery ES6语法 而笔者看到的： Source: JSONP Webpack Vue的Sourcemap已经关闭 看一下Element： Header部分，webkit渲染 Link: dns-prefetch，DNS预解析，网站性能优化。 Application: 字体图标，字体文件，字体自定义 LocalStorage/Session/Cookie 艺龙： 微信扫一扫：小程序，公众号 手机版就是H5 组件：日期控件、轮播图、鼠标Hover效果（background相关的知识），去了解一下如何实现（transition属性）； 看一下DevTools： 看一下Elements, network, sources Header 页面中JS全放在页面的Header中，关系到渲染机制，async属性。 JQuery版本是1.11版本与新版本有什么区别，与新/旧版有什么新增/删减的功能，兼容性的角度。 模块化：Require.js相关的配置 模板引擎：ejs, swig webpack打包相关 技术栈准备目标： 准备哪些技术栈 如何准备 角度：1.从框架；2.从自动化工具 框架的角度 首先是JQuery还是需要准备一下，了解一下源码。看核心的架构，事件委托，事件机制，兼容性。 不需要看所有的源码，看看博客与文章，浏览量比较高的。 前端框架：Vue, React, Angular，了解其中之一就行了。原理基本一样！！不用给自己挖坑，说自己都懂。 怎么准备？ 源码角度； 实战准备； 然后是Nodejs，Nodejs需要了解一些基本的，如果没有Nodejs相关的经验就不用写在简历之中。 前端工程（自动化）的角度 简单的说就是在工程上线之前，对JS,css进行处理。 Sass/less预编译 构建：Gulp/Webpack npm常用命令，打包发布 自我介绍123456简历：- 基本信息，姓名-年龄-手机-邮箱-籍贯- 学历，博士 &gt; 硕士 &gt; 本科 &gt; 大专- 工作经历，时间-公司-岗位-职责-技术栈-业绩- 开源项目，Github和说明 解析： 招聘中对年龄与工作经历来判断，是否达到了年龄段相应的技术要求，判断是否对技术有沉淀与追求。 手机与邮箱这个是联系方式。 绝大数公司对学历还是有要求的，从大写到小，只保留最高的学历。 工作经历很重要。总结一下业绩，HR比较习惯看，有技巧。举例：在某个岗位上做了什么，如果没有做出什么业绩，现在去回想，如果有一些缺点，自己有没有新的解决方案，如何去构思，如何去实现。 开源项目：亮点项目，可以沉淀。同样，可以与开源项目去做一些贡献，不能作假。 1234自我陈述：- 把握面试的沟通方向- 豁达、自信的适度发挥 解析： 举例：校招中，面试者说：“我做过什么什么样的项目”，从面试的角度，心中有准备了如下问题： 负责什么项目 有什么人参与 与前端的结合点是什么 角色是什么 项目中承担的责任 做出了什么成绩 “我是负责人”： - 有几个人参与 - 项目管理？技术负责？ - 落脚点：做出了什么成绩 头衔越大，问得越多。 所以要针对性的准备，比如对于艺龙：我平时喜欢看一些网站，学习一些新的技术知识，也会去尝试。话不用多说，传递一种对技术有热爱、有追求/思考的人的感觉。引导面试官去问：（1）你平时喜欢去哪些网站；（2）研究哪些代码； 不能直接去说艺龙，然后，等面试官问了之后，自己就可以去回答自己准备了的内容。 豁达指说话要声音要洪亮，不能自卑，要有自己的气场，因为面试官也很紧张。 关于适度发挥：不能骄傲，目的是让面试官来欣赏你。 关于照片是否要准备，视频中的老师的意思是不需要，也不重要。而笔者看来，非常重要。 下面来看看反例： 关于教育背景，不要写学习的课程，不要写高中。 个人技能不要写的琐碎：比如不要写Linux到工具类里面，写的比较大了。 去繁化简，把握“了解/熟悉/精通” 兴趣：写对技术的追求，不要写爬山之类的。 不要太放自我评价 写业务的业绩，而不提技术上的业绩。 总结一下：在简历中，要简洁，注意排版；突出重点要传达的个人信息（技术的、能力上的），引导面试官针对性的发问。 实例与实战环节1234实例：- 自如谈兴趣、巧妙示实例、适时讨疑问- 节奏要适宜、切忌小聪明 解析： 切忌不能说XXX我没有准备，我来给你讲讲这个。聪明的求职者，不要“我不知道”“我不懂”“我要回去看看”，要说“面试官，这里能不能指点一下？”“给点建议？”“给点资料，我想回去看看” 不要对简单的问题很不屑。 耐心的写/说一些对问题的答案，而不是对实现/回答了就行了的心态。 1234实战：- 方向要对，过程要细- 胆子要大、心态要和 解析： 可能有一些公司的项目，没有做过所有的模块，但是要了解细节。 对于有一些公司考察一些比较难的算法题，要去尝试。根据自己的经验去做方案，就怕没有想就放弃。勇于承担负责，敢于挑战未知。 无论是否自己能否答完，都不要自傲；无论是否自己是否了解，都不要自卑。 如果自己不清楚，不要轻易放弃，可以去多请教一下面试官。要感谢这次面试，可以找到知识体系中，薄弱的地方。","categories":[{"name":"前端跳槽面试必备技巧","slug":"前端跳槽面试必备技巧","permalink":"https://www.toimc.com/categories/%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"前端面试","slug":"前端面试","permalink":"https://www.toimc.com/tags/%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"name":"技巧总结","slug":"技巧总结","permalink":"https://www.toimc.com/tags/%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/"}]},{"title":"慕课网《前端跳槽面试必备技巧》——导学部分","slug":"慕课网《前端跳槽面试必备技巧》——导学部分","date":"2019-03-24T14:53:36.000Z","updated":"2019-04-04T01:26:02.000Z","comments":true,"path":"慕课网《前端跳槽面试必备技巧》——导学部分/","link":"","permalink":"https://www.toimc.com/%E6%85%95%E8%AF%BE%E7%BD%91%E3%80%8A%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7%E3%80%8B%E2%80%94%E2%80%94%E5%AF%BC%E5%AD%A6%E9%83%A8%E5%88%86/","excerpt":"这个系列介绍的是前端跳槽面试中经验的总结，技巧分享，常见面试题的解析。通过课程的学习笔记，整理相关的资料与大家分享。原课程链接：前端跳槽面试必备技巧","text":"这个系列介绍的是前端跳槽面试中经验的总结，技巧分享，常见面试题的解析。通过课程的学习笔记，整理相关的资料与大家分享。原课程链接：前端跳槽面试必备技巧 关于面试一般来说，面试分为技术面试、负责人面试、HR面试，时长在1小时~1个半小时(所有的环节时间累加)，目标如何在最短的时间，给面试官留下足够好的印象，得到比较高的认可，面试的技术 面试环节 面试准备 面试技巧(答题技巧、沟通技巧) 题目演练 知识梳理 复习指导 面试中常见的坑抱着问题找答案，一个坑一个坑的跳： 职位描述（Job Describe，简称JD）怎么看？ 简历怎么写？ 知识怎么复习？ 问题该怎么回答？ 项目怎么准备？ 如何与负责人沟通？ HR怎么留印象？ 面试准备 职位描述 业务分析 技术栈准备 自我介绍 技术面试（模拟一面） 面试技巧、页面布局类 CSS盒模型 DOM事件类 HTTP协议类 原型链类 面向对象类 通信类 前端安全类、算法类 能力面试（模拟二面） 面试技巧 渲染机制 JS运行机制 页面性能 错误监控 负责人面试（模拟三面） 面试技巧 业务能力 团队协作能力 带人能力 HR面试（模拟终面） 面试技巧 职业竞争力（特别重要） 职业规划 课程总结 注意事项 复习指南 适用人群： 有前端基础 端正心态 不浮躁 不求押题","categories":[{"name":"前端跳槽面试必备技巧","slug":"前端跳槽面试必备技巧","permalink":"https://www.toimc.com/categories/%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"前端面试","slug":"前端面试","permalink":"https://www.toimc.com/tags/%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"name":"技巧总结","slug":"技巧总结","permalink":"https://www.toimc.com/tags/%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/"}]},{"title":"Centos7网络配置及SSH自定义端口","slug":"Centos7网络配置及SSH自定义端口","date":"2019-03-21T07:35:36.000Z","updated":"2019-12-27T08:58:30.000Z","comments":true,"path":"Centos7网络配置及SSH自定义端口/","link":"","permalink":"https://www.toimc.com/Centos7%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E5%8F%8ASSH%E8%87%AA%E5%AE%9A%E4%B9%89%E7%AB%AF%E5%8F%A3/","excerpt":"本文介绍了Centos7中网络的配置和SSH自定义端口的设置方法，核心命令：nmcli, nmtui 介绍","text":"本文介绍了Centos7中网络的配置和SSH自定义端口的设置方法，核心命令：nmcli, nmtui 介绍 Centos7 中网络配置nmcli命令与nmtui命令介绍nmcli命令 在CentOS / RHEL 7中网络管理命令行工具，叫nmcli(command-line tool for controlling NetworkManager)。经常使用ifconfig的用户应该在CentOS 7中避免使用ifconfig，如果需要使用ifconfig命令，可以参考：如下命令进行安装。 123456# yum search ifconfigFailed to set locale, defaulting to CLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfilenet-tools.x86_64 : Basic networking tools# yum install -y net-tools 常用的几个命令及用法： 命令 作用 nmcli dev status 显示所有的网卡信息 nmcli con show 显示所有的连接信息 nmcli con up &lt;ID&gt; 激活网口，启动一个连接 nmcli con down &lt;ID&gt; 关闭网口连接，如果autoconnect设置成yes的话，重启后会自动连接 nmcli dev dis &lt;DEV&gt; 关闭这个网卡设备，就算有autoconnect也不会重启 nmcli net off 关闭所有受NetworkManager管理的网卡 nmcli con add ... 添加一个新的连接 nmcli con mod &lt;ID&gt; 修改指定ID的连接 nmcli con del &lt;ID&gt; 删除指定ID的连接 nmtui命令 NetworkManager 文本用户界面（TUI）工具 nmtui 可提供一个文本界面配置由 NetworkManager 控制的网络。如果提示not found命令的话，可以 yum install -y NetworkManager-tui进行安装。 输入这个命令后，会显示如下页面： 这里有一个操作细节： 键盘的→,←, ↑, ↓来控制方向； 空格用来选择/选中； 最后要使用service network restart来使保存生效 编辑页面： 下面是配置一个固定IP的方式方法，注意红色线框部分需要勾选。代表：1. 自启动；2. 对所有用户有效； 网络配置按照nmtui命令进行配置，Edit之后，选择Ok保存，重启network服务。 配置完成之后，查看配置信息： 看看配置文件： 1vi /etc/sysconfig/network-script/ifcfg-eth0 内容如下： 1234567891011121314151617181920TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=noIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=eth0UUID=1c462a5e-aff5-423e-a21b-df1112a443f4DEVICE=eth0ONBOOT=yesIPV6_PRIVACY=noBOOTPROTO=noneIPADDR=192.168.4.59PREFIX=24GATEWAY=192.168.4.50DNS1=192.168.4.50 配置完成。 Centos7的镜像及源地址 官方镜像地址： 官方下载地址 阿里云(推荐) Centos 7源 第一步：备份你的原镜像文件，以免出错后可以恢复。 1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 第二步：下载新的CentOS-Base.repo 到/etc/yum.repos.d/ 1wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 或者使用curl命令 1curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 第三步：运行yum makecache生成缓存 12yum clean allyum makecache 参考资料：阿里云对应各个Linux的源Repo SSH自定义端口的方法与Ubuntu不一样，Centos的配置可能复杂一些，需要增加SELinux相应的配置，见下文： SELinux 全称 Security Enhanced Linux (安全强化 Linux)，是 MAC (Mandatory Access Control，强制访问控制系统)的一个实现，目的在于明确的指明某个进程可以访问哪些资源(文件、网络端口等)。强制访问控制系统的用途在于增强系统抵御 0-Day 攻击(利用尚未公开的漏洞实现的攻击行为)的能力，所以它不是网络防火墙或 ACL 的替代品。 查看是否已安装SSH软件包(可跳过) 1#rpm -qa|grep ssh 检查服务是否开启 1systemctl status sshd.service 检查进程运行状态(可跳过) 1ps -ef |grep sshd 检查程序运行端口(可跳过) 1# netstat -anpl |grep sshd 修改sshd配置文件 1# vi /etc/ssh/sshd_config 取消#Port 22前面的#号，另起一行新增Port 27300（自定义端口），ESC + :wq保存退出。 重启SSH服务 1systemctl restart sshd.service 防火墙相关，默认情况下，防火墙会开启。 查看防火墙开启的状态 12345# firewall-cmd --staterunning # 说明是开启的# firewall-cmd --statenot running # 说明是被禁用了，可以使用 systemctl start firewalld 来开启 开放防火墙端口： 添加端口 1firewall-cmd --zone=public --add-port=27300/tcp --permanent 重新加载 1firewall-cmd --reload 重启服务 1systemctl restart firewalld.service 查看端口 1firewall-cmd --zone=public --list-all 修改SELinux端口： 检查SELinux是否启用 1234# sestatus -v |grep SELinuxSELinux status: enabled #表示启用SELinuxfs mount: /sys/fs/selinuxSELinux root directory: /etc/selinux 检查semanage是否安装 1# rpm -qa |grep policycoreutils-python 多数情况： 若未安装，请先安装工具包 12# yum update -y# yum install -y policycoreutils-python 查看当前selinux允许的端口 12# semanage port -l |grep sshssh_port_t tcp 22 添加新端口 1# semanage port -a -t ssh_port_t -p tcp 27300 注意：无法使用如下命令，去删除默认的SELinux配置端口22 1semanage port -d -t ssh_port_t -p tcp 22 会收到如下的提示： 1ValueError: Port tcp/22 is defined in policy, cannot be deleted 这里不用去纠结，不能删除的主要原因是SELinux中的默认Policy无法删除！！！只用删除firewall中的配置，并且保证firewall中没有放行22端口，SSH配置文件中没有Port 22，就行了。 检查是否添加成功 12# semanage port -l |grep sshssh_port_t tcp 27300, 22 # 说明添加成功了 重启SSH服务 1# systemctl restart sshd.service","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.toimc.com/tags/Linux/"}]},{"title":"《穷爸爸和富爸爸》阅后感","slug":"《穷爸爸和富爸爸》阅后感","date":"2018-10-02T14:27:28.000Z","updated":"2019-03-14T15:42:19.000Z","comments":true,"path":"《穷爸爸和富爸爸》阅后感/","link":"","permalink":"https://www.toimc.com/%E3%80%8A%E7%A9%B7%E7%88%B8%E7%88%B8%E5%92%8C%E5%AF%8C%E7%88%B8%E7%88%B8%E3%80%8B%E9%98%85%E5%90%8E%E6%84%9F/","excerpt":"《富爸爸，穷爸爸》是一个真实的故事，作者罗伯特・清崎的亲生父亲和朋友的父亲对金钱的看法截然不同，这使他对认识金钱产生了兴趣，最终他接受了朋友的父亲的建议，也就是书中所说的。“富爸爸”的观念，即不要做金钱的奴隶，要让金钱为我们工作，并由此成为一名极富传奇色彩的成功的投资家。","text":"《富爸爸，穷爸爸》是一个真实的故事，作者罗伯特・清崎的亲生父亲和朋友的父亲对金钱的看法截然不同，这使他对认识金钱产生了兴趣，最终他接受了朋友的父亲的建议，也就是书中所说的。“富爸爸”的观念，即不要做金钱的奴隶，要让金钱为我们工作，并由此成为一名极富传奇色彩的成功的投资家。 财商是由4个方面的专门知识构成的： 第一是会计，也就是我说的财务知识。如果你想建立一个自己的商业帝国，财务知识是非常重要的。你管理的钱越多，就越要精确，否则这幢大厦就会倒塌。这需要左脑来处理，是细节的部分。财务知识能帮助你读懂财务报表，还能让你辨别一项生意的优势和劣势。 第二是投资，我把它称为钱生钱的科学。投资涉及策略和方案，这要右脑来做，是属于创造的部分。 第三是了解市场，它是供给与需求的科学。这要求了解受感情驱动的市场的“技术面”。1996年圣诞节的搔痒娃娃大获成功就是一个受技术与感情影响的市场的最佳佐证。市场的另一个因素是“基本面”，或者说是一项投资的经济意义。一项投资究竟有无意义最终取决于当前的市场状况。 第四是法律。例如：利用一个具有会计、投资和市场运营的企业会使你的财富实现爆炸性地增长。了解减税优惠政策和公司法的人会比雇员和小业主更快致富。这就像一个人在走，而另一个人却在飞，久而久之这种差距就更大了。","categories":[{"name":"成长路上","slug":"成长路上","permalink":"https://www.toimc.com/categories/%E6%88%90%E9%95%BF%E8%B7%AF%E4%B8%8A/"}],"tags":[{"name":"读书计划","slug":"读书计划","permalink":"https://www.toimc.com/tags/%E8%AF%BB%E4%B9%A6%E8%AE%A1%E5%88%92/"}]},{"title":"我的咖啡因依赖","slug":"我的咖啡因依赖","date":"2018-09-21T14:00:28.000Z","updated":"2019-03-14T16:16:17.000Z","comments":true,"path":"我的咖啡因依赖/","link":"","permalink":"https://www.toimc.com/%E6%88%91%E7%9A%84%E5%92%96%E5%95%A1%E5%9B%A0%E4%BE%9D%E8%B5%96/","excerpt":"时间管理，是一门看似简单实则复杂的学问。 最近非常依赖咖啡，因为不喝咖啡就让我感觉一天很困，效率很低下，头闷闷的。我在想我是不是得了咖啡因依赖症，症状与我现在的差不多。","text":"时间管理，是一门看似简单实则复杂的学问。 最近非常依赖咖啡，因为不喝咖啡就让我感觉一天很困，效率很低下，头闷闷的。我在想我是不是得了咖啡因依赖症，症状与我现在的差不多。 一建考试过后，我发现，要在考试的附近进行估分，时间久了，一方面是自己不太刻当时的答案， 一方面是因为生活的琐事太多，不得已让自己疲惫了起来。 我们总是在生活中，做着各种各样的选择，让自己的生活过的更好。却往往忘记了，留给自己思考的时间。那些看似蒸蒸日上的人，实则是一是忘记了自己的思考时间，简单的去重复自己的工作，操劳自己的家庭，等等。而有一部分人，总是会在忙忙碌碌之中，选择时间去思考，去做自己想做的事情。选择真的很重要，会决定你的人生走向，同样，也会改变你对世界的认知。 专注思考，专注于你所做的事情。怎么做？ 我的时间管理方法论： 做自己擅长的事情。 请人来做别人擅长的事情； 请教人，如何让自己做的一般的事情，变得擅长； 擅长需要练习； 计划，一定要计划，具体到可实施，具体到小时，具体到小时的工作量可完成性； 分解所做的事情，从可以入手开始，做起来一件事情； 提炼、总结、发散能力；","categories":[{"name":"成长路上","slug":"成长路上","permalink":"https://www.toimc.com/categories/%E6%88%90%E9%95%BF%E8%B7%AF%E4%B8%8A/"}],"tags":[{"name":"时间计划","slug":"时间计划","permalink":"https://www.toimc.com/tags/%E6%97%B6%E9%97%B4%E8%AE%A1%E5%88%92/"},{"name":"生活随感","slug":"生活随感","permalink":"https://www.toimc.com/tags/%E7%94%9F%E6%B4%BB%E9%9A%8F%E6%84%9F/"}]},{"title":"看逻辑思维笔记","slug":"看逻辑思维笔记","date":"2018-09-17T14:27:28.000Z","updated":"2019-03-14T15:38:32.000Z","comments":true,"path":"看逻辑思维笔记/","link":"","permalink":"https://www.toimc.com/%E7%9C%8B%E9%80%BB%E8%BE%91%E6%80%9D%E7%BB%B4%E7%AC%94%E8%AE%B0/","excerpt":"有很多人对罗胖这个人争议很大，但是人家做节目是认真的。 这里记录下来最近学习到的几个知识，并打算在今后的工作生活中去实践。","text":"有很多人对罗胖这个人争议很大，但是人家做节目是认真的。 这里记录下来最近学习到的几个知识，并打算在今后的工作生活中去实践。 知识就是力量之如何成为一个上进的人 设计你的环境 引入外部监督（被绑架） 寻求不确定的反馈 选择无止境的晋升的职业 怎样做一个有价值的人 锚定时间：节约时间是一生最重要的一道算术题 多元收益：同一笔时间支出，获得多种时间价值； 复制时间：同一笔时间支出，收获多次价值； 营造预期：营造别人对自己未来时间的预期； 购买时间：购买他人的时间，花好自己的时间。 这是对我的影响最大的一堂课，我感觉以前把时间都浪费了好多。 我们都知道要节约时间，也都知道要珍惜时间，要有毅力，但是，时常事与愿违。 原因是什么？因为，我们可能在做一件我们自己不可能或者要花很大的气力完成的事情。 做着做着就放弃了，因为人是有惰性的。 我打算通过授课的方式去分享我的知识，通过授课来把我的学习能力、表达能力提高，来督促自己学习。 这部分后面，能我完善了之后，再给大家来分享。 怎样找一份合适的工作不管你是要找一份合适的工作，还是响应国家号召，创一份自己的业，其实本质上就是这么一段话，叫把自己的价值变成一个确定的产品，然后让第一个陌生用户，不管他是谁去使用它，然后在整个社会释放价值。最后你会找到一份合适的工作，甚至你会创一份让自己满意的业，甚至成就一个你自己满意的人格。 拆解工作成为可实现的目标； 产品化本身；（不感动；不骚扰；不迎合；） 合适：选择一个上长中的公司；如果在火箭上给你一个位置，那就不要挑仓位了。 不可胜在已，可胜在敌；（想打败敌人，不是我们自己说了算是，是因为敌人不中用不行。要保持不可战胜的状态，不要输光手中的牌，这才是我们的使命。）","categories":[{"name":"成长路上","slug":"成长路上","permalink":"https://www.toimc.com/categories/%E6%88%90%E9%95%BF%E8%B7%AF%E4%B8%8A/"}],"tags":[{"name":"时间计划","slug":"时间计划","permalink":"https://www.toimc.com/tags/%E6%97%B6%E9%97%B4%E8%AE%A1%E5%88%92/"},{"name":"逻辑思维","slug":"逻辑思维","permalink":"https://www.toimc.com/tags/%E9%80%BB%E8%BE%91%E6%80%9D%E7%BB%B4/"}]},{"title":"centos6.5离线安装mysql","slug":"centos6-5离线安装mysql","date":"2018-03-26T07:58:47.000Z","updated":"2019-12-27T08:58:30.000Z","comments":true,"path":"centos6-5离线安装mysql/","link":"","permalink":"https://www.toimc.com/centos6-5%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85mysql/","excerpt":"本文介绍了在Centos6.5下离线安装Mysql的方法","text":"本文介绍了在Centos6.5下离线安装Mysql的方法 centos6.5离线安装mysql环境介绍： Centos 6.5 Mysql 5.6 首先说明下 ：1） Centos7将默认数据库mysql替换成了Mariadb，如果想继续使用mysql 需要卸载Mariadb 再安装mysql2） mysql 5.7版本的密码问题搞得人很头疼，所以干脆选择mysql5.6了 先下载Mysql 首先说明下 ：1） Centos7将默认数据库mysql替换成了Mariadb，如果想继续使用mysql 需要卸载Mariadb 再安装mysql 2） mysql 5.7版本的密码问题搞得人很头疼，所以干脆选择mysql5.6了 卸载系统自带的Mariadb rpm -qa|grep mariadb //查询出已安装的mariadb rpm -e –nodeps 文件名 //卸载 ， 文件名为使用rpm -qa|grep mariadb 命令查出的所有文件 删除etc目录下的my.cnf文件 1rm /etc/my.cnf 执行以下命令来创建mysql用户组 1groupadd mysql 执行以下命令来创建一个用户名为mysql的用户并加入mysql用户组 1useradd -g mysql mysql 将下载的二进制压缩包放到/usr/local/目录下。 解压安装包 1tar -zxvfmysql-5.6.36-linux-glibc2.5-x86_64.tar.gz 将解压好的文件夹重命名为mysql 在etc下新建配置文件my.cnf，并在该文件内添加以下代码： 123456789101112131415161718192021[mysql]# 设置mysql客户端默认字符集default-character-set=utf8socket=/var/lib/mysql/mysql.sock[mysqld]skip-name-resolve#设置3306端口port=3306socket=/var/lib/mysql/mysql.sock# 设置mysql的安装目录basedir=/usr/local/mysql# 设置mysql数据库的数据的存放目录datadir=/usr/local/mysql/data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODBlower_case_table_names=1max_allowed_packet=16M 创建步骤9中用到的目录并将其用户设置为mysql 1234mkdir /var/lib/mysqlmkdir /var/lib/mysql/mysqlchown -R mysql:mysql /var/lib/mysqlchown -R mysql:mysql /var/lib/mysql/mysql 进入安装mysql软件目录 1234cd /usr/local/mysqlchown -R mysql:mysql ./ #修改当前目录拥有者为mysql用户./scripts/mysql_install_db --user=mysql #安装数据库chown -R mysql:mysql data #修改当前data目录拥有者为mysql用户 到此数据库安装完毕！","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://www.toimc.com/tags/mysql/"},{"name":"linux","slug":"linux","permalink":"https://www.toimc.com/tags/linux/"}]},{"title":"《创业小败局》阅后笔记","slug":"创业小败局","date":"2018-02-13T01:36:00.000Z","updated":"2019-03-16T05:39:05.000Z","comments":true,"path":"创业小败局/","link":"","permalink":"https://www.toimc.com/%E5%88%9B%E4%B8%9A%E5%B0%8F%E8%B4%A5%E5%B1%80/","excerpt":"让别人的失败，成为你的成功之母！阅读笔记！","text":"让别人的失败，成为你的成功之母！阅读笔记！ 战略：从自己的熟悉做起，从容易入手的做起，不要盲目。 在战略实施的节奏上，创业者应当优先解决自己不熟悉的环节（除非存在先后依赖关系），而不是轻车熟路地投入资源把自己熟悉的环节先准备好。 传统企业向互联网转型，绝不能为了电商而电商，必须有清晰的战略规划、详细的调研分析，切忌好高骛远。 产业链黑洞，盲目扩张问题。 农业这个东西是一个非常专业的领域，建议不要把农业随随便便当作创业的方向，也绝非是所谓屌丝首选的创业项目，逆袭的故事也许只有电视里有。做农业必须要有敬畏的心、感恩的心，民以食为天，切不能当儿戏 关于这个新农业，我总结为一定要接地气，不要花拳绣腿；一定要沉住气，不要急功近利；一定要大气，不要斤斤计较；一定要有勇气，不要眼光短浅。做新农业，不是搞工业化大农业，不是工业化的现代农业，因为这样的话品质是个问题。如果做这个生态农业，只要做就要注重这个品质。 树大招风，但是也要学会试错 网络是一个可以“暴富”的行业，也是一个极具风险的行业，知名度高、财富多并不意味着安全。 互联网创业是讲究团队作战的，需要产品、技术、市场、销售团队紧密配合，每个方面都不能有明显短板，否则很容易被替代竞争性产品击败。 创业公司的股权结构设计问题。再好的兄弟、同学创业，都需要把股权结构与利益梳理清晰，否则一旦面临利益问题，就会让公司结构处于动荡的风险中，分家、出走都是很常见的结果。初创公司的股权设计，第一忌讳江湖方式处理，结构与利益不明晰；第二忌讳股权平均或分散，没有“带头大哥”作为决策中心；第三忌讳股权比例错配，非关键人员拥有大股权比例。创业者可引以为戒。 小食品: 没有必要去关注“每公斤价值”的问题，而需要关注的是一个商业模式其本身如何实现盈利。而这个问题的答案也很简单，就是“我必须要成为一个品牌”，因为“你只有是品牌的时候，顾客才会讨好你，才会付更多的钱购买你的产品”。要知道坚果目前看来还是属于食品中的奢侈品，大部分对象是白领，其实他们并不缺多付的那点钱，也很舍得自己付邮费，关键在于你是否让顾客有购买你的理由，而这个理由一定不是便宜。 任何一家企业都不能通过购买主营业务的形式去获得长足的发展与成功。由于资本驱动，缺乏苦练内功、长期运营、培养自己的核心业务的决心，所以这从道的层面、规律的层面上就是错的，注定以“资本操盘手”的“昙花一现”结束。 创业企业除了要有试错意识外，还需要“根据地意识”。 几个失败的案例： 大树网的案例: a．对市场容量和业务增长预期盲目乐观，甚至按线下成熟业务的发展轨迹来加速估算，并未考虑所需流量、转化以及推广覆盖成本，导致摊子铺得太大，资金和资源跟不上。b．整体策略和局部建设不配套，线下花了大量的资金和资源做推广，线上的板块却迟迟无法上线，导致推广效果减弱，无法及时转化为销量，团队士气受挫。c．仓促上马加盲目建设。大树网在业务规模以及容量还没有发展起来，甚至业务链条还不能承担较大的业务流量的时候，就已经开始盲目地大兴基础扩容工程，从而背负了沉重的资金负担。 亿佰购物： a. 寄居；b. 无品牌；c. 不够专注；d. 没有危机感；e. 树敌太多。 教育网站的核心问题： 第一个问题是体验。因为家长不太信任不出名的网站，所以我决定大规模免费体验，我直接让家长带着学生到公司体验，甚至可以直接在现场约老师上课，然后我们给他一个房间，和远在北京、上海的比较好的老师面对面上课。后来忍痛为了用户体验效果，也为了更加严格控制教育内容，我租用了视频会议系统。 第二个问题是用户源。我采用了三个到现在也觉得很不错的办法。 第一个办法是直接花钱买下了几个网上家教吧，直接把这些家教吧上的用户导到我的网站上。这几个网站每天可以给我网站导入不少注册用户；第二个是我买下了某个分类信息网站的所有省级城市的家教版块广告，这个上面的用户都很精准有效；第三个是免费体验加电话扫街。 这三个办法虽然非常草根，跟那些高端大气的大网站动辄上百万的推广比，显得那么寒酸，但是最后证明是行之有效的。 失败原因：生不逢时；缺乏规划；盲目扩张；市场反馈；联合创始人；资源不足；现金流的认识不足。","categories":[{"name":"成长路上","slug":"成长路上","permalink":"https://www.toimc.com/categories/%E6%88%90%E9%95%BF%E8%B7%AF%E4%B8%8A/"}],"tags":[{"name":"创业","slug":"创业","permalink":"https://www.toimc.com/tags/%E5%88%9B%E4%B8%9A/"}]},{"title":"linux离线安装nginx","slug":"linux离线安装nginx","date":"2018-02-08T15:20:25.000Z","updated":"2019-03-12T16:01:05.000Z","comments":true,"path":"linux离线安装nginx/","link":"","permalink":"https://www.toimc.com/linux%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85nginx/","excerpt":"nginx编译安装介绍","text":"nginx编译安装介绍 下载nginx源码包：http://nginx.org/download/nginx-1.12.1.tar.gz 然后解压，tar zxvf nginx-1.12.1.tar.gz 安装依赖：安装之前使用rpm -qa |grep &quot;名称&quot;查看是否安全了包（centos），或者dpkg --get-selections | grep gcc（Ubuntu或者Debian） 链接:https://pan.baidu.com/s/1ggKF0XX 密码:vwig 安装gcc，如果没有gcc没有装，去看我的上一篇文章，离线安装gcc。 安装pcre依赖包： 123rpm -ivh pcre-7.8-7.el6.x86_64.rpm --force（由于机器上已经有低版本的pcre，所以强制安装）。rpm -ivh pcre-devel-7.8-7.el6.x86_64.rpm。 安装libstdc++-devel（gcc-c++依赖） 一般来说REDHAT 6.5上会有这个依赖 1rpm -ivh libstdc++-devel-4.4.7-4.el6.x86_64.rpm 安装gcc-c++ 一般来说REDHAT 6.5上会有这个依赖 1rpm -ivh gcc-c++-4.4.7-4.el6.x86_64.rpm 安装zlib-devel 一般来说REDHAT 6.5上会有这个依赖 1rpm -ivh zlib-devel-1.2.3-29.el6.x86_64.rpm 安装nginx 1234567cd nginx-1.12.1./configure make make install 运行nginx 123cd /usr/local/nginx/sbin./nginx 加入nginx开机启动将如下代码复制粘贴到/etc/init.d/nginx 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144#!/bin/sh## nginx - this script starts and stops the nginx daemon## chkconfig: - 85 15# description: Nginx is an HTTP(S) server, HTTP(S) reverse \\# proxy and IMAP/POP3 proxy server# processname: nginx# config: /usr/local/nginx/conf/nginx.conf# config: /etc/sysconfig/nginx# pidfile: /usr/local/nginx/logs/nginx.pid# Source function library.. /etc/rc.d/init.d/functions# Source networking configuration.. /etc/sysconfig/network# Check that networking is up.[ &quot;$NETWORKING&quot; = &quot;no&quot; ] &amp;&amp; exit 0nginx=&quot;/usr/local/nginx/sbin/nginx&quot;prog=$(basename $nginx)sysconfig=&quot;/etc/sysconfig/$prog&quot;lockfile=&quot;/var/lock/subsys/nginx&quot;pidfile=&quot;/usr/local/nginx/logs/$&#123;prog&#125;.pid&quot;NGINX_CONF_FILE=&quot;/usr/local/nginx/conf/nginx.conf&quot;[ -f $sysconfig ] &amp;&amp; . $sysconfigstart() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 echo -n $&quot;Starting $prog: &quot; daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125;stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc -p $pidfile $prog retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125;restart() &#123; configtest_q || return 6 stop start&#125;reload() &#123; configtest_q || return 6 echo -n $&quot;Reloading $prog: &quot; killproc -p $pidfile $prog -HUP echo&#125;configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125;configtest_q() &#123; $nginx -t -q -c $NGINX_CONF_FILE&#125;rh_status() &#123; status $prog&#125;rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125;# Upgrade the binary with no downtime.upgrade() &#123; local oldbin_pidfile=&quot;$&#123;pidfile&#125;.oldbin&quot; configtest_q || return 6 echo -n $&quot;Upgrading $prog: &quot; killproc -p $pidfile $prog -USR2 retval=$? sleep 1 if [[ -f $&#123;oldbin_pidfile&#125; &amp;&amp; -f $&#123;pidfile&#125; ]]; then killproc -p $oldbin_pidfile $prog -QUIT success $&quot;$prog online upgrade&quot; echo return 0 else failure $&quot;$prog online upgrade&quot; echo return 1 fi&#125;# Tell nginx to reopen logsreopen_logs() &#123; configtest_q || return 6 echo -n $&quot;Reopening $prog logs: &quot; killproc -p $pidfile $prog -USR1 retval=$? echo return $retval&#125;case &quot;$1&quot; in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest|reopen_logs) $1 ;; force-reload|upgrade) rh_status_q || exit 7 upgrade ;; reload) rh_status_q || exit 7 $1 ;; status|status_q) rh_$1 ;; condrestart|try-restart) rh_status_q || exit 7 restart ;; *) echo $&quot;Usage: $0 &#123;start|stop|reload|configtest|status|force-reload|upgrade|restart|reopen_logs&#125;&quot; exit 2esac 启动nginx: 12# chmod +x /etc/init.d/nginx# service nginx start 配置nginx开机启动 1# chkconfig nginx on 设置nginx环境变量 1# vim /etc/profile 在其文件末尾添加如下变量 1export PATH=$PATH:/usr/local/nginx/sbin 或者用以下命令添加 1# sed -i &#x27;/unset -f pathmunge/a\\export PATH=$PATH:/usr/local/nginx/sbin&#x27; /etc/profile 运行如下命令使环境变量生效 1# source /etc/profile","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://www.toimc.com/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"https://www.toimc.com/tags/nginx/"}]},{"title":"linux编译安装php7+nginx","slug":"linux编译安装php7","date":"2018-02-07T00:33:43.000Z","updated":"2019-03-12T16:01:29.000Z","comments":true,"path":"linux编译安装php7/","link":"","permalink":"https://www.toimc.com/linux%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85php7/","excerpt":"有很多坑人的内网情况下，需要手动安装PHP，下面就带大家一起来学习一下。有一些企业内网环境用的linux版本又低，又不能装docker，那么就要折腾一下吧。 如果能用docker，如果能联网，如果能升级内核，不装TMD该死的十三年前的内核的RHEL6.5，那么就没有这篇文章及下面的总结了。","text":"有很多坑人的内网情况下，需要手动安装PHP，下面就带大家一起来学习一下。有一些企业内网环境用的linux版本又低，又不能装docker，那么就要折腾一下吧。 如果能用docker，如果能联网，如果能升级内核，不装TMD该死的十三年前的内核的RHEL6.5，那么就没有这篇文章及下面的总结了。 环境：Centos 6.5或者RHEL 6.5，其他比如ubuntu或者Debian会有一些不一样，比如安装包是dpkg -i命令，参考ubuntu安装与删除软件的命令。 PHP7编译安装下载PHP源文件：本次编译安装的php版本 php官网：http://www.php.net/ php7.1.5：http://hk1.php.net/get/php-7.1.5.tar.gz/from/this/mirror 解压文件，安装依赖，配置PHPtar zxvf php-7.1.5.tar.gz 有几个依赖需要下，一般来说gcc gcc++都有，而libxml2-devel需要根据大家自己的linux版本去下载。 https://pkgs.org/ 到这里搜索下载。 cd php-7.1.5/ 这里我来说几个坑： 安装完成之后，phpinfo中configure file为None: 默认路径在： /usr/local/php7/etc/php.ini，可以通过strace /usr/local/php7/bin/php -i 2&gt;/tmp/php-fpm.log来查看fpm调用了什么位置的php.ini 参考： https://www.hongweipeng.com/index.php/archives/1007/ 需要配置--with-config-file-path=/xxx/xxx，如--with-config-file-path=/etc 配置基本的php安装目录，与enable开启fpm。 --prefix=/usr/local/php7 --enable-fpm 安装模块，最终的配置命令： 如果配置失败了，提示没有autoconf，请跳到后面配置autoconf。 `./configure --prefix=/usr/local/php7/ --enable-mbstring --with-curl --with-gd --with-jpeg-dir --with-png-dir --with-config-file-path=/usr/local/php7/etc/ --enable-fpm --enable-mysqlnd --with-pdo-mysql=mysqlnd --enable-fpm --enable-opcache --with-zlib --with-openssl --with-iconv` 查看一下Makefiles，查找一下EXTRA_LIBS，如果没有-liconv 请追加-liconv，最后看起来是这样的： EXTRA_LIBS = -lcrypt -lcrypt -lrt -lpng -lz -lcurl -lrt -lm -ldl -lnsl -lrt -lxml2 -lz -lm -lcurl -lxml2 -lz -lm -lxml2 -lz -lm -lcrypt -lxml2 -lz -lm -lxml2 -lz -lm - lxml2 -lz -lm -lcrypt -liconv 查看php配置的几种方法： （1）phpinfo()直接，直观； （2）php -i |grep &quot;这里是参数名称&quot; 比较全的配置命令： 1234567891011121314151617181920212223242526272829303132333435./configure --prefix=/usr/local/php \\ --with-apxs2=/usr/local/apache/bin/apxs \\ --with-curl \\ --with-freetype-dir=/usr/local/freetype \\ --with-gd \\ --with-gettext \\ --with-iconv-dir \\ --with-mysqli \\ --with-openssl \\ --with-pcre-regex \\ --with-pdo-mysql \\ --with-pdo-sqlite \\ --with-pear \\ --with-png-dir=/usr/local/libpng \\ --with-jpeg-dir=/usr/local/libjpeg \\ --with-xsl \\ --with-zlib \\ --enable-fpm \\ --enable-bcmath \\ --enable-libxml \\ --enable-inline-optimization \\ --enable-gd-native-ttf \\ --enable-mbregex \\ --enable-mbstring \\ --enable-opcache \\ --enable-pcntl \\ --enable-shmop \\ --enable-soap \\ --enable-sockets \\ --enable-sysvsem \\ --enable-xml \\ --enable-zip shell&gt; make shell&gt; make install **重要：如果编译失败，请make clean ** 安装与环境变量的配置123makemake testmake install 安装完以后，PHP 安装到了 /usr/local/php7，我们切进去： cd /usr/local/php7 有几个配置文件，如php.ini，php-fpm.conf，php-fpm.d/www.conf需要配置一下： 123cp /usr/local/src/php-7.0.10/php.ini-production etc/php.inicp etc/php-fpm.conf.default etc/php-fpm.confcp etc/php-fpm.d/www.conf.default etc/php-fpm.d/www.conf 同时修改一下php-fpm.conf，这里需要添加用户adduser www和组usermod -a -G www www; 参考： http://blog.sina.com.cn/s/blog_4b93170a0100nggo.html https://cnzhx.net/blog/linux-add-user-to-group/ 修改www.conf： 1234567user = wwwgroup = wwwlisten = 127.0.0.1:9000pm.max_children = 32pm.start_servers = 32pm.min_spare_servers = 32pm.max_spare_servers = 32 最后启动 php-fpm： /usr/local/php7/sbin/php-fpm -D 配置全局变量 修改/etc/profile文件使其永久性生效 添加下面两行（也可以写成一行） export PATH=$PATH:/usr/local/php7/bin source一下/etc/profile 到这里基本上就完成了PHP7的编译、配置、启动。 说一说扩展extensions有的时候，像gd,iconv,pdo_mysql扩展需要手动编译安装： 重要的事情说三遍： 不要百度，请在插件的官网下载tar.gz的原码来编译与安装！！！！ 不要百度，请在插件的官网下载tar.gz的原码来编译与安装！！！！ 不要百度，请在插件的官网下载tar.gz的原码来编译与安装！！！！ 下面提供几个常见插件的官网： zlib 官网：http://www.zlib.net/ 安装举例 12345shell&gt; tar xf zlib.1.2.8.tar.gz shell&gt; cd zlib.1.2.8 shell&gt; ./configure shell&gt; make test shell&gt; make install GD libpng 官网：http://www.libpng.org/ 123456shell&gt; tar xf libpng-1.6.21 shell&gt; cd libpng-1.6.21 shell&gt; ./configure --prefix=/usr/local/libpng shell&gt; make shell&gt; make check shell&gt; make install jpeg 官网：http://www.ijg.org/ 12345shell&gt; tar xf jpegsrc.v9.tar.gz shell&gt; cd jpeg-9 shell&gt; ./configure --prefix=/usr/local/libjpeg shell&gt; make shell&gt; make install freetype 字体操作库 官网：http://www.freetype.org/ 12345shell&gt; tar xf freetype-2.6.3.tar.bz2 shell&gt; sh autogen.sh shell&gt; ./configure --prefix=/usr/local/freetype shell&gt; make shell&gt; make install libiconv [https://www.gnu.org/software/libiconv/](https://www.gnu.org/software/libiconv/) 操作举例 1234567cd /usr/local/srctar zxvf libiconv-1.14.tar.gz #解压cd libiconv-1.14 #进入安装目录./configure --prefix=/usr/local/libiconv #配置 如果还需要配置如Opcache或者yac：同样。 首先，下载http://pecl.php.net/get/yac-2.0.1.tgz 12tar zxvf yac-2.0.1.tgzcd yac-2.0.1 php扩展标准流程： 12345/usr/local/php7/bin/phpize./configure --with-php-config=/usr/local/php7/bin/php-configmake &amp;&amp; make install Installing shared extensions: /usr/local/php7/lib/php/extensions/no-debug-non-zts-20151012/ 配置php.ini： 1234567891011121314151617181920vim /usr/local/php7/etc/php.ini extension_dir = &quot;/usr/local/php7/lib/php/extensions/no-debug-non-zts-20151012/&quot;zend_extension=opcache.soextension=yac.so [opcache]opcache.enable=1 opcache.enable_cli=1 opcache.memory_consumption=64opcache.validate_timestamps=1opcache.revalidate_freq=2opcache.file_cache=/dev/shm [yac]yac.enable = 1yac.keys_memory_size = 4Myac.values_memory_size = 64Myac.compress_threshold = -1yac.enable_cli = 0 重启php-fpm： 12kill `cat /var/run/php-fpm.pid`/usr/local/php7/sbin/php-fpm -D 如果内存不足，可能会报错，打开交换分区： 12345dd if=/dev/zero of=/home/swap bs=64M count=32mkswap /home/swapswapon /home/swap make 完毕以后swapoff /home/swap 编译openssl： 12345678/usr/local/php7/bin/php -mcd /usr/local/src/php-7.1.13/ext/openssl/cp config0.m4 config.m4/usr/local/php7/bin/phpize --with-php-config=/usr/local/php7/bin/php-config ./configure --with-openssl --with-php-config=/usr/local/php7/bin/php-config makemake installll /usr/local/php7/lib/php/extensions/no-debug-non-zts-20151012/ 参考 http://bbs.xiuno.com/thread-12701.htm 配置autoconf下载新版本解压安装。 去http://ftp.gnu.org/gnu/autoconf/下载想要安装的版本，如：http://ftp.gnu.org/gnu/autoconf/autoconf-2.69.tar.gz 1234567tar -xzf autoconf-2.69.tar.gz cd autoconf-2.69./configure make &amp;&amp; make install 使用命令autoconf -V查看安装版本。 参考： linux 下php环境的安装及Discuz论坛安装 编译配置 PHP7 7.0.10, OPCache, Yac，奔向 0.00x 秒 在CentOS上使用离线YUM安装软件包 查看linux系统版本命令 如何在 docker 中使用 PHP FPM","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://www.toimc.com/tags/linux/"},{"name":"php","slug":"php","permalink":"https://www.toimc.com/tags/php/"}]},{"title":"centos远程桌面vncserver安装","slug":"centos远程桌面vncserver安装","date":"2017-12-20T15:26:08.000Z","updated":"2019-03-12T15:59:03.000Z","comments":true,"path":"centos远程桌面vncserver安装/","link":"","permalink":"https://www.toimc.com/centos%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2vncserver%E5%AE%89%E8%A3%85/","excerpt":"VNC 可以实现对另外的计算机的操作： A ： 可以访问另一个计算机，采用命令终端 或者窗口界面。 B ： 可以远程控制另一个计算机，两台同步显示操作。","text":"VNC 可以实现对另外的计算机的操作： A ： 可以访问另一个计算机，采用命令终端 或者窗口界面。 B ： 可以远程控制另一个计算机，两台同步显示操作。 安装vncserver检查是否安装VNC rpm -q tigervnc tigervnc-server 安装VNC yum update yum install tigervnc-server -y vncserver配置从VNC备份库中复制service文件到系统service服务管理目录下： cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service 修改配置文件： [Unit] Description=Remote desktop service (VNC) After=syslog.target network.target [Service] Type=forking User=&lt;Username&gt; # Clean any existing files in /tmp/.X11-unix environment ExecStartPre=-/usr/bin/vncserver -kill %i ExecStart=/usr/bin/vncserver %i -geometry 1920x1080 PIDFile=/home/&lt;Username&gt;/.vnc/%H%i.pid ExecStop=-/usr/bin/vncserver -kill %i [Install] WantedBy=multi-user.target 主要有三行： 需要修改为有root权限的用户； ExecStart后面使用-geometry指定默认vnc的分辨率，默认情况下是1024x768 加载vncserver服务systemctl daemon-reload vncpasswd &lt;username&gt; 修改vnc远程用户的密码 关闭防火墙CentoS7默认采用新防火墙firewall,不在用iptables [使用firewall] firewall-cmd --permanent --add-service vnc-server #添加访问权限 systemctl restart firewalld.service #重启firewalld #systemctl stop firewalld.service #停止firewall(start，启动) #systemctl disable firewalld.service #设置开机禁止firewall(enable 开机启动) [使用iptables] yum -y install iptables-services #安装iptables vi /etc/sysconfig/iptables #修改iptables防火规则，在合适的位置加上如下一句 -A INPUT -m state --state NEW -m tcp -p tcp --dport 5900:5903 -j ACCEPT systemctl restart iptables.service #重启防火墙使配置生效-----systemctl status iptables.service#查看状态 systemctl stop iptables.service #启动iptables(start) systemctl disable iptables.service #禁止防火墙开机启动(enable)#设置防火墙开机启动 [注意]安装iptables后可以使用 service iptables status #查看防火墙状态 service iptables stop #关闭防火墙 chkconfig iptables --list #查看防火墙开机启动状态 chkconfig iptables off #关闭防火墙开机启动 启动VNC服务systemctl enable vncserver@:1.service #设置开机启动 systemctl start vncserver@:1.service #启动vnc会话服务 #systemctl status vncserver@:1.service #查看nvc会话服务状态 #systemctl stop vncserver@:1.service #关闭nvc会话服务 检查vnc服务正在监听的端口： # netstat -tulpn | grep vnc [root@localhost ~]# netstat -tulpn | grep vnc tcp 0 0 0.0.0.0:5901 0.0.0.0:* LISTEN 18218/Xvnc tcp 0 0 0.0.0.0:6001 0.0.0.0:* LISTEN 18218/Xvnc tcp6 0 0 :::5901 :::* LISTEN 18218/Xvnc tcp6 0 0 :::6001 :::* LISTEN 18218/Xvnc 参考文章：CentOS7.1安装VNC，让Win7远程桌面LinuxVPS安装和访问CentOS 7远程桌面","categories":[],"tags":[]},{"title":"python开发微信企业应用-报警程序","slug":"python开发微信报警程序","date":"2017-12-20T13:52:26.000Z","updated":"2019-03-12T15:59:03.000Z","comments":true,"path":"python开发微信报警程序/","link":"","permalink":"https://www.toimc.com/python%E5%BC%80%E5%8F%91%E5%BE%AE%E4%BF%A1%E6%8A%A5%E8%AD%A6%E7%A8%8B%E5%BA%8F/","excerpt":"为了熟悉python，记使用python开发一个简单的微信报警后台的过程，主要完成了微信企业应用中进行文字推送。","text":"为了熟悉python，记使用python开发一个简单的微信报警后台的过程，主要完成了微信企业应用中进行文字推送。 使用urllib3发送REST（POST，GET）请求； 使用Apscheduler定时任务； 使用pyinstaller打包应用； 使用logging产生日志； 使用configparser读取ini配置文件中的属性与参数； cx_oracle常见问题； 使用urllib模块import urllib3 import json http = urllib3.PoolManager() def getToken(corpid, corpsecret): url = &#39;https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=&#123;a&#125;&amp;corpsecret=&#123;b&#125;&#39;.format(a=corpid, b=corpsecret) try: r = http.request(&#39;GET&#39;, url) data = json.loads(r.data) if data[&#39;errmsg&#39;] == &#39;ok&#39;: return data[&#39;access_token&#39;] except: print(&#39;Get token is failed, check the network!!!&#39;) 使用urllib3的GET方法，定义了一个获取微信token的方法getToken，需要传输企业微信应用的两个参数corpid，corpsecret； 使用json模块对数据进行解析； format的常见用法，参见： python format 用法详解，Python format 格式化函数 下面是，获取发送对象（user）和发送接口； def getApp(token, agentid): url = &#39;https://qyapi.weixin.qq.com/cgi-bin/agent/get?access_token=&#123;a&#125;&amp;agentid=&#123;b&#125;&#39;.format( a=token, b=agentid, ) try: r = http.request(&#39;GET&#39;, url) data = json.loads(r.data) if data[&#39;errmsg&#39;] == &#39;ok&#39;: USERLIST = data[&#39;allow_userinfos&#39;][&#39;user&#39;] return [item[&#39;userid&#39;] for item in USERLIST] except: print(&#39;Get App user is failed!!!&#39;) def sendMsg(postData): token = getToken(corpid, corpsecret) toUser = &#39;|&#39;.join(getApp(token, cp[&#39;rest&#39;][&#39;agentid&#39;])) # print(toUser) dataTomsg = &#123; &quot;touser&quot;: toUser, &quot;toparty&quot;: &quot;&quot;, &quot;totag&quot;: &quot;&quot;, &quot;msgtype&quot;: &quot;text&quot;, &quot;agentid&quot;: cp[&#39;rest&#39;][&#39;agentid&#39;], &quot;text&quot;: &#123; &quot;content&quot;: postData &#125;, &quot;safe&quot;: 0 &#125; url = &#39;https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=&#123;&#125;&#39;.format(token) try: r = http.request(&quot;POST&quot;, url, body=json.dumps(dataTomsg), headers=&#123;&#39;Content-Type&#39;: &#39;application/json&#39;&#125;) data = json.loads(r.data) if data[&#39;errmsg&#39;] == &#39;ok&#39;: USERLIST = data[&#39;invaliduser&#39;] return USERLIST.split(&#39;|&#39;) except: print(&#39;消息发送失败！&#39;) 常见的获取python对象的Attribute（属性）的方法： 方法一： [item[&#39;userid&#39;] for item in USERLIST] 方法二： attrList = map(lambda x: x.attr, objectList) 使用`join`方法，组合字符串； 加入`try…except’防止异常抛出； 参考文章： Python——深入理解urllib、urllib2及requests（requests不建议使用？） 如何使用urllib3发送POST带参请求 Python–urllib3库详解1 Python中的json解析 python解析url返回的json格式数据 定时任务Apscheduler介绍from apscheduler.schedulers.background import BlockingScheduler from apscheduler.triggers.cron import CronTrigger import datetime scheduler = BlockingScheduler() def minHourJob(): today = datetime.datetime.now() fromTime = today + datetime.timedelta(hours=-1) startTime = today.strftime(&#39;%Y-%m-%d %H:00:00&#39;) # 使用cx_oracle读取oracle数据库中的数据，传递时间参数 data = orcl.getMinHours(startTime) if len(data) &gt; 0: list = data[0] msg = &quot;分钟数据完整率[按小时统计]：&#123;a&#125;至&#123;b&#125;，收到数据量：&#123;c&#125;，应有数据量：&#123;d&#125;，数据完整率：&#123;e&#125;&quot;.format( a=fromTime.strftime(&#39;%Y-%m-%d %H:00:00&#39;), b=startTime, c=list[0], d=list[1], e=list[2] ) if isSendCheck(&#39;minHourNum&#39;, list): auth.sendMsg(msg) trigger = CronTrigger(day_of_week=&#39;*&#39;, hour=&#39;*&#39;, minute=&#39;*&#39;, second=&#39;*/5&#39;) scheduler.add_job(minHourJob, trigger, id=&#39;job_min_hours&#39;) scheduler.start() 使用Blocking阻塞的方式创建了scheduler； 把minHourJob加入定时任务，设置每5秒执行一次； 使用datetime.timedelta对时间进行运算，strftime格式化时间； 参考文章： Python定时任务的实现方式 Python下APScheduler的快速指南 python 实现日期加1天或减少一天 加入logging模块： import logging # log part log = logging.getLogger(&#39;定时任务&#39;) log.setLevel(logging.INFO) # DEBUG fmt = logging.Formatter(&#39;[%(levelname)s]: %(name)s-%(message)s&#39;) log_path = &quot;../debug.log&quot; h = logging.FileHandler(log_path) # h = logging.StreamHandler() h.setFormatter(fmt) log.addHandler(h) 参考文章： python logging模块使用教程 使用pyinstaller打包windows应用因为考虑到方便在windows上运行，所以使用pyinstaller打包应用； 需要一台windows机器，如果之前是在Linux上开发，那么需要导出requirements.txt（依赖包） pip install pipreqs pipreqs [options] &lt;path&gt; 简单的安装pyinstaller之后，就可以使用该命令打包应用了。 pip install pyinstaller pyinstaller src/app.py 使用pip命令安装包的时候，可以使用-i命令，指定中国大陆的源，这样安装起来会比较快。 pip install pyinstaller -i https://pypi.douban.com/simple 参考文章： PYINSTALLER打包PYTHON脚本的一些心得 pip国内镜像源的配置 修改PyPI源 使用configparser读取配置文件有的时候，打包好的应用中有一些可变的因素，比如数据库连接、定时器的触发条件，需要把配置写在外面。 import configparser, os import cx_Oracle path = os.path.abspath(&#39;..&#39;) cp = configparser.ConfigParser() # ORCL连接 user = cp[&#39;db&#39;][&#39;user&#39;] passwd = cp[&#39;db&#39;][&#39;passwd&#39;] ip = cp[&#39;db&#39;][&#39;server&#39;] port = cp[&#39;db&#39;][&#39;port&#39;] SID = cp[&#39;db&#39;][&#39;sid&#39;] dsn_tns = cx_Oracle.makedsn(ip, port, SID) def execute(sql): con = cx_Oracle.connect(user, passwd, dsn_tns) cur = con.cursor() cur.execute(sql) res = cur.fetchall() con.commit() cur.close() con.close() return res 使用cx_oracle比较麻烦的是需要下载动态库，Linux与windows是一样的，需要在oracle官网下载client，如果提示如下错： cx_Oracle.DatabaseError: DPI-1047: Oracle Client library cannot be loaded: dlopen(libclntsh.dylib, 1): image not found. See https://oracle.github.io/odpi/doc/installation.html for help 说明可能配置没有配置好，官方的原话： Add Oracle 12.2, 12.1 or 11.2 client libraries to your operating system library search path such as PATH on Windows or LD_LIBRARY_PATH on Linux. On macOS move the files to ~/lib or /usr/local/lib. windows配置变量LD_LIBRARY_PATH ; linux或者Mac，新建lib目录，然后把.dylib的动态库文件使用ln -s链接过去。 参考文章： Python ConfigParser模块常用方法示例 Python 读取写入配置文件 —— ConfigParser cx_Oracle 6 Installation cx_Oracle - Oracle client on Mac OS X - RPATH issue","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://www.toimc.com/tags/python/"}]},{"title":"精益创业：新创企业的成长思维","slug":"精益创业：新创企业的成长思维","date":"2017-04-10T10:03:00.000Z","updated":"2019-03-16T01:36:02.000Z","comments":true,"path":"精益创业：新创企业的成长思维/","link":"","permalink":"https://www.toimc.com/%E7%B2%BE%E7%9B%8A%E5%88%9B%E4%B8%9A%EF%BC%9A%E6%96%B0%E5%88%9B%E4%BC%81%E4%B8%9A%E7%9A%84%E6%88%90%E9%95%BF%E6%80%9D%E7%BB%B4/","excerpt":"一本好书推荐给大家。精益创业的五项原则：1. 创业者无处不在。2. 创业即管理。3. 经证实的认知。4. 开发-测量-认知。5. 创新核算。","text":"一本好书推荐给大家。精益创业的五项原则：1. 创业者无处不在。2. 创业即管理。3. 经证实的认知。4. 开发-测量-认知。5. 创新核算。 创业需要快企业唯有快速顺应时代才能赢得未来，产品生产方式必须因时代而变。 创业的三个阶段创业的第一阶段是把想法变成产品。这时开发的产品是精简的原型，投入最少的金钱和精力开发出体现核心价值的产品。此时创业者们率领精干的成员，用类似特种部队的组织方式，在有限的资源和时间窗口内用很短的时间做出产品，并快速投入市场，通过不断的小规模实验，获得顾客反馈，进而不断迭代，让产品得到市场验证。 创业的第二阶段，新创企业要对正确的产品形态进行重点投入，做好做细，做“最了解用户的人”，做到极致。这个阶段，必须用最小的成本、在最短时间里找到最有价值的认知。 创业的第三阶段，成功者往往伴随着爆发式的增长，全面的扩张。企业开始与传统的、陈旧的市场势力展开阵地战。这一过程中，创业企业的力量之源正来自此前积累的对用户的深入理解和对市场的快速反应，即“爱与速度”。能到达第三个阶段的创业企业，大都把“对用户有爱、对产品有爱”作为一种信仰。他们不能容忍产品有缺点，不能容忍产品的用户体验不好，不能容忍BUG，跟0.1秒的延迟较劲，跟0.1M的大小较真…… 新创企业的成功不在于优良的基因，或生逢其时其地。它可以因为遵循了正确的流程而获得，也就是说，成功是可以习得的，是可以传授的。 乏味的琐事和细节才至关重要。 创业活动需要运用管理准则，才能从我们得到的创业机会中收获成果。 领导者需要创造条件，允许员工们进行创业活动中需要做的实验。 创业会失败的原因为什么新创企业以惨败告终的情况比比皆是？第一个原因在于好的计划、可靠的战略和深入的市场分析造成的诱惑。第二个原因在于，当目睹运用传统管理方式无法摆脱困境后，一些创业者和投资人干脆就撒手不管，回到“想做就做”跟着感觉走的状态。 如果创业的根本目的是在极不确定的情况下建立组织机构，那么它最重要的功能就是学习。为了要实现愿景，我们必须明确我们的哪些策略是可行的，哪些是过激的。我们必须了解顾客真正需要的是什么，而不是他们自己说要什么，或者我们认为他们应该要什么。我们必须认清自己是否朝着可持续企业之路发展成长。 保持学习的心态“学习”二字是书本里用以掩饰执行失败的惯用借口。 “学习”的概念。我将之称为“经证实的认知”。 如果你无法失败，就学不到东西。 创业的五项原则精益的思维方式把价值定义为“向顾客提供利益”，除此之外的任何东西都是浪费。 我们的工作就是要让企业愿景和顾客接受度相匹配。这并非向顾客自以为需要的东西让步，亦非告诉顾客他们应该要什么。 精益创业的五项原则：1. 创业者无处不在。2. 创业即管理。3. 经证实的认知。4. 开发-测量-认知。5. 创新核算。 胸怀大志，但要从小事做起新创企业的实验则由其愿景为指引，每个实验的目标都是为了要建立一项围绕愿景的可持续业务。 如果没有真正可行的增长模式，很多公司见了一些蝇头小利就会沾沾自喜、故步自封，却没意识到一次转型（改变方向或战略）也许会带来重大增长。唯一确认的方式就是在真实顾客那里系统地检测这个增长模式。 胸怀大志，从小事做起 企业做市场？做产品？最小化可行产品的目的则是开启学习认知的流程，而不是结束这个流程。与原型或概念测试不同的是，最小化可行产品并非用于回答产品设计或技术方面的问题，而是以验证基本的商业假设为目标。 最小化可行产品的经验教训在于，不管某项工作在当时看起来多么重要，只要在开启认知流程所需之外的，都是浪费。 开发-测量-认知 现代生产流程以高质量作为一种提升效率的方式，它们遵从质量管理大师爱德华·戴明（W.Edwards Deming）的格言：顾客是生产流程中最重要的部分。 在不正确的时间做了超乎寻常的事情，感觉很了不起，其实没有卵用。 在许多行业中，专利大多有着防御目的，作为一种威慑力制约竞争对手。这种情况下，相比最小化可行产品在认知方面的所得，它的专利风险较小。但是，在某些以新的科学突破为公司核心竞争优势的行业中，则需要更小心地平衡这种风险。无论哪种情形，创业者都应该寻求法律咨询，确保自身充分了解所有风险。 创新核算分三步走：第一，使用最小化可行产品确定企业目前所处阶段的真实数据。第二，新创企业必须尝试把增长引擎从基准线逐步调至理想状态，这期间可能要经过多次尝试。第三步：转型还是坚持？ 当我们的努力方向和顾客真实所需一致时，我们的实验就更可能把顾客行为往更好的方面调整。","categories":[{"name":"成长路上","slug":"成长路上","permalink":"https://www.toimc.com/categories/%E6%88%90%E9%95%BF%E8%B7%AF%E4%B8%8A/"}],"tags":[{"name":"创业","slug":"创业","permalink":"https://www.toimc.com/tags/%E5%88%9B%E4%B8%9A/"}]},{"title":"认知与设计——理解UI设计","slug":"认知与设计——理解UI设计","date":"2017-02-20T16:37:00.000Z","updated":"2019-03-18T02:27:35.000Z","comments":true,"path":"认知与设计——理解UI设计/","link":"","permalink":"https://www.toimc.com/%E8%AE%A4%E7%9F%A5%E4%B8%8E%E8%AE%BE%E8%AE%A1%E2%80%94%E2%80%94%E7%90%86%E8%A7%A3UI%E8%AE%BE%E8%AE%A1/","excerpt":"《认知与设计》阅后感和一些摘抄，学习前端不得不会、不得不懂的UI设计的基础原则。","text":"《认知与设计》阅后感和一些摘抄，学习前端不得不会、不得不懂的UI设计的基础原则。 一、我们感知自己的期望经验、环境、目标是影响我们感知的因素。就像一幅画中我们可能看到的是可能是LIFE这个单词或者是几个建筑俯视图。周围的环境也会影响我们看到的东西，THE CHT如果去一个工具箱里面找剪刀，我们不会关心工具箱里面是否有螺丝刀。鸡尾酒会效应——你会在嘈杂的环境中听见你想听到声音，你也会在与你不关心的话题的人谈话过程中，去注意环境中别人在谈论的内容。对设计意味着什么 避免歧义 2. 保持一致 3. 理解目标 二、为观察结构优化我们的视觉格式塔原理： 接近性：我们会认识相互接近的物体是一组，或者是相关的。 相似性：相似的物体是一组。 连续性：我们的视觉会自动的闭合认知连续的事物，像IBM的百叶窗的标志。 封闭性：我们感知一个完整的物体。 对称性：我们会组织我们看到形状，对称的来组织。 主体/背景：主体建立在背景之上，通常主体比背景元素要少。背景传递信息，或者暗示一个主题、品牌或者内容所表达的情绪。（弹窗+遮罩） 共同命运：相同的元素，如果采用不同的动作，我们的认知会告诉我们相同动作的是一组 三、我们寻找和使用视觉结构几个关键词：扫描、从上到下从左到右、形式结构、图形设计 结构提高了用户浏览长数的能力如：我们会区别 电话号码 与 信用卡。 数据专用控件找了更多的结构如：时间选择控件、邮件控件 视觉层次让人专注于相关的信息如：文章中的分段、缩进、加粗都是给予层次信息很重要的体验方式。 四、阅读不是自然的 我们的大脑是为语言而不是为阅读设计的。 阅读是特征驱动还是语境驱动，熟练阅读和不熟练阅读使用大脑不同的部位。 糟糕的信息设计会影响阅读（1）不常见和不熟悉的词汇（2）难以辨认的书写和字型。（3）微小的字体（4）嘈杂背景下的文字（5）信息被重复的内容淹没（6）居中对齐的文字（7）妨碍阅读的设计缺陷的组合（8）对设计的启示：支持，而不是干扰的阅读 软件里要求的阅读很多都是不必要的对设计的启示：尽量少让人阅读 对真实用户的测试","categories":[{"name":"成长路上","slug":"成长路上","permalink":"https://www.toimc.com/categories/%E6%88%90%E9%95%BF%E8%B7%AF%E4%B8%8A/"}],"tags":[{"name":"UI","slug":"UI","permalink":"https://www.toimc.com/tags/UI/"}]},{"title":"Gitlab+Jenkins+docker完成Maven项目的自动部署","slug":"Gitlab+Jenkins+docker完成Maven项目的自动部署","date":"2016-12-20T16:00:00.000Z","updated":"2019-08-03T17:00:27.000Z","comments":true,"path":"Gitlab+Jenkins+docker完成Maven项目的自动部署/","link":"","permalink":"https://www.toimc.com/Gitlab+Jenkins+docker%E5%AE%8C%E6%88%90Maven%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/","excerpt":"工程自动化开发环境搭建：Gitlab+Jenkins+docker如何来构建Maven项目","text":"工程自动化开发环境搭建：Gitlab+Jenkins+docker如何来构建Maven项目 本文的环境：Ubuntu 16.04LTSDocker version 1.12.5, build 7392c3b 思路： Jenkisn安装在宿主机上，通过Jenkins从属机来拉取gitlab上的代码，进行Maven编译，使用docker进行发布。 安装Jenkins关于Docker的安装，国内用户建议使用以下脚本： #!/bin/sh mv /etc/apt/sources.list /etc/apt/sources.list.bak cd /etc/apt/ cat &gt; sources.list &lt;&lt;- EOF deb-src http://archive.ubuntu.com/ubuntu xenial main restricted #Added by software-properties deb http://mirrors.aliyun.com/ubuntu/ xenial main restricted deb-src http://mirrors.aliyun.com/ubuntu/ xenial main restricted multiverse universe #Added by software-properties deb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted deb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted multiverse universe #Added by software-properties deb http://mirrors.aliyun.com/ubuntu/ xenial universe deb http://mirrors.aliyun.com/ubuntu/ xenial-updates universe deb http://mirrors.aliyun.com/ubuntu/ xenial multiverse deb http://mirrors.aliyun.com/ubuntu/ xenial-updates multiverse deb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse #Added by software-properties deb http://archive.canonical.com/ubuntu xenial partner deb-src http://archive.canonical.com/ubuntu xenial partner deb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted deb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted multiverse universe #Added by software-properties deb http://mirrors.aliyun.com/ubuntu/ xenial-security universe deb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverse EOF apt-get update curl -sSL https://get.daocloud.io/docker | sh curl -L https://get.daocloud.io/docker/compose/releases/download/1.12.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose 可以选择官方的Docker镜像。 docker run -p 8080:8080 -p 50000:50000 jenkins 不过没有本地环境，如果需要在Jenkins的宿主机上跑docker的话可以使用如下镜像包： 建议使用我写的安装包，包含JAVA与maven环境： docker run -it -d -p 8080:8080 -v /opt/jenkins:/jenkins -v /etc/localtime:/etc/localtime:ro --name jenkins lw96/java8-jenkins-maven-git-vim 这个包里面包含的环境： Ubuntu 16.04 LTS Oracle Java 1.8.0_112-b15 64 bit Maven 3.3.9 Jenkins 2.19.4 git 2.7.4 Vim 不定期进行更新到最新的Jenkins，欢迎大家下载点星。 添加从属机与权限系统管理→管理节点→新建节点 选择节点名称：选择Permament Agent # of exectors 并发数 看你从属机的配置了 远程工作目录： /opt/jenkins_workspace 标签： SlaveServer 用法： 尽可能的使用这个节点 启用方法： Launch slave agents via SSH Host: www.example.com Credentials: 点击Add添加，或者选择一个SSHkey Availability: keep this agent online as much as possible 上面的配置基本完成了一个从属机器的连接配置信息。 关于SSH登录与配置，点击我。 下面的Node Properties中Environment variables为环境变量，Tools Locations为一些环境： 比如我的是这样填的： git-2.7.4 /usr/bin/git Docker /usr/bin/docker Maven3.3.9 /opt/maven Java8 /opt/java 以上路径为slave机上的环境。 我写了一个简单的安装shell脚本： apt-get update apt-get install -y wget export MAVEN_NAME=apache-maven-3.3.9 export MAVEN_HOME=/opt/maven/ wget --no-verbose -O /tmp/$MAVEN_NAME.tar.gz http://archive.apache.org/dist/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz \\ &amp;&amp; mkdir /opt/maven \\ &amp;&amp; tar -zxf /tmp/$MAVEN_NAME.tar.gz -C /opt/maven --strip-components=1 \\ &amp;&amp; ln -s /opt/maven/bin/mvn /usr/local/bin \\ &amp;&amp; rm -f /tmp/$MAVEN_NAME.tar.gz apt-get install -y git wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; -O /tmp/jdk-8u112-linux-x64.tar.gz http://download.oracle.com/otn-pub/java/jdk/8u112-b15/jdk-8u112-linux-x64.tar.gz \\ &amp;&amp; mkdir /opt/java \\ &amp;&amp; tar -zxf /tmp/jdk-8u112-linux-x64.tar.gz -C /opt/java/ --strip-components=1 \\ &amp;&amp; update-alternatives --install /usr/bin/java java /opt/java/bin/java 20000 \\ &amp;&amp; update-alternatives --install /usr/bin/javac javac /opt/java/bin/javac 20000 点击保存。 新建任务我的工作目录： mkdir /opt/jenkins_workspace cd /opt/jenkins_workspace # 用来拉取gitlab代码，并编译用 mkdir workspace # 用来存项目的war包与发布用 mkdir war （1）回到Jenkins首页，点击新建任务，选择自动风格。 General部分选择Restrict where this project can be run: 输入前面写的从属机的标签：SlaveServer （2）源码管理，点击Git: 填入Repository URL仓库地址：比如ssh://www.example.com/test.git 选择之前添加的密钥，同理，把密钥添加到gitlab项目中。 点击高级，选择Name为origin 下面的分支选择origin/dev (3)构建触发器： 选择Build when a change is pushed to Gitlab. Gitlab CI Service URL:http://jenkins.example.com:8080/project/projectName 取消 Comments前面的勾。其他可以根据自己的需要调整。 在Gitlab中，进入项目中，选择项目设置→webhook→Url处填入上面的URL。 这样就完成了项目的自动触发。 （4）构建添加Maven构建War包： 选择MavenVersion→命令：clean install→POM：pom.xml 选择Exectue Shell cd /opt/jenkins_workspace &amp;&amp; ./del.sh test 10000 其中del.sh脚本中的内容如下： 大体思想是，传递两个参数，一个是项目名称，一个项目运行的端口。 先去判断有没有这个同名容器，如果有，那就删除这个容器。 再去判断有没有端口被其他应用占用，如果没有，就运行容器；如果有，就在端口池里面随机一个端口进行运行容器。 #!/bin/bash CONTAINER=$1 PORT=$2 MAXPORT=10000 MINPORT=20000 DIR=&quot;`dirname $BASH_SOURCE`&quot; MYDIR=`readlink -f &quot;$DIR&quot;` # MYDIR=&quot;$( cd &quot;$( dirname &quot;$&#123;BASH_SOURCE[0]&#125;&quot; )&quot; &amp;&amp; pwd )&quot; echo $MYDIR # functions # docker function start_docker()&#123; filePath=$MYDIR/war/$CONTAINER echo &quot;docker use filePath is $filePath&quot; docker run -it -d --name $CONTAINER -p $PORT:8080 -v $filePath:/usr/local/tomcat/webapps tomcat:7-jre8 &#125; #check docker exist check_docker()&#123; RUNNING=$(docker inspect --format=&quot;&#123;&#123; .State.Running &#125;&#125;&quot; $CONTAINER 2&gt; /dev/null) if [ $? -eq 1 ]; then echo &quot;$CONTAINER does not exist.&quot; return 1 fi if [ &quot;$RUNNING&quot; == &quot;false&quot; ]; then echo &quot;$CONTAINER is not running.&quot; return 2 else echo &quot;$CONTAINER is running&quot; fi &#125; # check port check_port() &#123; echo &quot;Checking instance port ...&quot; netstat -tlpn | grep &quot;\\b$1\\b&quot; &#125; #random a number rand()&#123; min=$1 max=$(($2-$min+1)) num=$(cat /dev/urandom | head -n 10 | cksum | awk -F &#39; &#39; &#39;&#123;print $1&#125;&#39;) echo $(($num%$max+$min)) &#125; # delete same name container matchingStarted=$(docker ps --filter=&quot;name=$CONTAINER&quot; -q | xargs) [[ -n $matchingStarted ]] &amp;&amp; docker stop $matchingStarted matching=$(docker ps -a --filter=&quot;name=$CONTAINER&quot; -q | xargs) [[ -n $matching ]] &amp;&amp; docker rm $matching # create warfile dir cd `dirname $0`/war if [ ! -d `pwd`/$1 ]; then mkdir $1 else rm -rf $1/* echo &quot;`dirname $0`/workspace/$1/target/&quot; cp $MYDIR/workspace/$1/target/*.war `pwd`/$1/$1.war fi # check port if check_port $PORT then PORT=$(rand $MINPORT $MAXPORT) while check_port $PORT do PORT=$(rand $MINPORT $MAXPORT) done fi echo &quot;use $PORT to start $1 docker&quot; start_docker echo &quot;docker has started, waiting for tomcat.End!&quot; exit 0 （5）保存，Have Fun","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.toimc.com/tags/Docker/"},{"name":"Gitlab","slug":"Gitlab","permalink":"https://www.toimc.com/tags/Gitlab/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://www.toimc.com/tags/Jenkins/"}]},{"title":"如何在Ubuntu上搭建私有Docker仓库","slug":"如何在Ubuntu上搭建私有Docker仓库","date":"2016-12-13T16:00:00.000Z","updated":"2019-08-03T17:05:42.000Z","comments":true,"path":"如何在Ubuntu上搭建私有Docker仓库/","link":"","permalink":"https://www.toimc.com/%E5%A6%82%E4%BD%95%E5%9C%A8Ubuntu%E4%B8%8A%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89Docker%E4%BB%93%E5%BA%93/","excerpt":"本章的内容已经过时！！ Docker作为在服务器上，非常不错的一个部署部署工具。那大家应该使用过Docker hub，一个存储镜像的公有的Docker仓库。但是，当你创建了一个镜像上传到Docker hub上之后，必须公开你所创建的镜像——这可能不是你所想要的。因为，我们的很多项目，可能需要私有化。","text":"本章的内容已经过时！！ Docker作为在服务器上，非常不错的一个部署部署工具。那大家应该使用过Docker hub，一个存储镜像的公有的Docker仓库。但是，当你创建了一个镜像上传到Docker hub上之后，必须公开你所创建的镜像——这可能不是你所想要的。因为，我们的很多项目，可能需要私有化。 这是一篇如何搭建Docker私有仓库，并对仓库进行加密的教程。在教程的最后，你将学会如何建立私有镜像上传到自己的Docker仓库，并且以一种加密的方式，把自己的镜像从私有仓库拉取回来。 这篇教程没有把容器相关的知识全部涵盖到，只是把创建私有Docker放在第一介绍的位置。如果说，你想去学习Docker（而非Docker仓库本身），你可以在这个地方学习: Docker官方教程 这篇教程在Ubuntu14.04环境上架设，也可以在基于Debian的发行版上架设。同样，本教程涵盖了Docker 2.0版本。 Docker相关概念如果说之前你没有使用过Docker，那可能需要先来学习几个Docker相关的概念。如果说，你已经学习并使用过Docker，可以跳过这个章节，进入下一步。 为小白准备了一个Docker备忘录。 Docker的核心是分离应用和运行于该操作系统上的应用依赖。为了达到这个目的，Docker使用了容器与镜像。Docker镜像是一个基础的模块文件系统。当创建了Docker镜像之后，一个实例的文件系统就会创建，并在宿主机的Docker容器中运行起来。但是，宿主机的文件系统与容器的文件系统默认是隔离的，容器是一个隔离的运行环境。 无论在容器内部作了任何的改变，都不会影响到Docker的原始镜像，只会影响到正在运行的镜像本身。如果说，需要把改变保留下来，使用commit命令把该镜像容器生成一个镜像（docker commit命令）。这意味着，你可以根据旧的容器来产生新的容器，并且不影响原先的容器的文件系统（或者说镜像）。如果说你之前学习过git，那么Docker与Git有很相近的工作流：Docker里面的新容器或者说新镜像，就像是在Git中新建了一个分支一样，运行珍上新的镜像，就像是git中的切换分支git checkout。 形象一点说，存放Docker镜像的Docker仓库中的就像Git仓库一样。 先决条件继续这个教程，可能需要以下环境： 有管理员账户的2个Ubuntu14.04环境: 一个Docker仓库，一个Docker客户机。 安装Docker和Docker Compose。 一个可以解析到Ubuntu机器的域名。 安装Apache2扩展包为了让Docker仓库更加安全，最好使用Docker Compose。 通过Docker Compose可以轻松在Docker容器中构建Docker仓库，并且在另一个Docker镜像中构建Nginx容器，来负责Docker仓库认证环境。 所以，我们需要一个文件来存放访问我们私有仓库的用户名与密码。需要安装apached2-utils，它包含了htpasswd工具包，可以产生Nginx可以理解的hashes值，来保证Docker仓库的安全： sudo apt-get -y install apache2-utils 安装与配置Docker仓库Docker原生的命令行工具可以很好的管理与运行Docker容器，但是大多数容器并不是独立运行的容器。为了可以部署大部分应用，可能需要并行运行多个组件。例如：大多数应用需要的Web服务，可能需要像解析语言PHP、或者Ruby(with rails)，数据库服务MySQL。 使用Docker Compose可以在.yml的配置文件中，配置所有的Docker容器，以及容器之间的通信。使用docker-compose命令行工具，可以轻松的管理docker容器，docker-compose就像是一个复合管理命令。 Docker仓库需要多个组件来运行，使用docker-compose来进行管理，唯一需要定义的是仓库存放数据的位置。开始吧，在宿主机上，建立一个放置YAML配置文件和数据的位置： mkdir ~/docker-registry &amp;&amp; cd $_ mkdir data 使用nano或者vim来编辑docker-compose.yml文件： nano docker-compose.yml 添加如下内容： registry: container_name: &quot;docker-registry&quot; image: registry:2 ports: - 5000:5000 environment: REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY: /data volumes: - /root/docker-registry/data:/data 通过设置docker仓库的环境变量REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY来指定仓库容器建立之后，数据在容器中的存放位置。当容器启动之后，会到该变量的地方去建立数据。而volumes配置，设置了与宿主机的数据映射关系：在容器中的/data目录与宿主机的~/docker-registry/data建立了宿主关系。启动容器： cd ~/docker-registry docker-compose up -d 可以通过docker logs docker-registry查看docker-registry的运行日志信息。 上面的配置文件很好理解，有一个叫docker-registry的docker镜像registry:2，运行在5000端口，映射到宿主机的5000端口。 可以通过docker-compose stop docker-registry和docker=compose rm docker-registry来停止与删除容器。 运行Nginx容器下面来着手解决容器的安全问题。第一步，需要另外新建一个Nginx容器，并且与我们的Dokcer仓库链接起来。新建一个Ngnix的配置文件： mkdir ~/docker-registry/nginx nano ~/docker-registry/nginx/registry.conf 加入以下内容： upstream docker-registry &#123; server registry:5000; &#125; server &#123; listen 443; server_name myregistrydomain.com; # SSL # ssl on; # ssl_certificate /etc/nginx/conf.d/domain.crt; # ssl_certificate_key /etc/nginx/conf.d/domain.key; # disable any limits to avoid HTTP 413 for large image uploads client_max_body_size 0; # required to avoid HTTP 411: see Issue #1486 (https://github.com/docker/docker/issues/1486) chunked_transfer_encoding on; location /v2/ &#123; # Do not allow connections from docker 1.5 and earlier # docker pre-1.6.0 did not properly set the user agent on ping, catch &quot;Go *&quot; user agents if ($http_user_agent ~ &quot;^(docker\\/1\\.(3|4|5(?!\\.[0-9]-dev))|Go ).*$&quot; ) &#123; return 404; &#125; # To add basic authentication to v2 use auth_basic setting plus add_header # auth_basic &quot;registry.localhost&quot;; # auth_basic_user_file /etc/nginx/conf.d/registry.password; # add_header &#39;Docker-Distribution-Api-Version&#39; &#39;registry/2.0&#39; always; proxy_pass http://docker-registry; proxy_set_header Host $http_host; # required for docker client&#39;s sake proxy_set_header X-Real-IP $remote_addr; # pass on real client&#39;s IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_read_timeout 900; &#125; &#125; 并且再次编辑目录~/docker-registry下的docker-compose.yml文件： nano docker-compose.yml 加入以下内容： registry: container_name: &quot;docker-registry&quot; image: registry:2 ports: - 5000:5000 environment: REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY: /data volumes: - ./data:/data nginx: container_name: &quot;docker-nignx&quot; image: &quot;nginx:1.9&quot; ports: - 5043:443 links: - registry:registry volumes: - ./nginx/:/etc/nginx/conf.d:ro volumes可以使用绝对位置，也可以使用相对位置，相对该配置文件的位置。 使用docker-compose up -d命令，可以在同一时间一次运行两个容器：docker仓库和Nginx。同样，使用log命令，查看docker与nginx的运行情况。 测试HTTP请求： curl http://localhost:5000/v2/ 如果看到： &#123;&#125; 或者： curl http://localhost:5043/v2/ 看到： &#123;&#125; 说明，已经成功构建了Docker仓库，并且Nginx运行良好。如果，没有curl命令，可以通过apt-get install curl来安装curl。 使用docker-compose中的日志命令，在docker-compose.yml配置文件下使用如下命令： docker-compose logs 可以看到如下信息： registry_1 | time=&quot;2015-08-11T10:24:53.746529894Z&quot; level=debug msg=&quot;authorizing request&quot; environment=development http.request.host=&quot;localhost:5043&quot; http.request.id=55c3e2a6-4f34-4b0b-bc57-11c814b4f4d3 http.request.method=GET http.request.remoteaddr=172.17.42.1 http.request.uri=&quot;/v2/&quot; http.request.useragent=&quot;curl/7.35.0&quot; instance.id=55634dfc-c9e0-4ec9-9872-6f4930c17759 service=registry version=v2.0.1 registry_1 | time=&quot;2015-08-11T10:24:53.747650205Z&quot; level=info msg=&quot;response completed&quot; environment=development http.request.host=&quot;localhost:5043&quot; http.request.id=55c3e2a6-4f34-4b0b-bc57-11c814b4f4d3 http.request.method=GET http.request.remoteaddr=172.17.42.1 http.request.uri=&quot;/v2/&quot; http.request.useragent=&quot;curl/7.35.0&quot; http.response.contenttype=&quot;application/json; charset=utf-8&quot; http.response.duration=8.143193ms http.response.status=200 http.response.written=2 instance.id=55634dfc-c9e0-4ec9-9872-6f4930c17759 service=registry version=v2.0.1 registry_1 | 172.17.0.21 - - [11/Aug/2015:10:24:53 +0000] &quot;GET /v2/ HTTP/1.0&quot; 200 2 &quot;&quot; &quot;curl/7.35.0&quot; nginx_1 | 172.17.42.1 - - [11/Aug/2015:10:24:53 +0000] &quot;GET /v2/ HTTP/1.1&quot; 200 2 &quot;-&quot; &quot;curl/7.35.0&quot; &quot;-&quot; 设置认证服务现在，Nginx作为代理控制着Docker仓库的HTTP请求，所以，可以通过Nginx来控制用户访问权限。使用之前安装的apache的htpasswd组件，创建第一个用户：（下面的USERNAME可以替换成其他的用户） cd ~/docker-registry/nginx htpasswd -c registry.password USERNAME 创建用户密码： htpasswd registry.password USERNAME 使用-c可以重新创建配置文件，会覆盖之前的用户配置信息。 查看之前创建的Nginx的配置文件： nano ~/docker-registry/nginx/registry.conf 把如下注释给取消： # To add basic authentication to v2 use auth_basic setting plus add_header auth_basic &quot;registry.localhost&quot;; auth_basic_user_file /etc/nginx/conf.d/registry.password; add_header &#39;Docker-Distribution-Api-Version&#39; &#39;registry/2.0&#39; always; 使用docker-compose up --force-recreate -d重新创建容器，使上述的配置生效。再次使用curl命令： curl http://localhost:5043/v2/ 会看到如下内容： &lt;html&gt; &lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt; &lt;body bgcolor=&quot;white&quot;&gt; &lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt; &lt;hr&gt;&lt;center&gt;nginx/1.9.7&lt;/center&gt; &lt;/body&gt; &lt;/html&gt; 使用如下命令： curl http://USERNAME:PASSWORD@localhost:5043/v2/ 如果看到： &#123;&#125; 说明，设置认证服务已经生效。 设置SSL首先，设置nginx配置文件，取消如下注释内容： server &#123; listen 443; server_name myregistrydomain.com; # SSL ssl on; ssl_certificate /etc/nginx/conf.d/domain.crt; ssl_certificate_key /etc/nginx/conf.d/domain.key; 这个地方要注意一下，之前在docker-compose.yml配置文件中，宿主机的~/docker-registry/nginx/与Nginx容器的/etc/nginx/conf.d/映射关系，把相应的认证密钥与证书放置在宿主机的~/docker-registry/nginx/下，即Nginx容器可以访问了。 两种获取SSL证书的方式：自签或者申请。 申请有免费的DV证书，也有前面博客介绍的使用Let’s Encrypt全站启用HTTPS协议的方法申请Let’s Encrypt的免费证书。 下面介绍一下自签证书的方法： cd ~/docker-registry/nginx 使用openssl来自签证书： openssl genrsa -out devdockerCA.key 2048 openssl req -x509 -new -nodes -key devdockerCA.key -days 10000 -out devdockerCA.crt openssl genrsa -out domain.key 2048 重要：在Common Name处输入docker服务器的域名或者IP。 openssl req -new -key domain.key -out dev-docker-registry.com.csr 如果域名www.toimc.com，那么可以按照如下设置： Country Name (2 letter code) [AU]: State or Province Name (full name) [Some-State]: Locality Name (eg, city) []: Organization Name (eg, company) [Internet Widgits Pty Ltd]: Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []:www.toimc.com Email Address []: Please enter the following &#39;extra&#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: 不需要设置challenge password。 openssl x509 -req -in dev-docker-registry.com.csr -CA devdockerCA.crt -CAkey devdockerCA.key -CAcreateserial -out domain.crt -days 10000 因为证书没有任何认证机构进行认证，所以需要给所有的客户机这是一个合法的证书。首先，在宿主机上设置，这样，可以在Docker容器中使用Docker仓库中的证书。 sudo mkdir /usr/local/share/ca-certificates/docker-dev-cert sudo cp devdockerCA.crt /usr/local/share/ca-certificates/docker-dev-cert sudo update-ca-certificates 重启Docker服务： sudo service docker restart 测试SSL证书cd ~/docker-registry docker-compose up --force-recreate -d 使用curl来测试HTTPS连接： curl https://USERNAME:PASSWORD@[YOUR-DOMAIN]:5043/v2/ 如果使用是自签的证书，可能看到如下错误： curl: (60) SSL certificate problem: self signed certificate 使用-k选项，不认证peer： curl -k https://USERNAME:PASSWORD@[YOUR-DOMAIN]:5043/v2/ 如果域名是：www.toimc.com curl https://liwei:test@www.toimc.com:5043/v2/ 收到&#123;&#125;，说明HTTPS工作正常。 设置SSL为443端口打开docker-compose.yml的配置： nano ~/docker-registry/docker-compose.yml 修改端口的映射关系： nginx: image: &quot;nginx:1.9&quot; ports: - 443:443 links: - registry:registry volumes: - ./nginx/:/etc/nginx/conf.d:ro registry: image: registry:2 ports: - 5000:5000 environment: REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY: /data volumes: - ./data:/data 使用--force-recreate来重新生成容器。 现在可以使用: docker login https://&lt;YOURDOMAIN&gt; 或者： curl https://&lt;YOURUSERNAME&gt;:&lt;YOURPASSWORD&gt;@YOUR-DOMAIN/v2/ 在客户机上进行测试。 如何使用与docker.io的使用是一样的，只不过在commit镜像的时候，需要加上仓库地址，如： docker login https://&lt;YOURDOMAIN&gt; 输入密码，然后： docker commit &lt;容器ID&gt; &lt;YOURDOMAIN&gt;/&lt;容器名&gt; docker push &lt;YOURDOMAIN&gt;/&lt;容器名&gt; 使用镜像： docker pull &lt;YOURDOMAIN&gt;/&lt;容器名&gt;","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.toimc.com/tags/Docker/"}]},{"title":"Ubuntu上安装Docker卡在了“setting up docker-engine”","slug":"Docker安装问题","date":"2016-12-13T16:00:00.000Z","updated":"2019-03-12T16:06:14.000Z","comments":true,"path":"Docker安装问题/","link":"","permalink":"https://www.toimc.com/Docker%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/","excerpt":"本文介绍了Ubuntu上安装Docker卡在了“setting up docker-engine”","text":"本文介绍了Ubuntu上安装Docker卡在了“setting up docker-engine” 解决办法： 1.使用Ctrl+C来中止安装。 2.使用如下命令，新建Docker service mkdir /etc/systemd/system/docker.service.d vi /etc/systemd/system/docker.service.d/overlay.conf #添加如下内容 [Service] ExecStart= ExecStart=/usr/bin/docker daemon -H fd:// -s overlay # ESC+ :wq 保存退出 3.更新系统服务 sudo systemctl daemon-reload 4.确定刚刚的服务已经生效 systemctl show --property=ExecStart docker 5.重启docker服务 sudo systemctl restart docker 6.测试一下 docker run hello-world","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.toimc.com/tags/Docker/"}]},{"title":"git submodule","slug":"git submodule","date":"2016-11-27T16:26:48.000Z","updated":"2019-08-29T14:21:11.000Z","comments":true,"path":"git submodule/","link":"","permalink":"https://www.toimc.com/git%20submodule/","excerpt":"git submodule的介绍，常用命令git submodule add，git submodule init等。","text":"git submodule的介绍，常用命令git submodule add，git submodule init等。 submodule子模块的意思，git submodule的应用场景：经常有这样的事情，当你在一个项目上工作时，你需要在其中使用另外一个项目。也许它是一个第三方开发的库或者是你独立开发和并在多个父项目中使用的。这个场景下一个常见的问题产生了：你想将两个项目单独处理但是又需要在其中一个中使用另外一个。 这里有一个例子。假设你在开发一个网站，为之创建Atom源。你不想编写一个自己的Atom生成代码，而是决定使用一个库。你可能不得不像CPAN install或者Ruby gem一样包含来自共享库的代码，或者将代码拷贝到你的项目树中。如果采用包含库的办法，那么不管用什么办法都很难去定制这个库，部署它就更加困难了，因为你必须确保每个客户都拥有那个库。把代码包含到你自己的项目中带来的问题是，当上游被修改时，任何你进行的定制化的修改都很难归并。 Git 通过子模块处理这个问题。子模块允许你将一个 Git 仓库当作另外一个Git仓库的子目录。这允许你克隆另外一个仓库到你的项目中并且保持你的提交相对独立。 1.git submodule add添加子模块 命令： git submodule add 仓库地址 路径 注意：路径不能以 / 结尾（会造成修改不生效）、不能是现有工程已有的目录（不能順利 Clone）；仓库地址是指子模块仓库地址，路径指将子模块放置在当前工程下的路径。 2.git submodule init初始化，update更新 当clone一个项目带子模块的项目。 当你接收到这样一个项目，你将得到了包含子项目的目录，但里面没有文件： 命令： #初始化子模块 git submodule init #当子模块中的代码更新后，更新项目 git submodule update 子模块中，可以正常的使用git add,git commit,git push等常见的git操作。 3.删除子模块 step1:删除config配置 git submodule deinit -f docker 使用-f删除文件，使用--cached保留文件。 step2:删除子模块缓存 git rm --cached the_submodule step3:删除子模块工作区文件 rm -rf the_submodule step4：删除子模块在仓库中的空文件夹 rm -rf .git/modules/the_submodule","categories":[{"name":"git入门","slug":"git入门","permalink":"https://www.toimc.com/categories/git%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"git","slug":"git","permalink":"https://www.toimc.com/tags/git/"},{"name":"版本控制","slug":"版本控制","permalink":"https://www.toimc.com/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}]},{"title":"使用git subtree管理项目中的子库","slug":"使用git subtree管理项目中的子库","date":"2016-11-27T16:26:48.000Z","updated":"2019-08-29T14:23:47.000Z","comments":true,"path":"使用git subtree管理项目中的子库/","link":"","permalink":"https://www.toimc.com/%E4%BD%BF%E7%94%A8git%20subtree%E7%AE%A1%E7%90%86%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E5%AD%90%E5%BA%93/","excerpt":"随着项目越来越多，很多项目依赖同一个模板或是配置文件想同一管理，又不想分开维护，所以只能互相引用，或是各自维护，导致了后续的很多麻烦。怎么办呢？","text":"随着项目越来越多，很多项目依赖同一个模板或是配置文件想同一管理，又不想分开维护，所以只能互相引用，或是各自维护，导致了后续的很多麻烦。怎么办呢？ 背景最近工作中遇到了一个问题：随着项目越来越多，很多项目依赖同一个模板或是配置文件想同一管理，又不想分开维护，所以只能互相引用，或是各自维护，导致了后续的很多麻烦。 场景一： 很多公司手机端和pc同时开发，引用同一套模板，或者通用的组件库。 场景二：用gulp、webpack来打包，或是用node来开发会有一些通用的配置文件需要统一管理。 1.可以使用git submodule方法，来建立一个子模块，方法见http://toimc.com/2016/11/git-submodule/ 2.使用git subtree方法： 可以在git bash中使用git subtree --help来看官方的说明。 语法： #从提交中，创建本地目录 git subtree add -P &lt;prefix&gt; &lt;commit&gt; #从仓库中，创建本地目录 git subtree add -P &lt;prefix&gt; &lt;repository&gt; &lt;ref&gt; #更新与推送 git subtree pull -P &lt;prefix&gt; &lt;repository&gt; &lt;ref&gt; git subtree push -P &lt;prefix&gt; &lt;repository&gt; &lt;ref&gt; #快速拆分目录代码 git subtree split -P &lt;prefix&gt; [OPTIONS] [&lt;commit&gt;] #与指定提交进行合并 git subtree merge -P &lt;prefix&gt; &lt;commit&gt; 合并指定提交中的代码到subtree中来。 如： #使用git subtree add新建了目录lib git subtree add -P lib &lt;repository&gt; &lt;ref&gt; #此后lib中的文件发生了多次的改变 #可以使用git subtree merge到某次的提交 git subtree merge -p lib &lt;commit&gt; 使用git log或者git reflog来查看提交代码，取前6位数 情景：项目A中已经有lib库，需要在其他地方使用。方法一：把lib目录（lib分支）中的代码，使用以下命令进行常规提交到另一个库 1.使用split方法 #语法 git subtree split -P &lt;prefix&gt; [OPTIONS] [&lt;commit&gt;] #实际使用 git subtree split -P lib -b newLib git push origin newLib #在其他项目中，拉取分支内容 git clone --branch=newLib &lt;repository&gt; &lt;ref&gt; 此命令会把目录下的lib目录，新建一个分支为newLib,里面会包含所有与lib目录下文件相关的commit。 以上命令，相当于是建立了一个新的分支去管理lib目录中的文件， *2.或者在分支中初始化一个git仓库，推送代码到远程分支，对分支进行管理（不过 这样就与submodule没有区别了，而且逻辑更复杂不便管理） git init git remote add lib &lt;reponame&gt; &lt;repourl&gt; git add . git commit -m &quot;first commit git push origin master 方法二：使用git subtree push方法 语法： git subtree push -P lib &lt;repository&gt; &lt;ref&gt; git subtree push --prefix=&lt;子目录名&gt; &lt;子仓库名&gt; &lt;分支&gt; --squash 情景：项目A中需要newLib项目中的代码作为lib库1.使用git subtree add命令新建目录 git subtree add --prefix=&lt;子目录名&gt; &lt;子仓库名&gt; &lt;分支&gt; --squash --squash 会把subtree上的改动合并成一次commit。 2.使用pull &amp; push操作更新代码 ## pull：git subtree pull --prefix=&lt;子目录名&gt; &lt;子仓库名&gt; &lt;分支&gt; --squash push：git subtree push --prefix=&lt;子目录名&gt; &lt;子仓库名&gt; &lt;分支&gt; --squash 总结 1.在新员工加入团队时：一次性clone项目，submodule可以一起clone出来，只需添加–recursive递归参数就可以了，而subtree并不行，只能手动添加，不过可以借助神器Yeoman(一个自动生成项目脚手架的工具)来实现。 2.subtree适合像配置文件这种需要跟着项目走的情况。 3.submodule适合在开发阶段时引用，到了生产环境会被打包到指定文件内，而本身并不用跟着版本走的情况。 参考文献： [1] “Git submodule的坑” [2] 使用git subtree &amp; submodule管理多个子项目 [3] Mastering Git subtrees [4] 用 Git Subtree 在多个 Git 项目间双向同步子项目，附简明使用手册","categories":[{"name":"git入门","slug":"git入门","permalink":"https://www.toimc.com/categories/git%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"git","slug":"git","permalink":"https://www.toimc.com/tags/git/"},{"name":"版本控制","slug":"版本控制","permalink":"https://www.toimc.com/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}]},{"title":"linux硬盘分区，LVS分区扩容，挂载mount","slug":"linux硬盘分区，LVS分区扩容，挂载mount","date":"2016-11-26T16:00:00.000Z","updated":"2019-03-12T15:59:03.000Z","comments":true,"path":"linux硬盘分区，LVS分区扩容，挂载mount/","link":"","permalink":"https://www.toimc.com/linux%E7%A1%AC%E7%9B%98%E5%88%86%E5%8C%BA%EF%BC%8CLVS%E5%88%86%E5%8C%BA%E6%89%A9%E5%AE%B9%EF%BC%8C%E6%8C%82%E8%BD%BDmount/","excerpt":"前言：前段时间gitlab服务器挂了，看了一下日志，提示空间满了。 df -m看了一下硬盘，满了。所以想来操作加一块盘上来。 完成下面的操作后: 硬盘使用30%","text":"前言：前段时间gitlab服务器挂了，看了一下日志，提示空间满了。 df -m看了一下硬盘，满了。所以想来操作加一块盘上来。 完成下面的操作后: 硬盘使用30% root@ubuntu:/home/liwei# df -m Filesystem 1M-blocks Used Available Use% Mounted on udev 1951 0 1951 0% /dev tmpfs 395 12 383 3% /run /dev/mapper/ubuntu--vg-root 78004 21704 52836 30% / tmpfs 1972 2 1971 1% /dev/shm tmpfs 5 0 5 0% /run/lock tmpfs 1972 0 1972 0% /sys/fs/cgroup /dev/sda1 472 160 288 36% /boot tmpfs 1 0 1 0% /run/lxcfs/controllers tmpfs 395 1 395 1% /run/user/112 tmpfs 395 0 395 0% /run/user/0 下面我们进入正题： 1.fdisk -l 察看所有分区 Disk /dev/sda: 60 GiB, 64424509440 bytes, 125829120 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xe868d67b Device Boot Start End Sectors Size Id Type /dev/sda1 * 2048 999423 997376 487M 83 Linux /dev/sda2 1001470 62912511 61911042 29.5G 5 Extended /dev/sda3 62912512 125829119 62916608 30G 8e Linux LVM /dev/sda5 1001472 62912511 61911040 29.5G 8e Linux LVM Partition table entries are not in disk order. Disk /dev/sdb: 20 GiB, 21474836480 bytes, 41943040 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xe4879f9e Device Boot Start End Sectors Size Id Type /dev/sdb1 2048 41943039 41940992 20G 83 Linux Disk /dev/mapper/ubuntu--vg-root: 77.5 GiB, 83231768576 bytes, 162562048 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/ubuntu--vg-swap_1: 2 GiB, 2147483648 bytes, 4194304 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 2.fdisk /dev/sdb1 对分区进行分区，使用m参看命令（PS：/sdb1，自己来看，判断对哪个进行分区，或者使用m命令,按F看有没有空间剩余） Welcome to fdisk (util-linux 2.27.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): Help: DOS (MBR) a toggle a bootable flag b edit nested BSD disklabel c toggle the dos compatibility flag Generic d delete a partition F list free unpartitioned space l list known partition types n add a new partition p print the partition table t change a partition type v verify the partition table i print information about a partition Misc m print this menu u change display/entry units x extra functionality (experts only) Script I load disk layout from sfdisk script file O dump disk layout to sfdisk script file Save &amp; Exit w write table to disk and exit q quit without saving changes Create a new label g create a new empty GPT partition table G create a new empty SGI (IRIX) partition table o create a new empty DOS partition table s create a new empty Sun partition table Command (m for help): F 3.n 新建分区，p为主分区，一路回车。 4.t选择分区分类，输入8e代表逻辑分区，w保存。 下面有一个类型对照表： Command (m for help): l 0 Empty 24 NEC DOS 81 Minix / old Lin bf Solaris 1 FAT12 27 Hidden NTFS Win 82 Linux swap / So c1 DRDOS/sec (FAT- 2 XENIX root 39 Plan 9 83 Linux c4 DRDOS/sec (FAT- 3 XENIX usr 3c PartitionMagic 84 OS/2 hidden or c6 DRDOS/sec (FAT- 4 FAT16 &lt;32M 40 Venix 80286 85 Linux extended c7 Syrinx 5 Extended 41 PPC PReP Boot 86 NTFS volume set da Non-FS data 6 FAT16 42 SFS 87 NTFS volume set db CP/M / CTOS / . 7 HPFS/NTFS/exFAT 4d QNX4.x 88 Linux plaintext de Dell Utility 8 AIX 4e QNX4.x 2nd part 8e Linux LVM df BootIt 9 AIX bootable 4f QNX4.x 3rd part 93 Amoeba e1 DOS access a OS/2 Boot Manag 50 OnTrack DM 94 Amoeba BBT e3 DOS R/O b W95 FAT32 51 OnTrack DM6 Aux 9f BSD/OS e4 SpeedStor c W95 FAT32 (LBA) 52 CP/M a0 IBM Thinkpad hi ea Rufus alignment e W95 FAT16 (LBA) 53 OnTrack DM6 Aux a5 FreeBSD eb BeOS fs f W95 Ext&#39;d (LBA) 54 OnTrackDM6 a6 OpenBSD ee GPT 10 OPUS 55 EZ-Drive a7 NeXTSTEP ef EFI (FAT-12/16/ 11 Hidden FAT12 56 Golden Bow a8 Darwin UFS f0 Linux/PA-RISC b 12 Compaq diagnost 5c Priam Edisk a9 NetBSD f1 SpeedStor 14 Hidden FAT16 &lt;3 61 SpeedStor ab Darwin boot f4 SpeedStor 16 Hidden FAT16 63 GNU HURD or Sys af HFS / HFS+ f2 DOS secondary 17 Hidden HPFS/NTF 64 Novell Netware b7 BSDI fs fb VMware VMFS 18 AST SmartSleep 65 Novell Netware b8 BSDI swap fc VMware VMKCORE 1b Hidden W95 FAT3 70 DiskSecure Mult bb Boot Wizard hid fd Linux raid auto 1c Hidden W95 FAT3 75 PC/IX bc Acronis FAT32 L fe LANstep 1e Hidden W95 FAT1 80 Old Minix be Solaris boot ff BBT 硬盘分区设置完成以后，一般需要将系统重启以使设置生效，如果不想重启系统，可以使用“partprobe”命令使操作系统获知新的分区表情况。 例：执行partprobe命令重新探测“/dev/sdb”磁盘中分区情况的变化。 5.格式化分区：mkfs -V -t ext4 -c /dev/sdb1 命令： mkfs 格式： mkfs –t 文件系统类型 分区设备 参数： -t : 给定档案系统的型式，Linux 的预设值为 ext2 -c : 在制做档案系统前，检查该partition 是否有坏轨 -V : 详细显示模式 例：将/dev/sdb1格式化为ext4文件系统，同时检查是否有坏轨存在，并且将过程详细列出来 : mkfs -V -t ext4 -c /dev/sdb1 将/dev/sdb5格式化为fat32文件系统。 [root@localhost ~]# mkfs -t vfat /dev/sdb5 在这之前可以使用 df -Th 来看一下所需要扩展的分区的类型，是ext4，所以选择ext4 `pvcreate /dev/sdb1` 建为物理卷 6.pvs察看可用的LVS卷组， 组名，lvdisplay + 组名可以看出卷的详细信息 root@ubuntu:/home/liwei# pvs PV VG Fmt Attr PSize PFree /dev/sda3 lvm2 --- 30.00g 30.00g /dev/sda5 ubuntu-vg lvm2 a-- 29.52g 0 /dev/sdb1 ubuntu-vg lvm2 a-- 20.00g 0 vgextend ubuntu-vg /dev/sdb1 来扩展组 7.使用cat /etc/fstab 来查看需要扩容的分卷名称。 root@ubuntu:/home/liwei# cat /etc/fstab # /etc/fstab: static file system information. # # Use &#39;blkid&#39; to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt; /dev/mapper/ubuntu--vg-root / ext4 errors=remount-ro 0 1 # /boot was on /dev/sda1 during installation UUID=1df9dfd2-3dd9-4621-b6c7-580785db146b /boot ext2 defaults 0 2 /dev/mapper/ubuntu--vg-swap_1 none swap sw 0 0 /dev/fd0 /media/floppy0 auto rw,user,noauto,exec,utf8 0 0 我们需要扩容的是dev/mapper/ubuntu--vg-root 8.使用lvextend -L +20G /dev/mapper/ubuntu--vg-root /dev/sdb1来进行扩容 这条命令的意思是，给/dev/mapper/ubuntu--vg-root添加20G的容量，使用/dev/sdb1的空间来扩容。 9.使用/sbin/resize2fs /dev/mapper/ubuntu--vg-root 把新分配的空间进行生效","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://www.toimc.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"linux","slug":"linux","permalink":"https://www.toimc.com/tags/linux/"}]},{"title":"使用docker快速搭建gitlab服务器","slug":"使用docker快速搭建gitlab服务器","date":"2016-11-26T16:00:00.000Z","updated":"2019-03-12T16:07:58.000Z","comments":true,"path":"使用docker快速搭建gitlab服务器/","link":"","permalink":"https://www.toimc.com/%E4%BD%BF%E7%94%A8docker%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAgitlab%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"对于想自己搭建一套属于自己（公司）的git服务的小伙伴有服了，我们使用gitlab的社区版，可以快速搭建一套gitlab服务。但是，gitlab的官方配置又比较麻烦，怎么办呢？使用docker吧！","text":"对于想自己搭建一套属于自己（公司）的git服务的小伙伴有服了，我们使用gitlab的社区版，可以快速搭建一套gitlab服务。但是，gitlab的官方配置又比较麻烦，怎么办呢？使用docker吧！ 环境: Ubuntu 16.04LTSDocker 1.11.2gitlab 8.13.6 认识dockerDocker官网：www.docker.com Docker简介： PACKAGE YOUR APPLICATION INTO A STANDARDIZED UNIT FOR SOFTWARE DEVELOPMENT——Docker containers wrap a piece of software in a complete filesystem that contains everything needed to run: code, runtime, system tools, system libraries – anything that can be installed on a server. This guarantees that the software will always run the same, regardless of its environment. 方便开发，把你的应用打包到容器中。——把碎片化的软件放到一个完整的文件系统中，这个系统包括所有的代码、运行环境、系统工具、系统依赖包，即所有安装在一台服务器上的环境。这样，保证了该软件一直能够在同样的环境下进行运行。 简单来说，容器技术提供了跨平台、轻量、稳定的运行软件的统一环境。 安装Docker这里有详细的介绍： 【1】Ubuntu、Debian 系列安装 Docker（中文） 【2】Install Docker on Linux distributions（官方英文） 1.查看内核：Docker 需要安装在 64 位的 x86 平台或 ARM 平台上（如树莓派），并且要求内核版本不低于 3.10。 uname -a 2.更新包并且添加GPG密钥 sudo apt-get update sudo apt-get install apt-transport-https ca-certificates $ sudo apt-key adv \\ --keyserver hkp://ha.pool.sks-keyservers.net:80 \\ --recv-keys 58118E89F3A912897C070ADBF76221572C52609D 3.对于不同版本的ubuntu在/etc/apt/sources.list.d/目录下，新建docker.list文件 vi /etc/apt/sources.list.d/docker.list 添加内容如下：（提示：针对你自己的系统版本进行选择一行） Ubuntu version Repository Precise 12.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-precise main Trusty 14.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-trusty main Wily 15.10 deb https://apt.dockerproject.org/repo ubuntu-wily main Xenial 16.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-xenial main 如：Ubutun 16.04LTS /etc/apt/sources.list.d/docker.list添加如下内容，:wq保存退出。 deb https://apt.dockerproject.org/repo ubuntu-xenial main 4.更新依赖包并安装Docker-engine sudo apt-get update sudo apt-get install linux-image-extra-$(uname -r) linux-image-extra-virtual sudo apt-get install docker-engine 5.启动服务并运行例子docker镜像Hello world. sudo service docker start sudo docker run hello-world 这样就大功告成了。 docker加速器对于中国的用户，国外的镜像不是被墙就是下载很慢，提供大家两个好去处：阿里镜像加速、DaoCloud加速 个人试用之后，推荐使用DaoCloud的；PS：如果你的服务器是阿里的，那就使用阿里的吧，毕竟自家的加速还是快点儿，方法在这：docker使用阿里云Docker镜像库加速。 DaoCloud注册之后，登陆，选择顶部的加速器：https://www.daocloud.io/mirror，可以看到三个系统下的加速方法。在Linux下的加速方法： curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://xxxxxxxx.m.daocloud.io 使用DaoCloud的官方脚本进行加速就Ok了，或者手动添加： vi /etc/default/docker DOCKER_OPTS=&quot;--registry-mirror=http://xxxxxxxx.m.daocloud.io&quot; 保存后，使用service docker restart重启Docker，就可以在国内愉快的Download Docker镜像了。 配置gitlab国内外有很多很优秀的Docker镜像源。 Docker官方： https://store.docker.com/（新） https://hub.docker.com/(旧) DaoCloud: https://hub.daocloud.io/ 阿里Docker镜像: https://dev.aliyun.com/search.html ===分割线=== 进入正文： 1.下载gitlab的docker镜像并启动： sameersbn/docker-gitlab 命令： docker pull sameersbn/gitlab:8.14.0 docker pull sameersbn/postgresql:9.5-3 docker pull sameersbn/redis:latest 启动postgresql数据库： docker run --name gitlab-postgresql -d \\ --env &#39;DB_NAME=gitlabhq_production&#39; \\ --env &#39;DB_USER=gitlab&#39; --env &#39;DB_PASS=password&#39; \\ --env &#39;DB_EXTENSION=pg_trgm&#39; \\ --volume /srv/docker/gitlab/postgresql:/var/lib/postgresql \\ sameersbn/postgresql:9.5-3 启动Redis： docker run --name gitlab-redis -d \\ --volume /srv/docker/gitlab/redis:/var/lib/redis \\ sameersbn/redis:latest 启动gitlab服务： docker run --name gitlab -d \\ --link gitlab-postgresql:postgresql --link gitlab-redis:redisio \\ --publish 10022:22 --publish 10080:80 \\ --env &#39;GITLAB_PORT=10080&#39; --env &#39;GITLAB_SSH_PORT=10022&#39; \\ --env &#39;GITLAB_SECRETS_DB_KEY_BASE=long-and-random-alpha-numeric-string&#39; \\ --env &#39;GITLAB_SECRETS_SECRET_KEY_BASE=long-and-random-alpha-numeric-string&#39; \\ --env &#39;GITLAB_SECRETS_OTP_KEY_BASE=long-and-random-alpha-numeric-string&#39; \\ --volume /srv/docker/gitlab/gitlab:/home/git/data \\ sameersbn/gitlab:8.14.0 上面的命令一大堆，如果是程序员，应该很好懂这些参数的意义：env环境变量，volume相当于把容器内的文件挂载到宿主里面来，就像U盘插到了系统中，link连接容器，让他们通信，publish发布，做一个端口映射。 2.Docker-compose快速启动容器（推荐） 使用方法，下载Docker-compose管理脚本： curl -L &quot;https://github.com/docker/compose/releases/download/1.8.1/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 权限赋予： chmod +x /usr/local/bin/docker-compose 查看： docker-compose --version docker-compose version: 1.8.1 PS：或者使用pip安装： pip install docker-compose 安装gitlab的docker-compose配置文件： wget https://raw.githubusercontent.com/sameersbn/docker-gitlab/master/docker-compose.yml 需要配置的地方： （1）配置gitlab的密钥： https://github.com/sameersbn/docker-gitlab/blob/master/docker-compose.yml#L57-L59 - GITLAB_SECRETS_DB_KEY_BASE=long-and-random-alphanumeric-string - GITLAB_SECRETS_SECRET_KEY_BASE=long-and-random-alphanumeric-string - GITLAB_SECRETS_OTP_KEY_BASE=long-and-random-alphanumeric-string 在long-and-random-alphanumeric-string配置一长串密钥。 （2）配置Gitlab_host: https://github.com/sameersbn/docker-gitlab/blob/master/docker-compose.yml#L53 其他的，如端口的映射、数据库密码，大家按需配置。 （3）关于邮件配置： - SMTP_ENABLED=true - SMTP_DOMAIN=email-smtp.region-1.amazonaws.com - SMTP_HOST=email-smtp.region-1.amazonaws.com - SMTP_PORT=587 - SMTP_USER=IAMmailerKey - SMTP_PASS=IAMmailerSecret - SMTP_STARTTLS=true - SMTP_AUTHENTICATION=login 建议使用AWS，因为mailgun国内已经被墙了。而163，QQ这些公共邮箱，每天都有发件限制。https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/doc/settings/smtp.md （4）关于时区设置：（选择北京时区） - TZ=Asia/Beijing - GITLAB_TIMEZONE=Beijing （5）关于备份： - GITLAB_BACKUP_SCHEDULE=daily - GITLAB_BACKUP_TIME=02:00 - GITLAB_BACKUP_DIR=/home/git/data/backups PS：每天2点备份，备份地址：/home/git/data/backups 启动： docker-compose up -d 容器相关命令1.使用docker ps查看正在运行的容器 docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES df2be7411e4e sameersbn/gitlab:8.14.0 &quot;/sbin/entrypoint.sh &quot; 12 minutes ago Up 12 minutes 443/tcp, 0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10080-&gt;80/tcp mygitlab fe43f6fd82d6 sameersbn/redis:latest &quot;/sbin/entrypoint.sh &quot; 5 weeks ago Up 15 hours 6379/tcp myredis 1fee910ccc15 sameersbn/postgresql:9.5-3 &quot;/sbin/entrypoint.sh&quot; 5 weeks ago Up 15 hours 5432/tcp mypostgresql 2.使用docker logs &lt;containerId&gt;查看docker日志输出情况 root@ubuntu:/home/liwei# docker logs mygitlab Initializing logdir... Initializing datadir... Updating CA certificates... Installing configuration templates... Configuring gitlab... Configuring gitlab::database Configuring gitlab::redis Configuring gitlab::secrets... Configuring gitlab::sidekiq... Configuring gitlab::gitlab-workhorse... Configuring gitlab::unicorn... Configuring gitlab::timezone... Configuring gitlab::rack_attack... Configuring gitlab::ci... Configuring gitlab::artifacts... Configuring gitlab::lfs... Configuring gitlab::project_features... Configuring gitlab::smtp_settings... Configuring gitlab::incoming_email... Configuring gitlab::oauth... Configuring gitlab::oauth::github... Configuring gitlab::ldap... Configuring gitlab::backups... Configuring gitlab::backups::schedule... Configuring gitlab::registry... Configuring gitlab-shell... Configuring nginx... Configuring nginx::gitlab... ... 3.使用docker images查看已经下载的docker容器 root@ubuntu:/home/liwei# docker images REPOSITORY TAG IMAGE ID CREATED SIZE sameersbn/gitlab 8.14.0 3b000ac37c08 21 hours ago 777.1 MB sameersbn/gitlab 8.13.5 085ba74f4375 2 weeks ago 770.3 MB sameersbn/gitlab 8.13.1 986efbb1be0f 4 weeks ago 769.7 MB jenkins latest 9bc67dd3e379 5 weeks ago 712 MB sameersbn/postgresql 9.5-3 5d428ccd0ca8 5 weeks ago 232.5 MB sameersbn/redis latest d98e69c03abe 5 weeks ago 196.5 MB dordoka/tomcat latest 79eaa61ac94f 8 weeks ago 779.6 MB hello-world latest c54a2cc56cbb 4 months ago 1.848 kB busybox latest 2b8fd9751c4c 5 months ago 1.093 MB phpmyadmin/phpmyadmin latest 8d7d99c9cd5a 5 months ago 57.02 MB 4.使用docker rmi &lt;containerID&gt;删除镜像 root@ubuntu:/home/liwei# docker rmi 085ba74f4375 Untagged: sameersbn/gitlab:8.13.5 Deleted: sha256:085ba74f4375683370a4186c3e78784dd146b04a38f601c5d33c05e9495980a7 Deleted: sha256:8332e8dea2fb01961cb2f4302ea99070d9b41620521e5db5f1cdbbeae6af38d6 Deleted: sha256:3e343fbfe86b82a34a9f4367577d42fcfb2e64f35d247a63ad6ff088d617a5d5 Deleted: sha256:ad22df0171a53e6b5e5174470b8a351c65cf98eb81f775686419de4f5bf3181c Deleted: sha256:251592c53bb0b387f8f28c9aca2a95f9578d295327a30a1ccde637ab956f7412 Deleted: sha256:0aacd95dcfe0f3e7ea152cc235d52c67eca5a68153a182147b0f0abf953ca69d gitlab升级、备份恢复1.升级。 按照https://github.com/sameersbn/docker-gitlab/blob/master/docker-compose.yml修改gitlab的版本、redis版本、postgresql的版本即可。 docker-compose up -d 2.备份恢复： docker-compose run gitlab app:rake gitlab:backup:restore root@ubuntu:/home/liwei# docker-compose run gitlab app:rake gitlab:backup:restore Initializing logdir... Initializing datadir... Updating CA certificates... Installing configuration templates... Configuring gitlab... Configuring gitlab::database Configuring gitlab::redis Configuring gitlab::secrets... Configuring gitlab::sidekiq... Configuring gitlab::gitlab-workhorse... Configuring gitlab::unicorn... Configuring gitlab::timezone... Configuring gitlab::rack_attack... Configuring gitlab::ci... Configuring gitlab::artifacts... Configuring gitlab::lfs... Configuring gitlab::project_features... Configuring gitlab::smtp_settings... Configuring gitlab::incoming_email... Configuring gitlab::oauth... Configuring gitlab::oauth::github... Configuring gitlab::ldap... Configuring gitlab::backups... Configuring gitlab::backups::schedule... Configuring gitlab::registry... Configuring gitlab-shell... Configuring nginx... Configuring nginx::gitlab... ‣ 1480212149_gitlab_backup.tar (created at 27 Nov, 2016 - 02:02:29 Asia) ‣ 1480125698_gitlab_backup.tar (created at 26 Nov, 2016 - 02:01:38 Asia) ‣ 1480039281_gitlab_backup.tar (created at 25 Nov, 2016 - 02:01:21 Asia) ‣ 1479866501_gitlab_backup.tar (created at 23 Nov, 2016 - 02:01:41 Asia) ‣ 1479780085_gitlab_backup.tar (created at 22 Nov, 2016 - 02:01:25 Asia) ‣ 1479693688_gitlab_backup.tar (created at 21 Nov, 2016 - 02:01:28 Asia) Select a backup to restore: 选择指定的备份号进行恢复：1480212149_gitlab_backup.tar回车。 3.容器重启： docker-compose restart","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.toimc.com/tags/Docker/"},{"name":"Gitlab","slug":"Gitlab","permalink":"https://www.toimc.com/tags/Gitlab/"}]},{"title":"Debian/Ubuntu搭建LNMP（Linux,nginx,MySQL,PHP）环境，搭建wordpress","slug":"Debian Ubuntu搭建LNMP（Linux,nginx,MySQL,PHP）环境，搭建wordpress","date":"2016-04-21T02:28:55.000Z","updated":"2019-08-03T17:04:10.000Z","comments":true,"path":"Debian Ubuntu搭建LNMP（Linux,nginx,MySQL,PHP）环境，搭建wordpress/","link":"","permalink":"https://www.toimc.com/Debian%20Ubuntu%E6%90%AD%E5%BB%BALNMP%EF%BC%88Linux,nginx,MySQL,PHP%EF%BC%89%E7%8E%AF%E5%A2%83%EF%BC%8C%E6%90%AD%E5%BB%BAwordpress/","excerpt":"本文介绍了Debian/Ubuntu搭建LNMP（Linux,nginx,MySQL,PHP）环境的基本方法，并安装wordpress，附上视频教程。","text":"本文介绍了Debian/Ubuntu搭建LNMP（Linux,nginx,MySQL,PHP）环境的基本方法，并安装wordpress，附上视频教程。 环境准备1.有root账号的Ubuntu或者Debian环境。 2.拥有独立IP的服务器一台。 3.有一定的Linux操作知识。 安装Nginx服务器sudo apt-get update sudo apt-get install -y nginx 如果没有sudo命令，请apt-get install sudo 获取自己服务器的IP： ip addr show eth0 | grep inet | awk &#39;&#123; print $2; &#125;&#39; | sed &#39;s/\\/.*$//&#39; 当安装成功后，直接在浏览器中输入服务器IP或已经解析好的域名： http://server_domain_name_or_IP/ 如果出现： Welcome to Nginx! 的默认欢迎页面说明Nginx服务器已经安装好了。 安装MySQL数据库根之前的文章一样： sudo apt-get install mysql-server 然后 sudo mysql_install_db sudo mysql_secure_installation 记得设置mysql的root用户的管理密码。 安装PHP环境sudo apt-get install php5-fpm php5-mysql 使用默认vim编辑器：Debian下更换默认编辑器为vim sudo vi /etc/php5/fpm/php.ini 修改下面的内容： cgi.fix_pathinfo=0 因为： What we are looking for in this file is the parameter that sets cgi.fix_pathinfo. This will be commented out with a semi-colon (;) and set to “1” by default. This is an extremely insecure setting because it tells PHP to attempt to execute the closest file it can find if a PHP file does not match exactly. This basically would allow users to craft PHP requests in a way that would allow them to execute scripts that they shouldn’t be allowed to execute. 这是一个非常不安全的设置，告诉PHP试图去执行相近的文件而不是绝对精确的文件。如果是默认设置的话，会允许用户篡改PHP的请求，并且会去执行一些可能不被允许执行的脚本。 修改完后： sudo service php5-fpm restart 重启PHP。 配置Nginx使用PHP进程sudo vi /etc/nginx/sites-available/default 你可以打开后看到了如下的配置： server &#123; listen 80 default_server; listen [::]:80 default_server ipv6only=on; root /usr/share/nginx/html; index index.html index.htm; server_name localhost; location / &#123; try_files $uri $uri/ =404; &#125; &#125; 上面的文件很好理解： 监听80端口 默认服务器 nginx的根目录为 /usr/share/nginx/html index 会自动执行index.html 服务器的地址 指向了 localhost 也就是本机 配置成如下配置： server &#123; listen 80 default_server; listen [::]:80 default_server ipv6only=on; root /var/www; index index.php index.html index.htm; server_name server_domain_name_or_IP; location / &#123; try_files $uri $uri/ =404; &#125; #error_page 404 /404.html; #error_page 500 502 503 504 /50x.html; #location = /50x.html &#123; # root /usr/share/nginx/html; #&#125; location ~ \\.php$ &#123; try_files $uri =404; fastcgi_split_path_info ^(.+\\.php)(/.+)$; fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; &#125; 然后重启： sudo service nginx restart 如果重启失败可以使用： nginx -t 来看看系统提示了什么，再来修改。 最后测试一下cd /var mkdir www cd /var/www 相当于新建了一个/var/www目录 vi info.php 按i后输入： &lt;? phpinfo(); ?&gt; 然后，再来访问： http://server_domain_name_or_IP/ 就可以看到php相关信息了，就是这么简单。 搭建wordpress参考：WordPress安装视频教程 wordpress伪静态文件.htaccess文件配置 VPS推荐与选择&amp;putty基本使用方法 监控mysql运行状态，停止则重启 配置iptables 用SSH来管理Linux服务器，禁用口令登陆，提高Linux服务器安全 Debian7安装wordpress权限问题 MySql中添加用户,新建数据库,用户授权,删除用户,修改密码 整个视频教程","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.toimc.com/tags/Ubuntu/"},{"name":"集成环境搭建","slug":"集成环境搭建","permalink":"https://www.toimc.com/tags/%E9%9B%86%E6%88%90%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"LNMP","slug":"LNMP","permalink":"https://www.toimc.com/tags/LNMP/"}]},{"title":"Webstorm中使用Autoprefixer","slug":"Webstorm中使用Autoprefixer","date":"2016-04-15T16:26:48.000Z","updated":"2019-03-12T16:03:17.000Z","comments":true,"path":"Webstorm中使用Autoprefixer/","link":"","permalink":"https://www.toimc.com/Webstorm%E4%B8%AD%E4%BD%BF%E7%94%A8Autoprefixer/","excerpt":"最近玩了一下SASS，感觉不错，不过CSS3在不同平台兼容性代码一直是个头痛的问题，手写处理费时费力又容易出错。曾经一直用sublime text写html和css，这些问题都有相应的插件。用Webstorm写js，但是来回切换编辑器也比较麻烦。虽然Webstorm内置了css3自动补全功能，当输入user-select时,Webstorm会自动补全： -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; 但是很多情况下，这种自动补全并不令人满意，比如当我输入display:flex;时，Webstorm并不会自动补全为： display:-webkit-box; display:-webkit-flex; display:-ms-flexbox; display:flex;","text":"最近玩了一下SASS，感觉不错，不过CSS3在不同平台兼容性代码一直是个头痛的问题，手写处理费时费力又容易出错。曾经一直用sublime text写html和css，这些问题都有相应的插件。用Webstorm写js，但是来回切换编辑器也比较麻烦。虽然Webstorm内置了css3自动补全功能，当输入user-select时,Webstorm会自动补全： -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; 但是很多情况下，这种自动补全并不令人满意，比如当我输入display:flex;时，Webstorm并不会自动补全为： display:-webkit-box; display:-webkit-flex; display:-ms-flexbox; display:flex; 关于AutoprefixerAutoprefixer是一个后处理程序，不象Sass以及Stylus之类的预处理器。它适用于普通的CSS，可以实现css3代码自动补全。也可以轻松跟Sass，LESS及Stylus集成，在CSS编译前或编译后运行。详情见，https://github.com/postcss/autoprefixer 当Autoprefixer添加前缀到你的CSS，还不会忘记修复语法差异。这种方式，CSS是基于最新W3C规范产生： a &#123; background : linear-gradient(to top, black, white); display : flex &#125; ::placeholder &#123; color : #ccc &#125; 编译成： a &#123; background : -webkit-linear-gradient(bottom, black, white); background : linear-gradient(to top, black, white); display : -webkit-box; display : -webkit-flex; display : -ms-flexbox; display : flex &#125; ::-webkit-input-placeholder &#123; color : #ccc &#125; ::-moz-placeholder &#123; color : #ccc &#125; :-ms-input-placeholder &#123; color : #ccc &#125; ::placeholder &#123; color : #ccc &#125; Autoprefixer 同样会清理过期的前缀，因此下面的代码： a &#123; -webkit-border-radius : 5px; border-radius : 5px &#125; 编译成： a &#123; border-radius : 5px &#125; 因为经过Autoprefixer处理，CSS将仅包含实际的浏览器前缀。 具体安装和配置：所以尝试在Webstorm下搜索autoprefixer插件，无果。那就自己手动配置了一个。首先我考虑配置File Watchers，但是不习惯，原来在sublime text下用autoprefixer都是手动触发的，所以后面我配置了External Tools。 首先当然是安装node.js;直接在官网上https://nodejs.org/en/download/可以下载安装（windows）。 安装Autoprefixer：见https://github.com/postcss/autoprefixer： sudo npm install autoprefixer -g 要不要加sudo，或者是不是全局安装（-g）那就看你自己的环境了。 npm太慢，我是用淘宝的 NPM 镜像的https://npm.taobao.org/ 安装postcss-cliAutoprefixer其实是postcss的插件，见https://github.com/code42day/postcss-cli sudo npm install postcss-cli -g 配置External Tools打开Webstorm设置，Preferences -&gt; Tools -&gt; External Tools ;点击新增按钮，如图： 填写具体配置，例如我的配置，如图： Program:填入你的postcss-cli 的PATH； Parameters: -u autoprefixer -o $FileDir$/$FileName$ $FileDir$/$FileName$ ，你可以根据你自己的需要配置，具体参见https://github.com/code42day/postcss-cli Working directory :$ProjectFileDir$ 配置好后，你可以在css，或sass文件中右键，就可以在右键菜单中看到External Tools – autoprefixer，点击搞定，嘎嘎。 设置快捷键右键太麻烦的话，可以设置个快捷键，打开Webstorm设置，Preferences -&gt; Keymap ， 搜索External Tools ， 配置 autoprefixer即可。 不要和原来的冲突就可以了。","categories":[],"tags":[{"name":"webstorm","slug":"webstorm","permalink":"https://www.toimc.com/tags/webstorm/"},{"name":"css","slug":"css","permalink":"https://www.toimc.com/tags/css/"},{"name":"autoprefixer","slug":"autoprefixer","permalink":"https://www.toimc.com/tags/autoprefixer/"}]},{"title":"Dont't Make Me Think《点石成金》阅后感","slug":"Don't Make Me Think","date":"2016-04-09T16:26:48.000Z","updated":"2019-03-12T16:08:15.000Z","comments":true,"path":"Don't Make Me Think/","link":"","permalink":"https://www.toimc.com/Don't%20Make%20Me%20Think/","excerpt":"Don’t Make Me Think —— Steve Krug 点石成金——访客至上的Web和移动可用性设计秘笈 这本书很薄，内容很精练，入门级选择，让你设计出让访客舒服、易用的页面。","text":"Don’t Make Me Think —— Steve Krug 点石成金——访客至上的Web和移动可用性设计秘笈 这本书很薄，内容很精练，入门级选择，让你设计出让访客舒服、易用的页面。 可用性原则（指导原则）： 别让我思考： 网页的内容分类清晰，去掉多余的内容，格式，内容统一，采用常见的网页布局。 强迫去思考： 设置一些显而易见的内容，如button，如jobs而非job-o-rama之类的。 下拉框，或者input框中的内容，有一定的引导。 如果做不到让一个页面不言而喻，那么至少应该让它自我解释。 访客实事上如何使用Web的 我们不是阅读，而是扫描。 我想大家都会有这样的经历，打开一个Web页面的第一眼很关键，一般来说看看左上角，或者屏幕正中心。而不会去细致的浏览内容，而是跳跃着阅读。 我们不选择最好的，而是过得去的。 在淘宝上看东西，一般会怎么选？看看购买数量，看看商家评级等等，一般来说，还行的就下手了。我们不会去追求最便宜，因为便宜不一定会买到好质量的产品（我想大家应该有这样的经历），过得去就行。 不是追根究底，而是勉强应付。 原因： a. 对于用户来说不重要。 b. 如果发现某个东西能用，会一直使用它。如果有更好的，就会换成更好的方式。而不会主动的去找更好的使用方法。 广告牌设计101法则让用户了解你的网站： 尽量利用习惯用法。 建立有效的视觉层次 把页面划分成明确定义的区域。 明显标识可以点击的地方 最小化干扰 为内容创建清楚的格式，以便扫描 为什么用户喜欢无须思考的选择 点击多少次都没有关系，只要每次点击都是无须思考、明确无误的选择——Krug 可用性第二定律。 这句话很好理解，我们不喜欢在点了很多级页面之后，没有找到我们想要的东西。 例如在淘宝，如果你想买一个微波炉，你这样点选：家用电器→厨房电器→结果你没有看到你想要的。 所以，解决方法可以有： 提供搜索。 提供参考菜单 必要的帮助和支持。 省略多余的文字去掉每个页面上一半的文字，然后把剩下的文字再去掉一半。——Krug 可用性第三定律。 欢迎词必须消灭 指示文字必须消灭 ================== 必须正确处理的几个方面 设计导航（指示牌和面包屑）如果在网站上找不到方向，人们不会使用你的网站。 网络导航法则： 你通常是为了寻找某个目标。 你会决定先询问不审先浏览。 如果选择浏览，你将通过标志的引导在层次结构中穿行。 最后，如果找不到想要的东西，你会离开。 Web空间与实际购物的不同 ： 感觉不到大小 感觉不到方向 感觉不到位置 被忽视了的导航用途： 它告诉我们这是里有些什么 它告诉我们如何使用网站 它给了我们对网站建造都的信心。 Web导航的习惯用法 ： 位置明确。 单页面都会一样，都会相同的导航功能，除了部分的表单页面。 注意所有页面的左上方的区域，最好给出你的logo+slogan，让用户在无数次的点击跳转之后，知道现在自己在哪个网站。是跳转出去了，到其他的网站了，还是说还在本站内浏览。 层次清晰：一级菜单、二级菜单、功能菜单（登陆、搜索） 一定要设置返回到顶部或者是返回首页的按钮，而且轻松可以找到。 用户在一级菜单与二级菜单上花费的时间相同，所以请简明、显要的告诉用户。 每个页面清晰的告诉用户，他在哪里，最好是使用面包屑，标签页 web设计中的大爆炸理论——设计好你的主页 一个主页应该有下面的需要完成的任务： 站点的标识和使命 站点层次 搜索功能。 导读 内容推介 功能推介 交换链接 快捷方式 注册 还有一些抽象的目标： 让访客看到自己正在寻找的东西。 ..还有他没有寻找的。 告诉访客从哪里开始。 建立可信度和信任感。 当访客来到主页后，要可以回答他这5个问题： 这是什么网站？ 我能在这里做什么？ 网站上有些什么？ 为什么应该在这里，而不是别的地方？ 从哪里开始 如何做到上面的要求呢？ slogan一定要独立，要有自己的特点。 给予“了解更多”的选项。 并提供欢迎广告。 需要多大的空间就使用多大的空间，让内容简短。 实际的测试。 农场主和牧牛人应该是朋友大家在一个团队里面，思考的方式与角度可能不尽相同，辩论再所难免，关键是要定位受众及用户群，他们的行为来决定页面的功能与布局….一定不要自己拍板或者大家“都喜欢”。用户，只有用户才有发言权。 测试你的页面。 关于测试，你需要知道的： 如果想建立一个优秀的网站，一定要测试。 测试一个用户比不做测试好一倍。 在项目中，早点测试一位用户比最后测试50位用户要好得多。 应该多久进行一次测试？ 每个月一个上午进行一次可用性测试，原因如下： 这样能保持测试的简单性，所以能坚持的进行。 这样能满足实际的需要。 这样就不需要决定什么时候测试。 这样更容易让人们参与进来。 应该测试多少用户？ 理论上来讲是三个，原因： 测试的目的不是为了证明什么。 不用发现所有的问题。 如何选择测试者？ 去寻找能反映你目标群体的测试用户，但是别因此而裹足不前。 原因： 设计出的网站只有你的目标群体能使用，这通常并不是一个好主意。 在内心深处，我们都是初学者。 专家通常不会介意对初学者来说很清楚的界面。 另外还有一些： 测试者提供一定的报酬，这样他们会更用心。 让大家在一个没有干扰的环境中测试。 应该让更多人参与观察。 尽早的进行测试。","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://www.toimc.com/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"《程序员修炼之道》书评","slug":"《程序员的修炼之道》豆瓣书评","date":"2016-03-26T16:26:48.000Z","updated":"2019-03-12T16:08:27.000Z","comments":true,"path":"《程序员的修炼之道》豆瓣书评/","link":"","permalink":"https://www.toimc.com/%E3%80%8A%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93%E3%80%8B%E8%B1%86%E7%93%A3%E4%B9%A6%E8%AF%84/","excerpt":"《程序员修炼之道》由一系列的独立的部分组成，涵盖的主题从个人责任、职业发展，直到用于使代码保持灵活、并且易于改编和复用的各种架构技术。利用许多富有娱乐性的奇闻轶事、有思想性的例子以及有趣的类比，全面阐释了软件开发的许多不同方面的最佳实践和重大陷阱。无论你是初学者，是有经验的程序员，还是软件项目经理，本书都适合你阅读。","text":"《程序员修炼之道》由一系列的独立的部分组成，涵盖的主题从个人责任、职业发展，直到用于使代码保持灵活、并且易于改编和复用的各种架构技术。利用许多富有娱乐性的奇闻轶事、有思想性的例子以及有趣的类比，全面阐释了软件开发的许多不同方面的最佳实践和重大陷阱。无论你是初学者，是有经验的程序员，还是软件项目经理，本书都适合你阅读。 下面是我在读书的过程中的一些摘抄： 我的源码让猫给吃了 不要寻找借口,从自身找原因 软件的熵 一句话:不以善小而不为,勿以恶小而为之. 从初期就要做好规范,不要因为是poc这样的前提而放松对代码的规范,现在的项目就 有这种问题,初期的时候有人认为(自己也有这种想法)等到以后正式开发的时候再规范 ,而往往还未到正式开发,到处出现不规范的东西.加上拷贝粘贴的大法,亡羊补牢都晚 了.这就是所谓破窗户理论. 石头汤与煮青蛙 两个方面,一还是’软件的熵’当中的含义,喜欢书里面的这段话:’大多数的项目的拖 延都是一天一天发生的,系统一个特性一个特性的偏离其规范.一个又一个的补丁被打 到某段代码上,直到最初的代码一点没有留下’. 二是团队的协同合作,这样石头汤也很 鲜美. 足够好的软件 就是俗话说的一鸟在手胜于二鸟在林. 首先得确保软件可用性,至于亮点,特色,在可用以后才需要考虑.而且还得明确用户需 求(虽然这点始终被强调).大家都知道系统不可能做的完美,但是自己着手开发的时候 总是朝着尽可能完美的方向发展,欺骗自己说,这个功能多么伟大,一定要加上去,那个 功能多么惊天动地,最后反而成为四不像,使项目延期. 在第一次企图做那个todo list的时候,想着把calendar和task两项功能完整的结合, 同时还想着把contact功能也加入,甚至还有ms porject的管理功能,但是一切都太多, 以致于设计了少数几个界面以后就陷入了无止境的功能权衡中,因为太多东西又想完美 .所以第一次最终结果是除了最后那个简陋的复杂的界面,什么东西都没有,当然如今代 码也已经不知道是不是被自己删除,能够留在自己硬盘上并且使用的还是那个简简单单 的GeeTask,功能不多,但是的确对我来说,足够好了,如果还有新的功能,添加就是了,不 用一次就做一个大而全的玩意出来. 也想起在上一个公司参与的第一个项目,房地产的预警系统,先前同事通过研究,不知 道从哪里搞到一些其他人做的预警系统,动用高深的所谓经济学景气循环算法来计算, 艰难的实现这些公式.当然我们自己也不知道这个是不是准.后来我负责去给客户实施, 在客户处,得知了惊人的消息:客户需要的足够好的软件其实就是一个新闻发布功能的 东西,因为他们也不懂,是领导的要求—领导当然也是被上层领导要求.这个例子虽然 特殊,但是也说明了一定要及早知道客户心中的足够好的软件是什么. 你的知识资产 关于学习的一个章节,提到了不少如何学习,把学习知识作为投资一样看待,分析的也 很在理.自认为在这方面还是赶上了书中的要求,不然也不会看到这本书了^_^,学习是 一个过程,不会有立杆见影的效果,当然我们不是政客,不需要立马可见的政绩,那么种 种树又何妨呢?学习也要有实践,把学到的知识找机会就应用起来,起码,自己没用到,也 可以看看别人怎么用嘛.学的多了自然有了自己的判断,前两天不小心点开了jdk源码当 中关于Arrays.sort方法的实现.看到内部的合并排序法却不如《算法导论》中描述的 那么简洁,那么具有可读性,这时候,有了判断了,就不至于傻乎乎的研究它的写法,当然 ,jdk里面的mergesort又有一些额外的处理(小数组优化),这个又是可以学习的地方.对 了,这一小节里面还有一段关于如何获得答案的方法,和国内论坛风靡一时的《提问的 智慧》一文有多处相似之处,不知道作者是否参考了本书. 交流 这个不用说就知道重要了.离开上一家公司最后一个项目就是最好的例子,一开始其 他同事从客户处带回来老系统的截图以及一些需求的说明,然后我们就要按照这些支离 破碎的东西进行开发.我们不是先知,不是某些领导人,可以自由的发挥,于是绞尽脑汁, 开始努力向可以吻合的方向发展,这种日子很不好受,直到我可以与客户联系上以后,直 接的面对面的确认客户的需求(又是需求) 才让项目的进展在几天里面比前面一个月都 要好的多. 重复的危害 有时候是copy paste大法带来的后果，有时候是为了省事，总之，一份功能相同的代码在多处出现，更要命的是，需要修改这部分代码！这个可以毫不客气的说就是灾难，所以在设计，在编码初期就要有良好的规划，尽可能避免重复。实际工作中，发行有时候，尽管想要刻意避免，但是还是会出现。其中一个重要原因在于程序员的偷懒，还有是在于模块的可访问性。尤其是两个模块没有任何公用模块的时候，如何避免重复，或者说人工重复才是问题的关键，即使是build脚本去让两个模块出现相同的东西，也比人为维护两个东西都要好上千万倍。 正交性 模块耦合，代码耦合，分层分模块，善用设计模式。正交的目标只有一个，让系统富有弹性，可以随需应变。 可撤销性 还是系统的可变性，是否可以快速应付其中一些改变而快速改变。通常我们用面向接口的方式来做到这些。在前人的基础上，我们有corba ，com，ejb，webservice，odbc，jdbc等等让我们快速应变的基石，但是总有一些依赖我们自己的东西，接口，接口！ 曳光弹 很炫的名字，可惜就是在讲poc，Prove of Concept ，的确很有用。 原型与便笺 原型，没别的，常用的东西。 领域语言 不同语言有不同的优势，关键在于扬长避短，合理运用，有时候组合起来事半功倍。 估算 开始前做好计划，过程中最终计划，磨刀不误砍柴工。 纯文本的威力 很多时候纯文本的简单让事情更容易。 Shell游戏 程序员必须掌握命令行，即使在windows下面。 强力编辑 知道vi好，但是只会那么几个简单的命令，而且，通常我总是在windows下面工作，所以通常用crack的UltraEdit。不少实用的功能，加速编辑。倒是IDE的快捷键记住了不少，在实际工作中，发挥了很大的作用。 书上提到仍有不少人使用windows notepad写代码，我虽然不至于此，但倒是习惯使用它来写文章，记录东西，然而就在刚才，发现手工输入的东西都会出现几个黑色的黑框，可见一定要选择足够好的编辑器才行，何况，windows notepad只能撤销一次，而且你也不会知道撤销的到底是你那次的输入。 源码控制 凡是工作过的程序员，没有不用源码控制工具的吧？ 只是选择有所不同。 调试 读书的时候学习编程，觉得和其他人最不一样的地方在于两点，一是自己思考程序的流程，写下代码之前，知道代码将要（预期）执行的顺序逻辑，二是会调试代码，出现错误时不像一般人完全不知道该如何是好，而是去调试来寻找出错的原因。我相信，现在还是有不少工作了的程序员，不习惯去调试，他们期待的是自己的代码都是一次编写就能正确无误的执行，如果不行，那么别人大概可以帮忙解决。 一直以来，一直觉得，一个程序员的经验丰富情况很大程度依赖于他遇到的bug并解决的数量，所以一个人代码写的越多，解决的问题越多，那么他下次遇到问题时就越容易很快的定位。所以，有时候遇到问题并且成功的选择另外一个方案绕过去以后，不妨回头再看看原来到底为什么不行，毕竟下次也许你又要遇到，而且，更重要的是，可能到时候不能选择其他的方案。 文本操纵 这一节没理解它真正的含义，表面看来是讲可以使用程序来读取操作文本的信息，来加快工作效率，但是到底指什么呢？不明白。不过倒是在工作上，多次嫌手工执行一些转换数据库工作麻烦，而写一些简短的工具来做批处理，效果也很不错。 代码生成器 经常用，很好用。 按合约设计 以前也看过类似的文章，当时还把它贴到公司的wiki上面，并且自从那以后一直坚持契约的方式编程。长久一来，我一直认为这是行之有效的方式，每个人把注意力放到自己的代码中，对他人的代码只作检查，不做包容，如果，对方的屁股没擦干净，一脚踹出去比请进来帮他擦更让人能够觉得舒畅，而且，也能防止有些家伙习惯性的先把屁股伸进来。 至于断言，以前学习VC6的时候因为其对程序的终止而不那么喜欢，而并非每次都写JUnit 也让自己并非常用。 死程序不说谎 代码总是忠实的执行程序员的指令。一切程序员的错误最终将反映到代码上面来，在代码中随时做好踹别人屁股，甚至踹自己屁股的准备，因为崩溃比继续错误的运行更有好处。 断言式编程 就是断言，同21节中的内容。 何时使用异常 因为在用java所以一直在和异常打交道，系统的，别人写的或者是自己写的。异常的处理可以说是所有java应用中最普遍的东西。配合上面3节，合理使用，让异常发挥最大的效用。 怎样配平资源 记住并切实的执行一个原则：打开的资源一定要关闭，这个资源可以是文件，内存，io或者其他。虽然有些语言比如java有GC来管理内存，但是却管理不了文件，c的野指针问题，也都是因为只顾申请却不记得释放导致。还是前面的老话，屁股要自己擦干净，擦不干净当然会把裤子弄脏，脏了裤子是小，臭味熏了别人是大。 解耦与得墨忒耳法则 没明白得墨忒耳法则的具体确切内容，不过减少耦合总是不错的。 元程序设计 很多东西都应该以配置文件的形式来处理，这样的好处显而易见：修改这部分内容无需重新编译代码。而今，我又有一些新的体会： 配置可能会带来配置满天飞的灾难，所以一定要清晰易懂的配置。 时间耦合 工作流的东西，到现在还没有去瞅过，管他呢，用的到时再说吧。 它只是视图 mvc 常用的不行的东西，发布/订阅，这个也是在设计、编码过程中自然而然想要使用的玩意。 黑板 是指多系统共用数据吗？看着有点像，不确定。 靠巧合编程 编写代码的方式是知道要做什么，然后写代码。所以要清楚的知道自己的代码每一步都做了些什么。对于很多程序来说，通常情况下，它是正确的，而某些情况下它却不正常了，那么这就可以归属于靠巧合编程。程序的错误，很多时候在于对边界条件的判断。 算法速率 就目前来说，项目已经很少需要精确到一个具体算法的速度，但是在比较广义的范围内，减少不必要的计算，提高整体运算速度，还是会是系统看起来更好。本节提到的算法复杂度，在很多书中都被提及，但是我从一开始就忽略了这部分的学习，所以，通常情况下，总是不知道一个算法的具体复杂的（总是忘记某些重要的结论，比如递归算法的复杂度计算公式），所以这个一定要补上来。 重构 没什么好说的。 易于测试的代码 测试，保障代码质量，没什么好说的。 邪恶的向导 为了节约时间，出现了各种向导工具，同时也让不明就里的人失去了了解细节的机会，因而，懒惰的人更不会去理会向导做了什么事情，这就是邪恶的原因所在。 需求之坑 终于到了需求的部分，可是有没什么好说的了。 解开不可能解开的迷题 有时候问题的解决需要跳出常规的思维。或者简单一点，用另外一种方法，而不是钻牛角尖。 等你准备好 不打无准备的仗。没什么好说的。 规范陷阱 不要等万事具备才开始，因为不可能万事具备，用户总是在变。 圆圈与箭头 工具是拿来帮助加快开发，而不是束缚开发的。各种各样眼花缭乱的UML，其实只是为了能够清晰描述设计者的思想。当我还是高中生的时候，老师在课堂上面讲述着流程图这种工具，当时甚至5、6年以后我都没听说过uml，但是觉得流程图就是那么的实用。如今，已经很少见到有谁在使用流程图来描述。也许和设计的关注点不同有关，但是当自己在使用uml进行设计时，却又十分的想使用流程图，可惜，像rose之类的工具都没有，也不知道uml是否定义。viso倒貌似有，可是还没用过。前不久找了一个开源的digramdesinger的工具，在这方面倒做的不错。 注重实效的团队 项目开发就脱不开团队，个人的项目除了兴趣爱好，还没听说过。团队重要性不言而喻，以往的经历告诉我一个合理的团队让人觉得有归属感，反之，就容易萌生去意。一起喝着可乐，听着破喇叭放出的音乐，并且加着班的团队在多年以后的记忆里面显得那么的美。 无处不在的自动化 程序的目的之一就是让原本繁琐复杂的重复劳动自动化的处理，而软件开发过程中也一样需要自动化。我一直坚信别人说过的一句话：凡是有人参与的过程，肯定会产生错误。所以，我也一直坚持能让机器去做的事情就交给机器，以减少人的参与，减少错误的发生几率。在过去，我尝试了多次为某些任务编写简单的程序来自动化处理，虽然，我的计划上，没有写一个程序这样的描述，但是，写程序自动处理更好，更有效，最重要的是，还能再次重复预设的动作。此外其他的自动化工具也是很值得推荐，比如自动化测试，代码生成器。 无情的测试 测试是为了保障代码的质量。所以越是仔细，全面的测试，越是有助于系统的健壮，不负责任的程序员或者测试，总是拿着可以正常运行的数据来进行着测试。有条件还是需要专职的测试，合格的测试，而不是那种连代码都看不懂的刚毕业的小姑娘。 全都是写 文档和注释。自认为注释方面还过得去，但是有些情况下还是会忽略注释而后期弥补，这一点需要改正。 至于文档倒是需要好好努力的，这样能显的更“专业”，能更好的记录代码的情况。 极大的期望 达到客户的期望，才是软件真正的成功。这一点，其实又涉及到“万恶的”需求。刚刚经历了一段做完的曳光弹被客户枪毙的事情。其实这一切，如果能从一开始就得到客户的期望，就不会如此的糟糕。而事实却是客户的期望，客户的需求却并非可以得到。虽说这不是好的软件工程的典型，但是至少，我们现在知道了什么是客户期望的。 傲慢与偏激 很cool的名字，不是吗?其实只是指了一个小事情，在你的代码上面留下你的足迹。这一点，在第一个公司的时候就已经养成了习惯，并且保留到现在。虽然现在没有诸如此类的要求，但是我还会继续这么做下去，因为对于自己，对于队友，都是很重要的好习惯，当别人发现有问题时，可以马上过来问我：嘿，为什么会有这个问题。他可以节约自己的时间，我也可以有机会再一次增加自己的经验（参见我之前的感受）。而且留下自己的痕迹，也留下一份责任心，不负责任的人，马上就能被发现。 至此，终于把这本书看完了一遍，当然最后的附录和答案没看。对比自己以往接收的，以及所做的，还比较吻合作者描述的注重实效的程序员，值得欣慰。回忆往事，很多习惯源于第一家公司时候经历的一切。有时候我会想，一个程序员的第一份工作，很可能影响了他未来的道路。 我还是得感谢在我职业道路上给我醒目灯的第一家公司的同事：老麦。作为同事，师兄，领导，朋友，他无私的给我指明了很多的道路，教了我很多的东西。","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://www.toimc.com/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"JavaSript闭包学习","slug":"JavaSript闭包学习","date":"2016-03-09T16:26:48.000Z","updated":"2019-03-12T16:08:34.000Z","comments":true,"path":"JavaSript闭包学习/","link":"","permalink":"https://www.toimc.com/JavaSript%E9%97%AD%E5%8C%85%E5%AD%A6%E4%B9%A0/","excerpt":"今天学了JavaScript闭包，闭包作用：一个是可以读取函数内部的变量，另一个就是让这些变量的值始终保持在内存中。","text":"今天学了JavaScript闭包，闭包作用：一个是可以读取函数内部的变量，另一个就是让这些变量的值始终保持在内存中。 变量的作用域要理解闭包，首先必须理解Javascript特殊的变量作用域。 变量的作用域无非就是两种：全局变量和局部变量。 Javascript语言的特殊之处，就在于函数内部可以直接读取全局变量。 var n=999; function f1()&#123; alert(n); &#125; f1(); // 999 另一方面，在函数外部自然无法读取函数内的局部变量。 function f1()&#123; var n=999; &#125; alert(n); // error 这里有一个地方需要注意，函数内部声明变量的时候，一定要使用var命令。如果不用的话，你实际上声明了一个全局变量！ function f1()&#123; n=999; &#125; f1(); alert(n); // 999 如何从外部读取局部变量？出于种种原因，我们有时候需要得到函数内的局部变量。但是，前面已经说过了，正常情况下，这是办不到的，只有通过变通方法才能实现。 那就是在函数的内部，再定义一个函数 function f1()&#123; var n=999; function f2()&#123; alert(n); // 999 &#125; &#125; 在上面的代码中，函数f2就被包括在函数f1内部，这时f1内部的所有局部变量，对f2都是可见的。但是反过来就不行，f2内部的局部变量，对f1就是不可见的。这就是Javascript语言特有的”链式作用域”结构（chain scope），子对象会一级一级地向上寻找所有父对象的变量。所以，父对象的所有变量，对子对象都是可见的，反之则不成立。 既然f2可以读取f1中的局部变量，那么只要把f2作为返回值，我们不就可以在f1外部读取它的内部变量了吗！ function f1()&#123; var n=999; function f2()&#123; alert(n); &#125; return f2; &#125; var result=f1(); result(); // 999 闭包的概念上一节代码中的f2函数，就是闭包。 各种专业文献上的”闭包”（closure）定义非常抽象，很难看懂。我的理解是，闭包就是能够读取其他函数内部变量的函数。 由于在Javascript语言中，只有函数内部的子函数才能读取局部变量，因此可以把闭包简单理解成”定义在一个函数内部的函数”。 所以，在本质上，闭包就是将函数内部和函数外部连接起来的一座桥梁。 闭包的用途闭包可以用在许多地方。它的最大用处有两个，一个是前面提到的可以读取函数内部的变量，另一个就是让这些变量的值始终保持在内存中。 怎么来理解这句话呢？请看下面的代码。 function f1()&#123; var n=999; nAdd=function()&#123;n+=1&#125; function f2()&#123; alert(n); &#125; return f2; &#125; var result=f1(); result(); // 999 nAdd(); result(); // 1000 在这段代码中，result实际上就是闭包f2函数。它一共运行了两次，第一次的值是999，第二次的值是1000。这证明了，函数f1中的局部变量n一直保存在内存中，并没有在f1调用后被自动清除。 为什么会这样呢？原因就在于f1是f2的父函数，而f2被赋给了一个全局变量，这导致f2始终在内存中，而f2的存在依赖于f1，因此f1也始终在内存中，不会在调用结束后，被垃圾回收机制（garbage collection）回收。 这段代码中另一个值得注意的地方，就是”nAdd=function()&#123;n+=1&#125;“这一行，首先在nAdd前面没有使用var关键字，因此nAdd是一个全局变量，而不是局部变量。其次，nAdd的值是一个匿名函数（anonymous function），而这个匿名函数本身也是一个闭包，所以nAdd相当于是一个setter，可以在函数外部对函数内部的局部变量进行操作。 使用闭包的注意点1）由于闭包会使得函数中的变量都被保存在内存中，内存消耗很大，所以不能滥用闭包，否则会造成网页的性能问题，在IE中可能导致内存泄露。解决方法是，在退出函数之前，将不使用的局部变量全部删除。 2）闭包会在父函数外部，改变父函数内部变量的值。所以，如果你把父函数当作对象（object）使用，把闭包当作它的公用方法（Public Method），把内部变量当作它的私有属性（private value），这时一定要小心，不要随便改变父函数内部变量的值。 思考题如果你能理解下面两段代码的运行结果，应该就算理解闭包的运行机制了。 代码1： var name = &quot;The Window&quot;; var object = &#123; name : &quot;My Object&quot;, getNameFunc : function()&#123; return function()&#123; return this.name; &#125;; &#125; &#125;; alert(object.getNameFunc()()); 理解： 1.object.getNameFunc()返回的是function() 2.object.getNameFunc()()返回的是this.name 3.this这里是指的本文档，本页面。 4.this.name返回的是页面上申明的全局变量name的值。 代码2： var name = &quot;The Window&quot;; var object = &#123; name : &quot;My Object&quot;, getNameFunc : function()&#123; var that = this; return function()&#123; return that.name; &#125;; &#125; &#125;; alert(object.getNameFunc()()); 这个例子不同的地方，是返回了的是object对象作为this。 测试学习环境使用Firebug + CDN JQuery建立学习JS环境，记录调试过程： 1.新建一个html后缀文档。 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;mytest&lt;/title&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.bootcss.com/jquery/2.2.0/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;script type=&quot;text/javascript&quot;&gt; var name = &quot;The Window&quot;; var object = &#123; name : &quot;My Object&quot;, getNameFunc : function()&#123; return function()&#123; return this.name; &#125;; &#125; &#125;; var name = &quot;after Window&quot;; alert(object.getNameFunc()()); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 2.Head部分使用CDN服务： 推荐：BootCDN 3.在Body中写入Script标签，加入测试代码。 4.使用Firebug，F12打开，点击“脚本” 5.打上断点，就可以开始调试了。","categories":[],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://www.toimc.com/tags/Javascript/"}]},{"title":"Git分支管理","slug":"git分支管理","date":"2016-03-09T16:26:48.000Z","updated":"2019-03-12T16:08:46.000Z","comments":true,"path":"git分支管理/","link":"","permalink":"https://www.toimc.com/git%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86/","excerpt":"还记得《星际穿越》中的平行空间吗？两个独立的空间互不干扰，当你正在电脑前努力学习Git的时候，另一个你正在另一个平行宇宙里努力学习SVN。在某一个时间点，两个平行的时空合并了，结果，你既学会了Git又学会了SVN！","text":"还记得《星际穿越》中的平行空间吗？两个独立的空间互不干扰，当你正在电脑前努力学习Git的时候，另一个你正在另一个平行宇宙里努力学习SVN。在某一个时间点，两个平行的时空合并了，结果，你既学会了Git又学会了SVN！ 分支在实际中有什么用呢？假设你准备开发一个新功能，但是需要两周才能完成，第一周你写了50%的代码，如果立刻提交，由于代码还没写完，不完整的代码库会导致别人不能干活了。如果等代码全部写完再一次提交，又存在丢失每天进度的巨大风险。 分支的独立性：现在有了分支，就不用怕了。你创建了一个属于你自己的分支，别人看不到，还继续在原来的分支上正常工作，而你在自己的分支上干活，想提交就提交，直到开发完毕后，再一次性合并到原来的分支上，这样，既安全，又不影响别人工作。 git分支的高效：其他版本控制系统如SVN等都有分支管理，但是用过之后你会发现，这些版本控制系统创建和切换分支比蜗牛还慢，简直让人无法忍受，结果分支功能成了摆设，大家都不去用。 但Git的分支是与众不同的，无论创建、切换和删除分支，Git在1秒钟之内就能完成！无论你的版本库是1个文件还是1万个文件。 理解HEAD头指针一开始的时候，HEAD头指针指向的是主分支，即master分支。而HEAD指向的是当前分支，master指向的是提交。 如果，在master分支上新建了一个分支dev，此时HEAD指向了dev，Git建立分支的过程很快，因为除了增加一个dev指针，改改HEAD的指向，工作区的文件都没有任何变化！ 不过，从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变。 创建dev分支创建分支使用git branch命令，命令格式：git branch [分支别名] $ git branch dev 可以使用$ git branch来查看所有本地分支，$ git branch -a查看所有分支（包括远程分支）。 使用git checkout [分支名]切换到对应的分支，如： $ git checkout dev 此时，HEAD头指针会指向dev，如果在dev上提交，dev指针会往前移，而其他分支不变。（master分支及指针不变） 当使用git checkout master时，HEAD头指针会重新指向master，此时再提交，master指针会往前移。 这个过程，需要自己亲身的试验才能体会到它们的作用和变化。 $gitk 使用Git自带的图形界面，可以很好的来管理分支。 冲突解决冲突产生：当两个分支中修改的相同的文件并提交（add-&gt;commit），合并(merge)这两个分支的时候，会产生冲突。 如下例： $ git checkout -b feature1 在新的feature1分支下修改了readme.txt： vi readme.txt //修改，添加Creating a new branch is quick AND simple. $ git add readme.txt $ git commit -m &quot;AND simple&quot; 切换到master分支： $ git checkout master vi readme.txt //在`master`分支上把readme.txt文件的最后一行改为：Creating a new branch is quick &amp; simple $ git add readme.txt $ git commit -m &quot;&amp; simple&quot; 试图合并master与feature1： $ git merge feature1 Auto-merging readme.txt CONFLICT (content): Merge conflict in readme.txt Automatic merge failed; fix conflicts and then commit the result. （1）使用：$ git status来查看冲突文件： $ git status # On branch master # Your branch is ahead of &#39;origin/master&#39; by 2 commits. # # Unmerged paths: # (use &quot;git add/rm &lt;file&gt;...&quot; as appropriate to mark resolution) # # both modified: readme.txt # no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) （2）直接查看readme.txt文件内容： Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage. Git tracks changes of files. &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Creating a new branch is quick &amp; simple. ======= Creating a new branch is quick AND simple. &gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，我们修改如下后保存： Creating a new branch is quick and simple. 再提交： $ git add readme.txt $ git commit -m &quot;conflict fixed&quot; [master 59bc1cb] conflict fixed PS: 用带参数的git log也可以看到分支的合并情况： $ git log --graph --pretty=oneline --abbrev-commit * 59bc1cb conflict fixed |\\ | * 75a857c AND simple * | 400b400 &amp; simple |/ * fec145a branch test ... 最后，删除feature1分支： $ git branch -d feature1 Deleted branch feature1 (was 75a857c). 分支管理策略通常，合并分支时，如果可能，Git会用Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。 如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。 下面我们实战一下--no-ff方式的git merge： 首先，仍然创建并切换dev分支： $ git checkout -b dev Switched to a new branch &#39;dev&#39; 修改readme.txt文件，并提交一个新的commit： $ git add readme.txt $ git commit -m &quot;add merge&quot; [dev 6224937] add merge 1 file changed, 1 insertion(+) 现在，我们切换回master： $ git checkout master Switched to branch &#39;master 准备合并dev分支，请注意--no-ff参数，表示禁用Fast forward： $ git merge --no-ff -m &quot;merge with no-ff&quot; dev Merge made by the &#39;recursive&#39; strategy. readme.txt | 1 + 1 file changed, 1 insertion(+) 分支策略 在实际开发中，我们应该按照几个基本原则进行分支管理： 首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活； 那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本； 你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。 所以，团队合作的分支看起来就像这样： Bug分支软件开发中，bug就像家常便饭一样。有了bug就需要修复，在Git中，由于分支是如此的强大，所以，每个bug都可以通过一个新的临时分支来修复，修复后，合并分支，然后将临时分支删除。 当你接到一个修复一个代号101的bug的任务时，很自然地，你想创建一个分支issue-101来修复它，但是，等等，当前正在dev上进行的工作还没有提交： $ git status # On branch dev # Changes to be committed: # (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) # # new file: hello.py # # Changes not staged for commit: # (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) # (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) # # modified: readme.txt # 并不是你不想提交，而是工作只进行到一半，还没法提交，预计完成还需1天时间。但是，必须在两个小时内修复该bug，怎么办？ 幸好，Git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作： $ git stash Saved working directory and index state WIP on dev: 6224937 add merge HEAD is now at 6224937 add merge 现在，用git status查看工作区，就是干净的（除非有没有被Git管理的文件），因此可以放心地创建分支来修复bug。 首先确定要在哪个分支上修复bug，假定需要在master分支上修复，就从master创建临时分支： $ git checkout master $ git checkout -b issue-101 现在修复bug，需要把“Git is free software …”改为“Git is a free software …”，然后提交： $ git add readme.txt $ git commit -m &quot;fix bug 101&quot; 修复完成后，切换到master分支，并完成合并，最后删除issue-101分支： $ git checkout master $ git merge --no-ff -m &quot;merged bug fix 101&quot; issue-101 $ git branch -d issue-101 太棒了，原计划两个小时的bug修复只花了5分钟！现在，是时候接着回到dev分支干活了！ $ git checkout dev Switched to branch &#39;dev&#39; $ git status # On branch dev nothing to commit (working directory clean) 工作区是干净的，刚才的工作现场存到哪去了？用git stash list命令看看： $ git stash list stash@&#123;0&#125;: WIP on dev: 6224937 add merge 工作现场还在，Git把stash内容存在某个地方了，但是需要恢复一下，有两个办法： 一种方式：用git stash apply恢复，但是恢复后，stash内容并不删除，你需要用git stash drop来删除； 另一种方式：是用git stash pop，恢复的同时把stash内容也删了： $ git stash pop # On branch dev # Changes to be committed: # (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) # # new file: hello.py # # Changes not staged for commit: # (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) # (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) # # modified: readme.txt # Dropped refs/stash@&#123;0&#125; (f624f8e5f082f2df2bed8a4e09c12fd2943bdd40) 再用git stash list查看，就看不到任何stash内容了： $ git stash list 你可以多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash，用命令： $ git stash apply stash@&#123;0&#125; 删除分支软件开发中，总有无穷无尽的新的功能要不断添加进来。 添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。 还记得吗？ 建立新的分支:git checkout -b feature-new 工作提交：git add --a，git commit -m &quot;something...&quot; 回到dev开发分支：git checkout dev 合并分支：git merge --no-ff feature-new 一切顺利的话，feature分支和bug分支是类似的，合并，然后删除。 但是，就在此时，接到上级命令，因经费不足，新功能必须取消！虽然白干了，但是这个分支还是必须就地销毁： （1）如果没有合并之前，可以简单的使用git branch -d [分支名]来删除分支（使用-D命令，强制删除分支） （2）如果已经合并，除了上面的需要删除以外，还需要使用前面讲到的git reset --hard HEAD^来退回到上一个版本。 PS:分支的删除，不会影响到其他分支上已经合并的分支内容。 多人协作多人协作的工作模式通常是这样： 首先，可以试图用git push origin branch-name推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin branch-name推送就能成功！ 如果git pull提示“no tracking information”，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream branch-name origin/branch-name。 这就是多人协作的工作模式，一旦熟悉了，就非常简单。 注：所有工作流建立在已经建立了个人账户，并添加了SSH key到个人的文档中。见Profile Settings → SSH keys → Before you can add an SSH key you need to [generate it]. 普通开发人员 情况一：程序员A是后加入到项目中的，项目已经存在代码仓库。 如：git@github.com:kanlidy/HelloGit.git （1）克隆版本仓库 git clone git@github.com:kanlidy/HelloGit.git （2）建立分支 git checkout -b (分支名) （3）提交代码 查看代码修改的状态： git status 添加到工作区： git add . 提交到本地仓库： git commit -m &quot;（写下提交日志）&quot; 推送到服务器： git push origin 分支名 （4）在服务器上建立Merge Request，把自己的提交到远程的分支，Merge到Dev(开发分支) 情况二：程序员B是在一个新项目中，本地有一些代码，需要建立一个版本控制仓库 （1）在项目目录下，初始化仓库 git init （2）添加到git版本控制系统： git remote add origin git@github.com:kanlidy/HelloGit.git （3）添加所有已经存在的文件到项目中： git add . （4）提交代码到本地仓库： git commit -m &quot;写下日志&quot; （5）提交代码远程服务器 git push origin &lt;本地分支名&gt;：&lt;远程分支名&gt; git push origin master:master 对于单人项目，情况二足以满足代码控制要求。→吕扬、刘扬。 仓库管理人员 情况一：手工合并代码 （1）在指定分支上获取更新 git checkout &lt;指定分支&gt; （2）拉取服务器上的代码 git pull origin &lt;指定分支&gt; （3）切换到dev，并获取dev上的更新，合并指定分支上的代码 git checkout dev git pull origin dev git merge &lt;指定分支&gt; 情况二：直接在gitlab上进行操作 直接点击accept merge request进行分支合并。 代码回撤参考git reset命令，获取更新参考git fetch命令，分支查看git branch，逻辑流程图gitk，状态命令git status,日志命令git reflog与git log 参考资料： Git 少用 Pull 多用 Fetch 和 Merge 真正理解 git fetch, git pull 以及 FETCH_HEAD git pull 和 git fetch 有什么区别？","categories":[{"name":"git入门","slug":"git入门","permalink":"https://www.toimc.com/categories/git%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"git","slug":"git","permalink":"https://www.toimc.com/tags/git/"},{"name":"版本控制","slug":"版本控制","permalink":"https://www.toimc.com/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}]},{"title":"Git常用命令","slug":"git常用命令","date":"2016-03-09T16:26:48.000Z","updated":"2019-03-12T16:08:46.000Z","comments":true,"path":"git常用命令/","link":"","permalink":"https://www.toimc.com/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"本文介绍了git的常用命令，如git clone、git pull、git push等等。","text":"本文介绍了git的常用命令，如git clone、git pull、git push等等。 git clone该命令会在本地主机生成一个目录，与远程主机的版本库同名。如果要指定不同的目录名，可以将目录名作为git clone命令的第二个参数。 克隆仓库git clone的语法： $ git clone &lt;版本库的网址&gt; &lt;本地目录名&gt; git clone支持多种协议，除了HTTP(s)以外，还支持SSH、Git、本地文件协议等，下面是一些例子。 $ git clone http[s]://example.com/path/to/repo.git/ $ git clone ssh://example.com/path/to/repo.git/ $ git clone git://example.com/path/to/repo.git/ $ git clone /opt/git/project.git $ git clone file:///opt/git/project.git $ git clone ftp[s]://example.com/path/to/repo.git/ $ git clone rsync://example.com/path/to/repo.git/ SSH协议还有另一种写法。 $ git clone [user@]example.com:path/to/repo.git/ 还可以使用-b和标签名来克隆指定的分支和tags： git clone -b r01 https://github.com/xxxx/xxxx.git git remote为了便于管理，Git要求每个远程主机都必须指定一个主机名。git remote命令就用于管理主机名。不带选项的时候，git remote命令列出所有远程主机。 $ git remote origin 使用-v选项，可以参看远程主机的网址。 $ git remote -v origin git@github.com:jquery/jquery.git (fetch) origin git@github.com:jquery/jquery.git (push) 上面命令表示，当前只有一台远程主机，叫做origin，以及它的网址。克隆版本库的时候，所使用的远程主机自动被Git命名为origin。如果想用其他的主机名，需要用git clone命令的-o选项指定。 $ git clone -o jQuery https://github.com/jquery/jquery.git $ git remote jQuery 上面命令表示，克隆的时候，指定远程主机叫做jQuery。git remote show命令加上主机名，可以查看该主机的详细信息。 $ git remote show &lt;主机名&gt; git remote add命令用于添加远程主机。 $ git remote add &lt;主机名&gt; &lt;网址&gt; git remote rm命令用于删除远程主机。 $ git remote rm &lt;主机名&gt; git remote rename命令用于远程主机的改名。 $ git remote rename &lt;原主机名&gt; &lt;新主机名&gt; git fetch一旦远程主机的版本库有了更新（Git术语叫做commit），需要将这些更新取回本地，这时就要用到git fetch命令。 $ git fetch &lt;远程主机名&gt; 上面命令将某个远程主机的更新，全部取回本地。git fetch命令通常用来查看其他人的进程，因为它取回的代码对你本地的开发代码没有影响。默认情况下，git fetch取回所有分支（branch）的更新。如果只想取回特定分支的更新，可以指定分支名。 $ git fetch &lt;远程主机名&gt; &lt;分支名&gt; 比如，取回origin主机的master分支。 $ git fetch origin master 所取回的更新，在本地主机上要用”远程主机名/分支名”的形式读取。比如origin主机的master，就要用origin/master读取。git branch命令的-r选项，可以用来查看远程分支，-a选项查看所有分支。 $ git branch -r origin/master $ git branch -a * master remotes/origin/master 上面命令表示，本地主机的当前分支是master，远程分支是origin/master。取回远程主机的更新以后，可以在它的基础上，使用git checkout命令创建一个新的分支。 $ git checkout -b newBrach origin/master 上面命令表示，在origin/master的基础上，创建一个新分支。此外，也可以使用git merge命令或者git rebase命令，在本地分支上合并远程分支。 $ git merge origin/master # 或者 $ git rebase origin/master 上面命令表示在当前分支上，合并origin/master。 git pullgit pull命令的作用是，取回远程主机某个分支的更新，再与本地的指定分支合并。它的完整格式稍稍有点复杂。 $ git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 比如，取回origin主机的next分支，与本地的master分支合并，需要写成下面这样。 $ git pull origin next:master 如果远程分支是与当前分支合并，则冒号后面的部分可以省略。 $ git pull origin next 上面命令表示，取回origin/next分支，再与当前分支合并。实质上，这等同于先做git fetch，再做git merge。 $ git fetch origin $ git merge origin/next 在某些场合，Git会自动在本地分支与远程分支之间，建立一种追踪关系（tracking）。比如，在git clone的时候，所有本地分支默认与远程主机的同名分支，建立追踪关系，也就是说，本地的master分支自动”追踪”origin/master分支。Git也允许手动建立追踪关系。 git branch --set-upstream master origin/next 上面命令指定master分支追踪origin/next分支。如果当前分支与远程分支存在追踪关系，git pull就可以省略远程分支名。 $ git pull origin 上面命令表示，本地的当前分支自动与对应的origin主机”追踪分支”（remote-tracking branch）进行合并。如果当前分支只有一个追踪分支，连远程主机名都可以省略。 $ git pull 上面命令表示，当前分支自动与唯一一个追踪分支进行合并。如果合并需要采用rebase模式，可以使用--rebase选项。 $ git pull --rebase &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 如果远程主机删除了某个分支，默认情况下，git pull 不会在拉取远程分支的时候，删除对应的本地分支。这是为了防止，由于其他人操作了远程主机，导致git pull不知不觉删除了本地分支。但是，你可以改变这个行为，加上参数 -p 就会在本地删除远程已经删除的分支。 $ git pull -p # 等同于下面的命令 $ git fetch --prune origin $ git fetch -p git pushgit push命令用于将本地分支的更新，推送到远程主机。它的格式与git pull命令相仿。 $ git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 注意，分支推送顺序的写法是&lt;来源地&gt;:&lt;目的地&gt;，所以git pull是&lt;远程分支&gt;:&lt;本地分支&gt;，而git push是&lt;本地分支&gt;:&lt;远程分支&gt;。如果省略远程分支名，则表示将本地分支推送与之存在”追踪关系”的远程分支（通常两者同名），如果该远程分支不存在，则会被新建。 $ git push origin master 上面命令表示，将本地的master分支推送到origin主机的master分支。如果后者不存在，则会被新建。如果省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支。 $ git push origin :master # 等同于 $ git push origin --delete master 上面命令表示删除origin主机的master分支。如果当前分支与远程分支之间存在追踪关系，则本地分支和远程分支都可以省略。 $ git push origin 上面命令表示，将当前分支推送到origin主机的对应分支。如果当前分支只有一个追踪分支，那么主机名都可以省略。 $ git push 如果当前分支与多个主机存在追踪关系，则可以使用-u选项指定一个默认主机，这样后面就可以不加任何参数使用git push。 $ git push -u origin master 上面命令将本地的master分支推送到origin主机，同时指定origin为默认主机，后面就可以不加任何参数使用git push了。不带任何参数的git push，默认只推送当前分支，这叫做simple方式。此外，还有一种matching方式，会推送所有有对应的远程分支的本地分支。Git 2.0版本之前，默认采用matching方法，现在改为默认采用simple方式。如果要修改这个设置，可以采用git config命令。 $ git config --global push.default matching # 或者 $ git config --global push.default simple 还有一种情况，就是不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用–all选项。 $ git push --all origin 上面命令表示，将所有本地分支都推送到origin主机。如果远程主机的版本比本地版本更新，推送时Git会报错，要求先在本地做git pull合并差异，然后再推送到远程主机。这时，如果你一定要推送，可以使用--force选项。 $ git push --force origin 上面命令使用--force选项，结果导致远程主机上更新的版本被覆盖。除非你很确定要这样做，否则应该尽量避免使用--force选项。最后，git push不会推送标签（tag），除非使用--tags选项。 $ git push origin --tags","categories":[{"name":"git入门","slug":"git入门","permalink":"https://www.toimc.com/categories/git%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"git","slug":"git","permalink":"https://www.toimc.com/tags/git/"},{"name":"版本控制","slug":"版本控制","permalink":"https://www.toimc.com/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}]},{"title":"Git入门教程","slug":"Git入门","date":"2016-03-09T16:26:48.000Z","updated":"2019-08-03T17:03:10.000Z","comments":true,"path":"Git入门/","link":"","permalink":"https://www.toimc.com/Git%E5%85%A5%E9%97%A8/","excerpt":"这是一篇Git入门教程，开始阅读本教程之前，请先仔细阅读目录，巧用目录来快速指引你阅读，无关紧要的目录内容可以跳过。","text":"这是一篇Git入门教程，开始阅读本教程之前，请先仔细阅读目录，巧用目录来快速指引你阅读，无关紧要的目录内容可以跳过。 Git简介Git是目前世界上最先进的分布式版本控制系统。 版本控制 典型代表Word文件的编辑，你的文件夹中是不是有这样的情况： word20160301.doc word备份的.doc word(小王).doc word-03.doc word.doc 而某一天，你可能需要以前修改过的版本（因为，经常会遇到这种抽风的上司或者客户） 而由版本控制给你带来的是： 版本 用户 说明 日期 1 张三 删除了软件服务条款5 7/12 10:38 2 张三 增加了License人数限制 7/12 18:09 3 李四 财务部门调整了合同金额 7/13 9:51 4 张三 延长了免费升级周期 7/14 15:17 而且，你想退回到哪里，就可以退回到哪里！ 记住第一个关键词：（无尽的）后悔药 分布式 VS 集中式 集中式，典型的代表就是SVN，版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。 分布式，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库，某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。而集中式版本控制系统的中央服务器要是出了问题，所有人都没法干活了。 Git不单是不必联网这么简单，Git更强大的是分支管理。后面讲到~~~~ 关于更多SVN&amp;Git的区别可以参见： [蒋鑫：为什么 Git 比 SVN 好](http://blog.jobbole.com/20069/) [SVN 和 Git 在日常使用中的明显差异](https://github.com/xirong/my-git/blob/master/why-git.md) [GIT和SVN之间的五个基本区别](http://www.vaikan.com/5-fundamental-differences-between-git-svn/) 记住第二个关键词：分布式 Git环境搭建安装Git* 在Linux(Debian)上安装Git: apt-get install git * Mac OS X上安装Git： 一是安装homebrew，然后通过homebrew安装Git，具体方法请参考homebrew的文档：[http://brew.sh/](http://brew.sh/)。 第二种方法更简单，也是推荐的方法，就是直接从AppStore安装Xcode，Xcode集成了Git，不过默认没有安装，你需要运行Xcode，选择菜单“Xcode”-&gt;“Preferences”，在弹出窗口中找到“Downloads”，选择“Command Line Tools”，点“Install”就可以完成安装了。 * 在Windows上安装Git 从这里[https://git-for-windows.github.io/](https://git-for-windows.github.io/)下载，双击安装 安装完成后，可以在右键菜单/开始菜单中找到“Git”-&gt;“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！ 全局变量设置就像Java需要设置Path一样，Git需要设置一些全局变量。 “Git”-&gt;“Git Bash” $ git config --global user.name &quot;Your Name&quot; $ git config --global user.email &quot;email@example.com&quot; 设置用户与Email，相当于自报家门，让版本库有一个记录。注意：git config命令的--global是全局设置的意思。 任何一个命令或者参考：git [命令] --help来查看帮助，或者登陆官方来学习命令http://git-scm.com/doc 参考资料：Git 内部原理 - 环境变量 创建版本库非常简单。 windows下，需要建立的版本库的地方，右键git bash-&gt; $ git init 瞬间Git就把仓库建好了，而且告诉你是一个空的仓库（empty Git repository），细心的读者可以发现当前目录下多了一个.git的目录，这个目录是Git来跟踪管理版本库的，没事千万不要手动修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。 PS:如果你没有看到.git目录，那是因为这个目录默认是隐藏的 Linux中： 如果，需要在learngit目录下建立一个Git仓库，可以如下操作 $ mkdir learngit $ cd learngit $ git init 你也可以这样: $ git init learngit 试一试吧！ 基本操作Git工作区和暂存区:我们看到目录为工作区(/learngit)；需要进行提交到版本库的文件放在暂存区（看不到，需要使用git status来查看）。 git status命令：可以让我们时刻掌握仓库当前的状态。 git diff命令：让我们查看文件与版本库中的区别。 获取远程仓库代码（前题是init之后） 克隆仓库： $ git clone [user@]example.com:path/to/repo.git/ 或者添加远程仓库： 使用git remote add命令，添加一个远程仓库的链接，命令格式：git remote add [远程仓库别名] [远程仓库地址] $ git remote add origin git@github.com:michaelliao/learngit.git 拉取代码。 如果已经被git管理的项目，则使用git pull和git fetch来管理代码的拉取与更新： 使用git pull拉取远程代码的HEAD头标记，即最新的代码。 命令格式：$ git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; $ git pull 提交代码把所有的文件更改提交到暂存区： $ git add -a 为所有暂存区的代码写入日志并提交到本地仓库： $ git commit -m &quot;(something)&quot; 把所有本地仓库的提交，更新到远程仓库： $ git push Git时光机 git log命令：查看每次修改的日志文件。 git log与git reflog的区别，记得几点：git log是顺着当前分支往前去查找提交记录，而git reflog并不像git log去遍历提交历史，它都不是仓库的一部分，它不包含推送、更新或者克隆，而是作为本地提交记录的清单。简单理解：本地后悔药。 git reset命令：回退命令。 首先，Git必须知道当前版本是哪个版本，在Git中，用HEAD表示当前版本，上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 $ git reset --hard HEAD^ HEAD is now at ea34578 add distributed 回退add命令提交到缓存区的文件，并不会把文件恢复缓存区，需要区别（3）git checkout命令： $ git reset HEAD &lt;file&gt; git checkout -- &lt;file&gt;命令:丢弃缓存区文件的修改，把文件恢复到git add之前的状态。 git diff HEAD -- &lt;file&gt;命令可以查看工作区和版本库里面最新版本的区别 git rm删除文件。 标签管理发布一个版本时，我们通常先在版本库中打一个标签，这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。 Git的标签虽然是版本库的快照，但其实它就是指向某个commit的指针（跟分支很像对不对？但是分支可以移动，标签不能移动），所以，创建和删除标签都是瞬间完成的。 创建标签（快照） 在Git中打标签非常简单，首先，切换到需要打标签的分支上： $ git branch * dev master $ git checkout master Switched to branch &#39;master&#39; 然后，敲命令git tag &lt;name&gt;就可以打一个新标签： $ git tag v1.0 可以用命令git tag查看所有标签： $ git tag v1.0 默认标签是打在最新提交的commit上的。有时候，如果忘了打标签，比如，现在已经是周五了，但应该在周一打的标签没有打，怎么办？ 方法是找到历史提交的commit id，然后打上就可以了： $ git log --pretty=oneline --abbrev-commit 6a5819e merged bug fix 101 cc17032 fix bug 101 7825a50 merge with no-ff 6224937 add merge 59bc1cb conflict fixed 400b400 &amp; simple 75a857c AND simple fec145a branch test d17efd8 remove test.txt 比方说要对add merge这次提交打标签，它对应的commit id是6224937，敲入命令： $ git tag v0.9 6224937 再用命令git tag查看标签： $ git tag v0.9 v1.0 注意，标签不是按时间顺序列出，而是按字母排序的。 可以用git show &lt;tagname&gt;查看标签信息： $ git show v0.9 commit 622493706ab447b6bb37e4e2a2f276a20fed2ab4 Author: Brian &lt;brian@toimc.com&gt; Date: Thu Aug 22 11:22:08 2013 +0800 add merge ... 可以看到，v0.9确实打在add merge这次提交上。 还可以创建带有说明的标签，用-a指定标签名，-m指定说明文字： $ git tag -a v0.1 -m &quot;version 0.1 released&quot; 3628164 用命令git show &lt;tagname&gt;可以看到说明文字： $ git show v0.1 tag v0.1 Tagger: Brian &lt;brian@toimc.com&gt; Date: Mon Aug 26 07:28:11 2013 +0800 version 0.1 released commit 3628164fb26d48395383f8f31179f24e0882e1e0 Author: Brian &lt;brian@toimc.com&gt; Date: Tue Aug 20 15:11:49 2013 +0800 append GPL 还可以通过-s用私钥签名一个标签： $ git tag -s v0.2 -m &quot;signed version 0.2 released&quot; fec145a 参考资料： GPG入门教程 带GPG签名的Git tag git使用GPG进行签名 标签操作（删除，推送） 命令git push origin &lt;tagname&gt;可以推送一个本地标签； 命令git push origin --tags可以推送全部未推送过的本地标签； 命令git tag -d &lt;tagname&gt;可以删除一个本地标签； 命令git push origin :refs/tags/&lt;tagname&gt;可以删除一个远程标签。 如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除： $ git tag -d v0.9 Deleted tag &#39;v0.9&#39; (was 6224937) 然后，从远程删除。删除命令也是push，但是格式如下： $ git push origin :refs/tags/v0.9 To git@github.com:michaelliao/learngit.git - [deleted] v0.9 使用.gitignore忽略文件有些时候，你必须把某些文件放到Git工作目录中，但又不能提交它们，比如保存了数据库密码的配置文件啦，等等，每次git status都会显示Untracked files …，有强迫症的童鞋心里肯定不爽。 好在Git考虑到了大家的感受，这个问题解决起来也很简单，在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。 不需要从头写.gitignore文件，GitHub已经为我们准备了各种配置文件，只需要组合一下就可以使用了。所有配置文件可以直接在线浏览：https://github.com/github/gitignore 忽略文件的原则是： 忽略操作系统自动生成的文件，比如缩略图等； 忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件； 忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。 举个例子： 假设你在Windows下进行Python开发，Windows会自动在有图片的目录下生成隐藏的缩略图文件，如果有自定义目录，目录下就会有Desktop.ini文件，因此你需要忽略Windows自动生成的垃圾文件： # Windows: Thumbs.db ehthumbs.db Desktop.ini 然后，继续忽略Python编译产生的.pyc、.pyo、dist等文件或目录： # Python: *.py[cod] *.so *.egg *.egg-info dist build 加上你自己定义的文件，最终得到一个完整的.gitignore文件，内容如下： # Windows: Thumbs.db ehthumbs.db Desktop.ini # Python: *.py[cod] *.so *.egg *.egg-info dist build # My configurations: db.ini deploy_key_rsa 最后一步就是把.gitignore也提交到Git，就完成了！当然检验.gitignore的标准是git status命令是不是说working directory clean。 使用Windows的童鞋注意了，如果你在资源管理器里新建一个.gitignore文件，它会非常弱智地提示你必须输入文件名，但是在文本编辑器里“保存”或者“另存为”就可以把文件保存为.gitignore了。 或者可以使用以下方法，在git bash中输入以下命令： $ touch .gitignore $ vi .gitignore Git忽略规则及.gitignore规则不生效的解决办法： git rm -r --cached . git add . git commit -m &#39;update .gitignore&#39; PS：注意–cached后面有一个”.”，add后面也有一个“.” 完成上述操作后，再重新修改.gitnore文件，并git add .添加文件到缓存区 配置命令别名有没有经常敲错命令？比如git status？status这个单词真心不好记。 如果敲git st就表示git status那就简单多了，当然这种偷懒的办法我们是极力赞成的。 我们只需要敲一行命令，告诉Git，以后st就表示status： $ git config --global alias.st status 好了，现在敲git st看看效果。 当然还有别的命令可以简写，很多人都用co表示checkout，ci表示commit，br表示branch： $ git config --global alias.co checkout $ git config --global alias.ci commit $ git config --global alias.br branch 以后提交就可以简写成： $ git ci -m &quot;bala bala bala...&quot; --global参数是全局参数，也就是这些命令在这台电脑的所有Git仓库下都有用。 在撤销修改一节中，我们知道，命令git reset HEAD file可以把暂存区的修改撤销掉（unstage），重新放回工作区。既然是一个unstage操作，就可以配置一个unstage别名： $ git config --global alias.unstage &#39;reset HEAD&#39; 当你敲入命令： $ git unstage test.py 实际上Git执行的是： $ git reset HEAD test.py 配置一个git last，让其显示最后一次提交信息： $ git config --global alias.last &#39;log -1&#39; 这样，用git last就能显示最近一次的提交： $ git last commit adca45d317e6d8a4b23f9811c3d7b7f0f180bfe2 Merge: bd6ae48 291bea8 Author: Michael Liao &lt;askxuefeng@gmail.com&gt; Date: Thu Aug 22 22:49:22 2013 +0800 merge &amp; fix hello.py 甚至还有人丧心病狂地把lg配置成了： git config --global alias.lg &quot;log --color --graph --pretty=format:&#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#39; --abbrev-commit&quot; 来看看git lg的效果： 为什么不早点告诉我？别激动，咱不是为了多记几个英文单词嘛！ 配置文件配置Git的时候，加上--global是针对当前用户起作用的，如果不加，那只针对当前的仓库起作用。 配置文件放哪了？每个仓库的Git配置文件都放在.git/config文件中： $ cat .git/config [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true ignorecase = true precomposeunicode = true [remote &quot;origin&quot;] url = git@github.com:michaelliao/learngit.git fetch = +refs/heads/*:refs/remotes/origin/* [branch &quot;master&quot;] remote = origin merge = refs/heads/master [alias] last = log -1 别名就在[alias]后面，要删除别名，直接把对应的行删掉即可。 而当前用户的Git配置文件放在用户主目录下的一个隐藏文件.gitconfig中： $ cat .gitconfig [alias] co = checkout ci = commit br = branch st = status [user] name = Your Name email = your@email.com Git恢复流程当中心仓库由于不可抗拒因素而垮了之后： 项目Git恢复流程： 方法一：恢复指定分支1.注册账号→输入SSH keys→新建项目。 2.在原项目文件夹下，使用git remote -v命令查看 $ git remote -v origin git@192.168.1.222:kanlidy/HelloGit.git (fetch) origin git@192.168.1.222:kanlidy/HelloGit.git (push) 使用git remote remove origin删除原有仓库地址。 3.使用新的仓库地址： git remote add origin [ssh仓库地址] 如： git remote add origin ssh://git@github.com/kanlidy/HelloGit.git 4.添加文件，并Commit提交，最后push上远程指定分支 git add . git commit -m &quot;add my repo&quot; #这条命令会把当前分支，推送到远程的master分支 git push origin master #如果需要把dev分支，推送到远程的dev分支 git push origin dev:dev 方法二：恢复项目所有分支:git remote remove origin git remote add origin [新的SSH仓库地址] git push --mirror ssh://git@github.com/kanlidy/LearnPython.git 本地多个SSH密钥文件有的时候，不仅github使用ssh key，工作项目或者其他云平台可能也需要使用ssh key来认证，如果每次都覆盖了原来的id_rsa文件，那么之前的认证就会失效。这个问题我们可以通过在~/.ssh目录下增加config文件来解决。 第一步依然是配置git用户名和邮箱 git config user.name &quot;用户名&quot; git config user.email &quot;邮箱&quot; 生成ssh key时同时指定保存的文件名 ssh-keygen -t rsa -f ~/.ssh/id_rsa.company -C &quot;email&quot; 上面的id_rsa.company就是我们指定的文件名，这时~/.ssh目录下会多出id_rsa.company和id_rsa.company.pub两个文件，id_rsa.company.pub里保存的就是我们要使用的key。 新增并配置config文件 添加config文件 如果config文件不存在，先添加；存在则直接修改 touch ~/.ssh/config 在config文件里添加如下内容(User表示你的用户名) Host 域名或者IP IdentityFile ~/.ssh/id_rsa.company User test 如： Host 192.168.1.222 IdentityFile ~/.ssh/id_rsa.company User kanlidy 上传key到云平台后台(省略) 测试ssh key是否配置成功 ssh -T git@域名或者IP 如： ssh -T git@192.168.1.222 -p 8082 成功的话会显示： Welcome to GitLab, kanlidy! 至此，本地便成功配置多个ssh key。日后如需添加，则安装上述配置生成key，并修改config文件即可。","categories":[{"name":"git入门","slug":"git入门","permalink":"https://www.toimc.com/categories/git%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"git","slug":"git","permalink":"https://www.toimc.com/tags/git/"},{"name":"版本控制","slug":"版本控制","permalink":"https://www.toimc.com/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}]},{"title":"HTTP状态码200、301、302、304、403、410、500的含义？","slug":"HTTP常见的状态码","date":"2016-03-05T16:26:48.000Z","updated":"2019-03-12T16:08:34.000Z","comments":true,"path":"HTTP常见的状态码/","link":"","permalink":"https://www.toimc.com/HTTP%E5%B8%B8%E8%A7%81%E7%9A%84%E7%8A%B6%E6%80%81%E7%A0%81/","excerpt":"一些常见的状态码为： 200 - 服务器成功返回网页 404 - 请求的网页不存在 503 - 服务器超时 下面提供 HTTP 状态码的完整列表。点击链接可了解详情。您也可以访问 HTTP 状态码上的 W3C 页获取更多信息。","text":"一些常见的状态码为： 200 - 服务器成功返回网页 404 - 请求的网页不存在 503 - 服务器超时 下面提供 HTTP 状态码的完整列表。点击链接可了解详情。您也可以访问 HTTP 状态码上的 W3C 页获取更多信息。 1xx临时响应 100(继续)请求者应当继续提出请求。服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。 101(切换协议)请求者已要求服务器切换协议，服务器已确认并准备切换。 2xx成功 200(成功)服务器已成功处理了请求。通常，这表示服务器提供了请求的网页。如果是对您的 robots.txt 文件显示此状态码，则表示 Googlebot 已成功检索到该文件。 201(已创建)请求成功并且服务器创建了新的资源。 202(已接受)服务器已接受请求，但尚未处理。 203(非授权信息)服务器已成功处理了请求，但返回的信息可能来自另一来源。 204(无内容)服务器成功处理了请求，但没有返回任何内容。 205(重置内容)服务器成功处理了请求，但没有返回任何内容。与 204 响应不同，此响应要求请求者重置文档视图(例如，清除表单内容以输入新内容)。 206(部分内容)服务器成功处理了部分 GET 请求。 3xx重定向 3xx要完成请求，需要进一步操作。通常，这些状态码用来重定向。Google 建议您在每次请求中使用重定向不要超过 5 次。您可以使用网站管理员工具查看一下 Googlebot 在抓取重定向网页时是否遇到问题。诊断下的网络抓取页列出了由于重定向错误导致 Googlebot 无法抓取的网址。 300(多种选择)针对请求，服务器可执行多种操作。服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。 301(永久移动)请求的网页已永久移动到新位置。服务器返回此响应(对 GET 或 HEAD 请求的响应)时，会自动将请求者转到新位置。您应使用此代码告诉 Googlebot 某个网页或网站已永久移动到新位置。 302(临时移动)服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。此代码与响应 GET 和 HEAD 请求的 301 代码类似，会自动将请求者转到不同的位置，但您不应使用此代码来告诉 Googlebot 某个网页或网站已经移动，因为 Googlebot 会继续抓取原有位置并编制索引。 303(查看其他位置)请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。对于除 HEAD 之外的所有请求，服务器会自动转到其他位置。 304(未修改)自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容。 如果网页自请求者上次请求后再也没有更改过，您应将服务器配置为返回此响应(称为 If-Modified-Since HTTP 标头)。服务器可以告诉 Googlebot 自从上次抓取后网页没有变更，进而节省带宽和开销。 . 305(使用代理)请求者只能使用代理访问请求的网页。如果服务器返回此响应，还表示请求者应使用代理。 307(临时重定向)服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。此代码与响应 GET 和 HEAD 请求的 301 代码类似，会自动将请求者转到不同的位置，但您不应使用此代码来告诉 Googlebot 某个页面或网站已经移动，因为 Googlebot 会继续抓取原有位置并编制索引。 4xx请求错误 4xx这些状态码表示请求可能出错，妨碍了服务器的处理。 400(错误请求)服务器不理解请求的语法。 401(未授权)请求要求身份验证。对于登录后请求的网页，服务器可能返回此响应。 403(禁止)服务器拒绝请求。如果您在 Googlebot 尝试抓取您网站上的有效网页时看到此状态码(您可以在 Google 网站管理员工具诊断下的网络抓取页面上看到此信息)，可能是您的服务器或主机拒绝了 Googlebot 访问。 404(未找到)服务器找不到请求的网页。例如，对于服务器上不存在的网页经常会返回此代码。 如果您的网站上没有 robots.txt 文件，而您在 Google 网站管理员工具”诊断”标签的 robots.txt 页上看到此状态码，则这是正确的状态码。但是，如果您有 robots.txt 文件而又看到此状态码，则说明您的 robots.txt 文件可能命名错误或位于错误的位置(该文件应当位于顶级域，名为 robots.txt)。 如果对于 Googlebot 抓取的网址看到此状态码(在”诊断”标签的 HTTP 错误页面上)，则表示 Googlebot 跟随的可能是另一个页面的无效链接(是旧链接或输入有误的链接)。 405(方法禁用)禁用请求中指定的方法。 406(不接受)无法使用请求的内容特性响应请求的网页。 407(需要代理授权)此状态码与 401(未授权)类似，但指定请求者应当授权使用代理。如果服务器返回此响应，还表示请求者应当使用代理。 408(请求超时)服务器等候请求时发生超时。 409(冲突)服务器在完成请求时发生冲突。服务器必须在响应中包含有关冲突的信息。服务器在响应与前一个请求相冲突的 PUT 请求时可能会返回此代码，以及两个请求的差异列表。 410(已删除)如果请求的资源已永久删除，服务器就会返回此响应。该代码与 404(未找到)代码类似，但在资源以前存在而现在不存在的情况下，有时会用来替代 404 代码。如果资源已永久移动，您应使用 301 指定资源的新位置。 411(需要有效长度)服务器不接受不含有效内容长度标头字段的请求。 412(未满足前提条件)服务器未满足请求者在请求中设置的其中一个前提条件。 413(请求实体过大)服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。 414(请求的 URI 过长)请求的 URI(通常为网址)过长，服务器无法处理。 415(不支持的媒体类型)请求的格式不受请求页面的支持。 416(请求范围不符合要求)如果页面无法提供请求的范围，则服务器会返回此状态码。 417(未满足期望值)服务器未满足”期望”请求标头字段的要求。 5xx服务器错误 5xx这些状态码表示服务器在处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。 500(服务器内部错误)服务器遇到错误，无法完成请求。 501(尚未实施)服务器不具备完成请求的功能。例如，服务器无法识别请求方法时可能会返回此代码。 502(错误网关)服务器作为网关或代理，从上游服务器收到无效响应。 503(服务不可用)服务器目前无法使用(由于超载或停机维护)。通常，这只是暂时状态。 504(网关超时)服务器作为网关或代理，但是没有及时从上游服务器收到请求。 505(HTTP 版本不受支持)服务器不支持请求中所用的 HTTP 协议版本。","categories":[],"tags":[{"name":"http","slug":"http","permalink":"https://www.toimc.com/tags/http/"},{"name":"调试技巧","slug":"调试技巧","permalink":"https://www.toimc.com/tags/%E8%B0%83%E8%AF%95%E6%8A%80%E5%B7%A7/"}]},{"title":"SQL快速入门","slug":"SQL快速入门","date":"2016-02-26T16:26:48.000Z","updated":"2019-08-03T17:05:42.000Z","comments":true,"path":"SQL快速入门/","link":"","permalink":"https://www.toimc.com/SQL%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","excerpt":"SQL 是用于访问和处理数据库的标准的计算机语言。在本教程中，您将学到如何使用 SQL 访问和处理数据系统中的数据，这类数据库包括：MySQL、SQL Server、Access、Oracle、Sybase、DB2 等等。本篇博客告诉大家如果快速入门，学习SQL的增(Insert)、删(Delete)、改(Update)、查(Select)。","text":"SQL 是用于访问和处理数据库的标准的计算机语言。在本教程中，您将学到如何使用 SQL 访问和处理数据系统中的数据，这类数据库包括：MySQL、SQL Server、Access、Oracle、Sybase、DB2 等等。本篇博客告诉大家如果快速入门，学习SQL的增(Insert)、删(Delete)、改(Update)、查(Select)。 SQL配置学习环境我的策略是：WAMP中的MySQL+ Navicat 如何配置： 可以先参考：使用WampServer搭建本地PHP环境，绑定域名，配置伪静态先自己搭建一个WAMP环境， 然后，安装Navicat软件，网上一大堆。 打开 -&gt; 选择”连接” -&gt; “MySQL” -&gt; 连接名：MyStudy 主机名或IP地址：localhost 端口：3306 用户名：root 密码：（如果设置了，请输入） -&gt; 连接测试 “OK” -&gt; “确定” -&gt; 选择表 -&gt; 点击”查询” -&gt; “新建查询” -&gt;就可以开始学习了。 简介SQL指结构化查询语言，全称是（Structured Query Language）是用于访问和处理数据库的标准的计算机语言。SQL 让您可以访问和处理数据库。SQL 是一种 ANSI（American National Standards Institute 美国国家标准化组织）标准的计算机语言。 语法数据表： [table id=18 /] 上面的表包含五条记录（每一条对应一个客户）和七个列（CustomerID、CustomerName、ContactName、Address、City、PostalCode 和 Country）。 下面的 SQL 语句从 “Customers” 表中选取所有记录： SELECT * FROM Customers; SQL 对大小写不敏感：SELECT 与 select 是相同的。 某些数据库系统要求在每条 SQL 语句的末端使用分号。 分号是在数据库系统中分隔每条 SQL 语句的标准方法，这样就可以在对服务器的相同请求中执行一条以上的 SQL 语句。 重要的SQL命令一览： SELECT - 从数据库中提取数据 UPDATE - 更新数据库中的数据 DELETE - 从数据库中删除数据 INSERT INTO - 向数据库中插入新数据 CREATE DATABASE - 创建新数据库 ALTER DATABASE - 修改数据库 CREATE TABLE - 创建新表 ALTER TABLE - 变更（改变）数据库表 DROP TABLE - 删除表 CREATE INDEX - 创建索引（搜索键） DROP INDEX - 删除索引 SELECT语句语法：SELECT column_name,column_name FROM table_name; 下面的 SQL 语句从 “Customers” 表中选取 “CustomerName” 和 “City” 列： SELECT CustomerName,City FROM Customers; 如果需要选中所有的列，使用*： SELECT * FROM Customers; ###SELECT DISTINCT语句 语法：SELECT DISTINCT column_name,column_name FROM table_name; 例如： SELECT DISTINCT City FROM Customers; 需要说明的是：DISTINCT与GROUP BY的区别： GROUP BY可以使用一些其它的聚合函数：AVG, MAX, MIN, SUM 和 COUNT。而DISTINCT只是简单的移除重复项。 WHERE子句子句，是作为SELECT语句来说的。 语法：SELECT column_name,column_name FROM table_name WHERE column_name operator value; 例子: SELECT * FROM Customers WHERE Country=&#39;Mexico&#39;; 取得Customers表中，Country为Mexico的所有列。 SQL 使用单引号来环绕文本值（大部分数据库系统也接受双引号）。如果是数值字段，请不要使用引号。 例子： SELECT * FROM Customers WHERE CustomerID=1; 下面的运算符可以在 WHERE 子句中使用： [table id=19 /] AND &amp; OR运算符如果第一个条件和第二个条件都成立，则 AND 运算符显示一条记录。 如果第一个条件和第二个条件中只要有一个成立，则 OR 运算符显示一条记录。 AND例子： SELECT * FROM Customers WHERE Country=&#39;Germany&#39; AND City=&#39;Berlin&#39;; OR例子： SELECT * FROM Customers WHERE City=&#39;Berlin&#39; OR City=&#39;München&#39;; 结合 AND &amp; OR： SELECT * FROM Customers WHERE Country=&#39;Germany&#39; AND (City=&#39;Berlin&#39; OR City=&#39;München&#39;); INSERT INTO语句语法1： INSERT INTO table_name VALUES (value1,value2,value3,…); 语法2： INSERT INTO table_name (column1,column2,column3,...) VALUES (value1,value2,value3,...); 比如插入新的一行： INSERT INTO Customers (CustomerName, ContactName, Address, City, PostalCode, Country) VALUES (&#39;Cardinal&#39;,&#39;Tom B. Erichsen&#39;,&#39;Skagen 21&#39;,&#39;Stavanger&#39;,&#39;4006&#39;,&#39;Norway&#39;); 在指定的列插入数据： INSERT INTO Customers (CustomerName, City, Country) VALUES (&#39;Cardinal&#39;, &#39;Stavanger&#39;, &#39;Norway&#39;); UPDATE语句UPDATE 语句用于更新表中已存在的记录。 语法：UPDATE table_name SET column1=value1,column2=value2,...WHERE some_column=some_value; 实例： UPDATE Customers SET ContactName=&#39;Alfred Schmidt&#39;, City=&#39;Hamburg&#39; WHERE CustomerName=&#39;Alfreds Futterkiste&#39;; 一定要注意，不能省略WHERE子句，否则数据库所有列都会被重写。 DELETE语句语法：DELETE FROM table_name WHERE some_column=some_value; 实例： DELETE FROM Customers WHERE CustomerName=&#39;Alfreds Futterkiste&#39; AND ContactName=&#39;Maria Anders&#39;; 删除所有数据： DELETE FROM table_name; or DELETE * FROM table_name; SELECT TOP子句语法： SELECT TOP number|percent column_name(s) FROM table_name; 下面的 SQL 语句从 “Customers” 表中选取头两条记录，实例： SELECT TOP 2 * FROM Customers; LIKE操作符语法： SELECT column_name(s) FROM table_name WHERE column_name LIKE pattern; 下面的 SQL 语句选取 City 以字母 “L” 开始的所有客户，例子： SELECT * FROM Customers WHERE City LIKE &#39;L%&#39;; 下面的 SQL 语句选取 Country 包含模式 “me” 的所有客户： SELECT * FROM Customers WHERE Country LIKE &#39;%me%&#39;; 通过使用 NOT 关键字，您可以选取不匹配模式的记录。下面的 SQL 语句选取 Country 不包含模式 “me” 的所有客户： SELECT * FROM Customers WHERE Country NOT LIKE &#39;%me%&#39;; SQL通配符[table id=20 /] 主要讲[charlist]通配符，下面的 SQL 语句选取 City 以 “b”、”s” 或 “p” 开始的所有客户： SELECT * FROM Customers WHERE City LIKE &#39;[bsp]%&#39;; 下面的 SQL 语句选取 City 以 “a”、”b” 或 “c” 开始的所有客户： SELECT * FROM Customers WHERE City LIKE &#39;[a-c]%&#39;; 下面的 SQL 语句选取 City 不以 “b”、”s” 或 “p” 开始的所有客户： SELECT * FROM Customers WHERE City LIKE &#39;[!bsp]%&#39;; 可以在线测试一下：http://www.w3schools.com/sql/trysql.asp?filename=trysql_select_wildcard_charlist&amp;ss=-1 IN操作符IN操作符主要是在WHERE子句中去设定多个值 SELECT column_name(s) FROM table_name WHERE column_name IN (value1,value2,...); 下面的 SQL 语句选取 City 为 “Paris” 或 “London” 的所有客户，例如： SELECT * FROM Customers WHERE City IN (&#39;Paris&#39;,&#39;London&#39;); 与下面的句子等价： SELECT * FROM Customers WHERE City = &#39;Paris&#39; OR City=&#39;London&#39;; BETWEEN操作符BETWEEN 操作符选取介于两个值之间的数据范围内的值。这些值可以是数值、文本或者日期。 语法： SELECT column_name(s) FROM table_name WHERE column_name BETWEEN value1 AND value2; 下面的 SQL 语句选取CustomerID介于 1 和 3 之间的所有用户： SELECT * FROM customers WHERE CustomerID BETWEEN 1 AND 3; 与下面的语句等价： SELECT * FROM customers WHERE CustomerID &gt;=1 AND CustomerID&lt;=3; 1.NOT BETWEEN 操作符 同样对于BETWEEN，我们可以使用NOT非操作符： SELECT * FROM customers WHERE CustomerID NOT BETWEEN 1 AND 3; 2.带有 IN 的 BETWEEN 操作符 下面的 SQL 语句选取CustomerID为1到3之间，并且CITY为Berlin的客户： SELECT * FROM customers WHERE CustomerID BETWEEN 1 AND 3 AND CITY IN (&#39;Berlin&#39;); 3.带有文本值的 BETWEEN 操作符下面的SQL语句选取了customers中CustomerName介于’A’和’B’之间字母开始的所有用户： SELECT * FROM customers WHERE CustomerName BETWEEN &#39;A&#39; AND &#39;B&#39;; 请注意，在不同的数据库中，BETWEEN 操作符会产生不同的结果！ 在某些数据库中，BETWEEN 选取介于两个值之间但不包括两个测试值的字段。 在某些数据库中，BETWEEN 选取介于两个值之间且包括两个测试值的字段。 在某些数据库中，BETWEEN 选取介于两个值之间且包括第一个测试值但不包括最后一个测试值的字段。 因此，请检查您的数据库是如何处理 BETWEEN 操作符！","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.toimc.com/tags/MySQL/"}]},{"title":"如何在Linux中添加Swap","slug":"如何在Linux中添加Swap","date":"2016-02-24T16:01:00.000Z","updated":"2019-03-12T16:10:32.000Z","comments":true,"path":"如何在Linux中添加Swap/","link":"","permalink":"https://www.toimc.com/%E5%A6%82%E4%BD%95%E5%9C%A8Linux%E4%B8%AD%E6%B7%BB%E5%8A%A0Swap/","excerpt":"Swap是什么？当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到Swap空间中，等到那些程序要运行时，再从Swap中恢复保存的数据到内存中。这样，系统总是在物理内存不够时，才进行Swap交换。","text":"Swap是什么？当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到Swap空间中，等到那些程序要运行时，再从Swap中恢复保存的数据到内存中。这样，系统总是在物理内存不够时，才进行Swap交换。 实际问题：使用 Vultr 有很长一段时间了，前几天在编译 PHP 的时候出现了进程被 killed 的状况，经过我的吐槽以及和别人交流后发现，是内存耗尽的缘故。其实是因为当时开着 MySQL 进程消耗了不少内存，后来觉得有必要手动添加一下 Swap（交换分区），这样以免以后再编译什么的时候进程被K 。关于 Linux 中 Swap（交换分区），类似于 Windows 的虚拟内存，就是当内存不足的时候，把一部分硬盘空间虚拟成内存使用,从而解决内存容量不足的情况。那么如何在 Linux 中手动添加 Swap 呢？ 下面给大家介绍 检查Swap在设置 Swap 文件之前，有必要先检查一下系统里有没有既存的 Swap 文件。运行以下命令： swapon -s 如果返回的信息概要是空的，则表示 Swap 文件不存在。 检查文件系统在设置 Swap 文件之前，同样有必要检查一下文件系统，看看是否有足够的硬盘空间来设置 Swap 。运行以下命令： df -hal 检查返回的信息，还剩余足够的硬盘空间即可。 创建Swap文件一般来说可以按照如下规则设置swap大小： 4G以内的物理内存，SWAP 设置为内存的2倍。4-8G的物理内存，SWAP 等于内存大小。8-64G 的物理内存，SWAP 设置为8G。64-256G物理内存，SWAP 设置为16G。 实际上，系统中交换分区的大小并不取决于物理内存的量，而是取决于系统中内存的负荷，所以在安装系统时要根据具体的业务来设置SWAP的值。 像我自己的Blog，内存有768M，我想用1G的Swap就应该够了。 下面使用 dd 命令来创建 Swap 文件。 dd if=/dev/zero of=/tmp/swapfile bs=1024 count=1024k 打印信息： 1048576+0 records in 1048576+0 records out 1073741824 bytes (1.1 GB) copied, 3.23377 s, 332 MB/s 参数解读： if=文件名：输入文件名，缺省为标准输入。即指定源文件。&lt; if=input file &gt; of=文件名：输出文件名，缺省为标准输出。即指定目的文件。&lt; of=output file &gt; bs=bytes：同时设置读入/输出的块大小为bytes个字节 count=blocks：仅拷贝blocks个块，块大小等于bs指定的字节数。 格式化并激活 Swap 文件上面已经创建好 Swap 文件，还需要格式化后才能使用。运行命令： mkswap /tmp/swapfile 激活 Swap ，运行命令： swapon /tmp/swapfile 以上步骤做完，再次运行命令： swapon -s 你会发现返回的信息概要： Filename Type Size Used Priority /tmp/swapfile file 1048572 0 -1 系统在什么情况下才会使用SWAP？实际上，并不是等所有的物理内存都消耗完毕之后，才去使用swap的空间，什么时候使用是由swappiness 参数值控制。 cat /proc/sys/vm/swappiness 该值默认值是60。 swappiness=0的时候表示最大限度使用物理内存，然后才是 swap空间， swappiness＝100的时候表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap空间里面。 现在服务器的内存动不动就是上百G，所以我们可以把这个参数值设置的低一些，让操作系统尽可能的使用物理内存，降低系统对swap的使用，从而提高系统的性能。 如何修改swappiness参数？临时修改：使用 sysctl 命令： sysctl vm.swappiness=10 但是这只是临时性的修改，在你重启系统后会恢复默认的60。 永久修改：要永久设置，还需要在 vim 中修改sysctl.conf： vi /etc/sysctl.conf 在这个文档的最后加上这样一行: vm.swappiness=10 输入:wq，保存退出 vim 。 管理SWAP相关命令释放Swap空间假设我们的系统出现了性能问题，我们通过vmstat命令看到有大量的swap，而我们的物理内存又很充足，那么我们可以手工把swap 空间释放出来。让进程去使用物理内存，从而提高性能。 vmstat 1 5 打印信息： root@vultr:~# vmstat 1 5 procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu---- r b swpd free buff cache si so bi bo in cs us sy id wa 0 0 0 61112 29756 324592 0 0 16 19 33 20 3 0 97 0 0 0 0 61112 29756 324592 0 0 0 0 260 550 0 0 100 0 0 0 0 61112 29756 324592 0 0 0 0 255 541 0 0 99 0 0 0 0 61112 29756 324592 0 0 0 0 256 540 0 0 100 0 0 0 0 61112 29760 324588 0 0 0 60 260 552 0 0 98 1 free -m 打印信息： total used free shared buffers cached Mem: 755 696 59 0 29 316 -/+ buffers/cache: 350 405 Swap: 1023 0 1023 注意：free命令默认单位为k, -m 单位为M。 我们这里的swap使用了0M的空间，可能是因为刚刚设置的Swap。 查看当前swap 的使用查看swap使用： swapon -s 或： cat /proc/swaps 之前使用过，就不介绍了。 启用swap使用swapon命令： 格式swapon [swap filename] swapon /dev/sda2 关闭swap使用swapoff命令：格式swapoff [swap filename] swapoff /dev/sda2 之后可以使用swapon -s进行查看。 查看开机启动使用cat /etc/fstab： root@vultr:~# cat /etc/fstab # /etc/fstab: static file system information. # # Use &#39;blkid&#39; to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt; # / was on /dev/vda1 during installation UUID=448a3d02-379e-446b-a1c5-27172ef46473 / ext4 errors=remount-ro 0 1 /dev/sr0 /media/cdrom0 udf,iso9660 user,noauto 0 0 /dev/fd0 /media/floppy0 auto rw,user,noauto 0 0 /tmp/swapfile swap swap defaults 0 0 说明： （1）ext分区是否启用由mount及umount控制。 （2）swap分区是否启动，由swapon及swapoff控制。","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://www.toimc.com/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"搭建Wordpress","slug":"安装wordpress","date":"2016-02-23T11:26:48.000Z","updated":"2019-03-12T16:10:32.000Z","comments":true,"path":"安装wordpress/","link":"","permalink":"https://www.toimc.com/%E5%AE%89%E8%A3%85wordpress/","excerpt":"虽然现在有更多更便捷的安装方式，了解一下原始的安装方法，可以清楚的了解到wordpress是如何运行起来的。搭建wordpress，首先你需要有自己的域名、空间，说白了wordpress就是程序，需要一台机器给它运行，同时需要给这个机器的IP配上一个名字（域名），这样大家通过域名就能访问到你的博客wordpress。","text":"虽然现在有更多更便捷的安装方式，了解一下原始的安装方法，可以清楚的了解到wordpress是如何运行起来的。搭建wordpress，首先你需要有自己的域名、空间，说白了wordpress就是程序，需要一台机器给它运行，同时需要给这个机器的IP配上一个名字（域名），这样大家通过域名就能访问到你的博客wordpress。 域名注册&amp;网站空间/VPS的选择域名有很多域名注册商，国外很有名是Godaddy，国内被阿里云收购的万网。大家萝卜青菜各有所爱，大家看一下http://t.tt/（锤子科技），可以考虑注册一些小众的后缀.io，.me等，因为.com/.cn顶级域名一般好一点的都被国人注册了。如果有一个你特别喜欢，而又被别人注册了的域名，联系域名所有者进行购买，也可以到域名交易平台上找一找相似的进行购买。易名中国，Sedo。网站的内容需要有一个服务器进行存储——虚拟主机（网站空间）、VPS（虚拟服务器）等。虚拟主机便宜的有像Godaddy、Hostease、Bluehost等（国外都不需要备案），VPS有[Vultr](https://www.vultr.com/?ref=6862890)、DigitalOcean、Linode、搬瓦工Bandwagon，国内只推一个阿里云吧。 网站空间很多情况下，是一台服务器上划分了很多磁盘空间，大家IP共一个，如果有人在上面做了一个非法网站被中国这么强大的防火墙给墙掉了，那你的网站也就访问不了了；有人可能会说，国内的呢有备案啊，一般不会被墙吧？但是，共享网站空间还有一个缺点，那就是当服务器其他的网站空间访问量大（视频网站），占用带宽/CPU资源，或多或少的影响到其他人，因为一台服务器的资源是一定的，没有哪个服务商可以拍着自己的胸脯说，我给你的就是足“量”的，要不怎么赚钱呢？而且很多共享空间的服务商的折扣打的很凶，大家一定要明白一个道理，天下没有白吃的午餐，一分价格一分货。便宜不是说没有好货，国人的双11中有节前升了价后又降价的，也有把快过季的东西拿出来打折甩货的，也有很少的一部分性价比高的，需要自己去选去看去比较。 那么，如何选择！根据自己的需求，比如：你是给自己建站建个博客？还是说有需要建个视频站？（高存储）需要很大的并发处理能力？（多cpu）你需要网站搜索高排名？（独立IP）…如果你觉得麻烦了，很多网站上会提供可选的配置清单，对应不同的配置，不同的价格。 想知道它好不好，可以先试用一下。很多服务运营商，会提供试用，如DigitalOcean就有首充送10$的活动，Vultr也有试用活动，点击地址。 总之： 选择口碑好的服务商。 如果有试用，尽量试用过再做选择。3。 不要图便宜，价格适中。 支付方便，反馈及时。 很多服务商都有速度测试，自己用站长工具ping一下，也可以选择这些服务商的测试页面，试一下下载的速度，感受一下。 提供Vultr，Digitalocean，Linode的测试页面： Vultr连接测速，测速页面：https://www.vultr.com/faq/#downloadspeedtests Digitalocean连接测速，测速页面：http://speedtest-sgp1.digitalocean.com/ （新加坡） Linode连接测速，测速页面：https://www.linode.com/speedtest Ramnode连接测速，测速页面：http://lg.la.ramnode.com/ （LA洛杉矶） 我的选择：Vultr: （1）曾经也用过两年的hostease共享空间，经常不是被攻击，就是连接超时，一个月总有那么几次“大姨妈”。 （2）VPS有独立的IP，适合SEO，而且可以做梯子（shadowsocks）sock5代理，让你看一下墙外的世界。 （3）不用备案。 （4）性价比高。相比与DO，我这个地方的联通就很无力；相比与Linode，Linode的最低配置价格又贵了一点。 当初我选择了Vultr的VPS，配置是基本配置1CPU 768M 15GB磁盘空间 1TB的流量。看中的正是它极高的性价比，相比与Linode，它支持Paypal付款，而且退款也很快。相比与DigitalOcean，因为国人搭梯子的太多，DO已经被国人玩坏了，而且限制很多，动不动就冻结你的VPS。所以，DigitalOcean适合中规中矩的站长。 用Vultr，不用Bandwagon的原因：Bandwagon是基于Openvz技术的，不是完全虚拟化的技术，而且带宽不稳定。 域名注册现在的域名注册都很方便，主要说一点：选择口碑好的服务商 服务对比 万网：7X24小时售后电话咨询服务 400 600 8500（支持工单） Goddaddy:中国: 11:00-17:00, 周一至周五(86) 400-842-8288 namesilo: 英文 从服务上来说，万网的优势是服务时间长，但是别忘记了中国人多啊！ 价格对比 目前godaddy的续费价格太高了，相比较而言阿里云的比较低，namesilo是我极力推荐的一个，价格公道，关键续费也便宜，推荐一次性注册个10年。 万网有什么不好的呢？ 有人说，放在万网不放心，不小心ZF哪天就把你的站给毙了！你不做违法乱纪的事，你担心这干嘛？ 老实站长，可以考虑万网的服务。 DNS选择与设置有了好的域名，还要有好的解析服务。 一般来说域名服务商都会提供DNS解析服务，但是在国外买的域名的同学可能就会感受到网站经常打不开，因为可能域名服务商的DNS服务器被GFW（Great Firewall of China）给墙了。 所以，建议国内的站长考虑使用国内的DNS服务商，首推的是DNSpod。 官网：http://dnspod.cn/ 本站就是使用的DNSpod的服务。使用方法： （1）首先，需要注册一个DNSPOD的账号。（如果有更高的安全需要，可以设置两步验证） （2）在DNSPod面板中添加你的域名 一些说明： www：解析后的域名为 www.localhost:8000@：直接解析主域名 localhost:8000*：泛解析，匹配其他所有域名 *.localhost:8000A记录：地址记录，用来指定域名的IPv4地址（如：8.8.8.8），如果需要将域名指向一个IP地址，就需要添加A记录。 CNAME： 如果需要将域名指向另一个域名，再由另一个域名提供ip地址，就需要添加CNAME记录。 TXT：在这里可以填写任何东西，长度限制255。绝大多数的TXT记录是用来做SPF记录（反垃圾邮件）。 NS：域名服务器记录，如果需要把子域名交给其他DNS服务商解析，就需要添加NS记录。 AAAA：用来指定主机名（或域名）对应的IPv6地址（例如：ff06:0:0:0:0:0:0:c3）记录。 MX：如果需要设置邮箱，让邮箱能收到邮件，就需要添加MX记录。 显性URL：从一个地址301重定向到另一个地址的时候，就需要添加显性URL记录（注：DNSPod目前只支持301重定向）。 隐性URL：类似于显性URL，区别在于隐性URL不会改变地址栏中的域名。 SRV：记录了哪台计算机提供了哪个服务。格式为：服务的名字、点、协议的类型，例如：xmpp-server.tcp。 （3）设置域名商的DNS（NameServers）为DNSPod的DNS地址 123456789免费DNS地址：f1g1ns1.dnspod.net/f1g1ns2.dnspod.net （对应 10 台服务器）；豪华DNS地址：ns1.dnsv2.com/ns2.dnsv2.com （对应 12 台服务器）；企业I DNS地址：ns1.dnsv3.com/ns2.dnsv3.com （对应 14 台服务器）；企业II DNS地址：ns1.dnsv4.com/ns2.dnsv4.com （对应 18 台服务器）；企业III DNS地址：ns1.dnsv5.com/ns2.dnsv5.com （对应 22 台服务器）；个人专业版DNS地址：ns3.dnsv2.com/ns4.dnsv2.com （对应 12 台服务器）；企业创业版DNS地址：ns3.dnsv3.com/ns4.dnsv3.com （对应 14 台服务器）；企业标准版 DNS地址：ns3.dnsv4.com/ns4.dnsv4.com （对应 18 台服务器）；企业旗舰版 DNS地址：ns3.dnsv5.com/ns4.dnsv5.com （对应 22 台服务器）。 （4）添加A记录到你的空间/VPS服务商提供的IP地址 （5）Ping/访问你的域名，看看解析是否正常。 wordpress简单介绍官方介绍：WordPress is web software you can use to create a beautiful website, blog, or app. We like to say that WordPress is both free and priceless at the same time. 译文：Wordpress是你可以用来创建炫酷网页、博客或者APP的web软件。我们想说，wordpress不仅是免费的，而且是非常有趣的。 更多wordpress相关：https://wordpress.org/about/,a敬请浏览wordpress官网。 说了这么说，wordpress是到底是什么玩意？ Wordpress是使用PHP语言开发的博客平台，支持在PHP和MySQL的服务器上架设自己的博客。 WordPress最大的“谎言”就是，它让那些没有任何基础的人(隔壁下岗工人张大妈，送快递初中没毕业的陈小蛋,楼下卖早餐的李大爷，餐厅里洗盘子的刘小花)天真地认为只要双击解压安装包，并且点击下一步，下一步，10分钟能就能搭建自己的第一个给力的网站。 选择wordpress理由 1.wordpress最大的特点就是开源，这使它有成千上万的人愿意贡献自己的力量使它变得更好。 2.wordpress拥有众多插件和主题，安装和使用都非常方便，及时你不动代码，你也可以很方便地使用它搭建出漂亮且强大的网站。 主题。网站主题一键更换，而且除了wordpress官网上会有很多免费的提供者，更有一些收费主题也挺不错。大家百度一下，就一大堆。 插件。网站插件一键添加，给你的网站添加不同的特色的功能。 3.前WordPress已不在是一个简单的Blog程序，你不仅可以使用它来搭建个人博客，还可以搭建其他常见类型的网站，比如门户、下载站、淘宝客、论坛、多博客等等。 4.使用WordPress，你不会再孤军奋战，不管你遇到什么问题，只要你百度或者Google一下，你就可以找到解决的办法。 博主弃用wordpress的主要理由：慢，太重了，定制性有但是太复杂。后来选择了hexo，比较轻，也比较方便，部署起来装个Nginx就行啦。 安装MySQLsudo apt-get install mysql-server mysql-client MySQL操作，新增用户，及数据库。 进入数据库： &gt;mysql -u root -p &gt;（密码，隐藏不见） 新建数据库： &gt;mysql&gt;create database testDB; 新建一下用户test@localhost，数据库操作密码123456,给testDB,授予所有权限： &gt;mysql&gt;grant all privileges on testDB.* to test@localhost identified by &#39;123456&#39;; 重要：记住数据库名testDB，用户名test，及用户密码123456，后面建立wordpress的wp-config.php文件时，会使用到。 刷新权限： mysql&gt;flush privileges; Ctrl+Z退出。 下载wordpress，并解压。有几种方法： 使用WinScp软件把下载好的安装包上传，使用解压命令进行解压（这个很简单，配置一下winscp，图形界面的操作方法，不作介绍了）。 使用wget命令进行网络下载，并解压。（推荐） cd /var/www/ wget https://wordpress.org/latest.zip unzip latest.zip -d /var/www/ 卧槽，提示没有unzip命令。所以没有的包在Debian/Ubunyu上，只需要apt-get install xxx，Debian就是这么方便。 apt-get installl unzip 可能会用到移动文件命令：mv ​ mv /var/www/wordpress/* /var/www/ 显示文件目录下的文件： dir 显示文件权限与组： ls -l 安装wordpress 通过http://服务器IP/wp-admin，访问进行安装。 提示： 没有修改wp-config.php文件的权限。 解决方法： 修改apache默认用户的写权限： chmod u+w /var/www/ 修改apache默认目录的所有者为www-data: chown -R www-data: /var/www/ 出现安装向导，点击“创建配置文件”-&gt;“现在开始”-&gt;如下填表-&gt;提交-&gt;进行安装 数据库名 testDB 用户名 test 密码 123456 数据库主机 localhost 表前缀 wp_ 填写网站的基本信息 站点标题 wayearn 用户名 demo 输入两次密码 （使用密码器生成） 您的电子邮件 i@localhost:8000 定制化需求 主题定制 wordpress官方主题就已经很丰富，能够满足大家日常的需要。如果，是企业或者需要有个性一点的主题，可以选择收费主题。 给大家推荐几个比较高质量收费主题的网址： http://themeforest.net/ http://www.elegantthemes.com/ https://www.woothemes.com/ 使用国外的wordpress主题需要有一定的阅读英文的能力，一般都很简单，小伙伴们不需要太紧张。 国内也有一些主题，但是都不像国外那么成气候，而且服务一般不是很到位，总结原因，可以有以下几点： 1.对wordpress认识还不足。 2.对wordpress更多的停留在应用层面。 3.会写的，能写好主题的，一般都在大公司做php开发。 4.无利不成欢，没人会投入自己的时间精力去做公益的事情。更多是把国外优秀的主题进行汉化来卖。 使用插件 (1) 使用插件前，先去插件详情页面去看一下如何使用。 (2) 安装插件，可以使用wordpress官方的插件库，在线的安装；同样，也可以自己从其它的渠道下载后，上传进行安装。 (3) 删除插件前，请前停用插件。 常用插件推荐： Akismet防止恶意评论的插件 BackWPupWordpress备份神器。 Code Snippets这个是可以不用修改functions.php文件，就可以插入功能的小插件。 Content Index文章内索引。 miniOrange 2 Factor Authentication给wordpress添加2步验证，提高wordpress安全。 Redirection重定向。 Related Posts for Wordpress相关的文章。 TablePress可以在Wordpress中插入漂亮表格的插件。 Widget Logic使小工具在指定页面显示。 Wordfence Securitywordpress安全插件 WP Super Cache静态页面神器。 WP-Mail-SMTP邮件插件。 Wp-PostViewswordpress文章浏览次数插件。 WP-Sticky文章分类置顶插件 WPJAM 七牛镜像存储七牛云存储插件。 Yoast SEOwordpress SEO插件。 进阶用法使用widget Logic实现wordpress不同的页面不同的侧边框，使用widget Logic实现wordpress不同的页面不同的菜单。 认识widget Logic插件 (1)基本介绍：widget logic从名称上来看，就是给小工具设置一个逻辑。这个逻辑称为条件标签Conditional Tags：http://codex.wordpress.org/zh-cn:%E6%9D%A1%E4%BB%B6%E6%A0%87%E7%AD%BE。 简单来说：类似C语言里面的if判断。 (2)使用方法：Widget Logic插件，当你启用后，在你所有的插件上会多出一个Widget logic的选择框，可以插入条件标签，或者任意PHP代码。 常用的条件标签： is_home() 主页 is_single() 文章页 is_page() 页面 is_category() 文章分类页 is_tag() 文章标签页 is_archive() 归档页 is_404() 404页 is_search() 搜索结果页 is_feed() 订阅页 进阶用法： is_page(&#39;about&#39;) -&gt; 判断是否为about页面 is_page(&#39;25&#39;) -&gt;判断是否为id=25的页面 is_category(&#39;wordpress&#39;) -&gt; 判断是否为别名是“wordpress“的目录 is_category(&#39;37&#39;) -&gt; 判断是否为id=37的目录 has_tag (&#39;wordpress&#39;) -&gt;判断是否存在名为“wordpress“的标签 你也可以使用逻辑运算符实现更多的控制。|| 为逻辑“或”，&amp;&amp;为逻辑“与”。 在title为“fruit”的页面或名为“food”的目录页或tag为“banana”的页面显示某一小工具。 is_page(&#39;fruit&#39;) || is_category(&#39;food&#39;) || has_tag(&#39;banana&#39;) 仅在单篇日志并且不是某一指定目录中显示小工具。你需要提供特定目录的id号，而不能用别名或目录名来代替。 is_single() &amp;&amp;!in_category( array(23,30,78)) (3)插件下载页面：https://wordpress.org/plugins/widget-logic/或者直接在仪表盘-&gt;插件-&gt;搜索：“Widget Logic”-&gt;下载并安装-&gt;启用。 认识Code Snippets插件 (1)基本介绍： 今天给大家介绍的Code Snippets非Code Snippet，Code Snippet是一个代码高亮插件，而今天我给大家介绍的Code Snippets是一个简单插入代码到主题functions.php的插件。可能你会问插入代码到functions.php有什么用，直接修改不就行了么？如果你的主题更新了的话，你的修改就会被覆盖掉。而使用Code Snippets就不会有这样的风险，你还可以导出/导入你所写的代码。文章的后面会给大家使用Code Snippets实现类似在线代码编辑的功能，wordpress整合Jsbin到页面上来，很简单，很炫酷。 简单来说：Code Snippets实现插入功能到wordpress主题 (2)使用方法： 安装插件后，在仪表盘-&gt;code snippets可以有: manage 管理 add new 新添加一个 import 导入 settings设置 (3)插件下载页面：https://wordpress.org/plugins/code-snippets/ 或者直接在仪表盘-&gt;插件-&gt;搜索：“Code Snippets”-&gt;下载并安装-&gt;启用。 注意：当添加了一个snippets之后，active之后，页面挂了，所有页面都打不开。请在wp-config.php中添加一行代码： define(&#39;CODE_SNIPPETS_SAFE_MODE&#39;, true); 一定要做好语法检查。 (4)使用Code Snippets实现wordpress页面在线编辑器，整合Jsbin到Wordpress页面。 安装code snippets 打开jsbin.com，输入一段代码。如test 选择share按钮，复制HTML代码。 仪表盘-&gt;code snippet-&gt;add new-&gt;名字写Jsbin。 代码输入： function addJsbin()&#123; return &#39;&lt;a class=&quot;jsbin-embed&quot; href=&quot;http://jsbin.com/hekezodiqe/embed?html,output&quot;&gt;JS Bin on jsbin.com&lt;/a&gt;&lt;script src=&quot;http://static.jsbin.com/js/embed.min.js?3.35.9&quot;&gt;&lt;/script&gt;&#39;; &#125; add_shortcode(&#39;jsbin&#39;,&#39;addJsbin&#39;); 在页面上使用[jsbin]短代码，就可以导入一个在线编辑器了。","categories":[],"tags":[{"name":"wordpress","slug":"wordpress","permalink":"https://www.toimc.com/tags/wordpress/"}]},{"title":"监控mysql运行状态","slug":"监控MYSQL","date":"2016-02-23T04:38:00.000Z","updated":"2019-03-12T16:10:32.000Z","comments":true,"path":"监控MYSQL/","link":"","permalink":"https://www.toimc.com/%E7%9B%91%E6%8E%A7MYSQL/","excerpt":"本文介绍了使用简单的shell脚本/supervisor来监控mysql的运行情况，如果停止则重启。","text":"本文介绍了使用简单的shell脚本/supervisor来监控mysql的运行情况，如果停止则重启。 前言最近发现MySQL服务隔三差五就会挂掉，导致我的网站无法正常运作，WordPress提示“建立数据库连接时出错”。 虽然我自己有网站监控和邮件通知，但是好多时候还是需要我来手动连接我的服务器重新启动一下我的MySQL，这样简直太不友好了. 所以，需要一个脚本，定时监控它，如果发现mySQL挂掉了就重启它。 好了，闲言碎语不多讲，开始我们的配置之旅。 运行环境： Distributor ID: Debian Description: Debian GNU/Linux 7.9 (wheezy) Release: 7.9 Codename: wheezy 新建bash脚本：首先，我们要编写一个shell脚本，脚本主要执行的逻辑如下： 显示mysqld进程状态，如果判断进程未在运行，那么输出日志到文件，然后启动mysql服务，如果进程在运行，那么不执行任何操作，可以选择性输出监测结果。 可能大家对于shell脚本比较陌生，在这里推荐官方的shell脚本文档来参考一下 shell脚本的后缀为sh，在任何位置新建一个脚本文件，我选择在 /etc/mysql 目录下新建一个 listen.sh 文件。 执行如下命令： cd /usr/local/sbin/ touch check_mysql.sh vi check_mysql.sh 按i添加如下内容： #!/bin/bash pgrep mysqld &amp;&gt; /dev/null if [ $? -gt 0 ] then echo &quot;`date` mysql is stop&quot; &gt;&gt;/var/log/check_mysql.log service mysql start else echo &quot;`date` mysql running&quot; &gt;&gt;/var/log/check_mysql.log fi 其中 pgrep mysqld 是监测mysqld服务的运行状态，&amp;&gt; /dev/null 是将其结果输出到空文件，也就是不保存输出信息 $? 是拿到上一条命令的运行结果，-gt 0 是判断是否大于0，后面则是输出时间到日志文件，然后启动mysql，否则不启动mysql。 Tips:写完之后可以在脚本所在目录下使用./check_mysql.sh执行脚本，看看log中是否有打印信息，判断脚本执行情况。 赋予脚本权限+x 是代表可执行权限： chmod +x check_mysql.sh 设计定时任务加入crontab，让系统五分钟检测一次mysql状态 #crontab -e 按i，调整光标，在文件的最后添加： */5 * * * * /usr/local/sbin/check_mysql.sh &gt; /dev/null 2&gt;&amp;1 crontab命令相关基础知识，请点击 查看定时任务效果：cat /var/log/check_mysql.log 输出效果： Tue Feb 23 03:25:01 UTC 2016 mysql running Tue Feb 23 03:30:01 UTC 2016 mysql running Tue Feb 23 03:35:01 UTC 2016 mysql running Tue Feb 23 03:40:01 UTC 2016 mysql running Tue Feb 23 03:45:01 UTC 2016 mysql running Tue Feb 23 03:50:01 UTC 2016 mysql running Tue Feb 23 03:55:01 UTC 2016 mysql running Tue Feb 23 04:00:01 UTC 2016 mysql running Tue Feb 23 04:05:01 UTC 2016 mysql running Tue Feb 23 04:10:01 UTC 2016 mysql running Tue Feb 23 04:15:01 UTC 2016 mysql running Tue Feb 23 04:20:01 UTC 2016 mysql running Tue Feb 23 04:25:01 UTC 2016 mysql running Tue Feb 23 04:27:21 UTC 2016 mysql running Tue Feb 23 04:28:00 UTC 2016 mysql running Tue Feb 23 04:28:06 UTC 2016 mysql running Tue Feb 23 04:28:53 UTC 2016 mysql running Tue Feb 23 04:30:01 UTC 2016 mysql running 使用supervisord进行监控（推荐）安装supervisor在centos中： yum install python-setuptools easy_install supervisor pip install supervisor 在Debian/Ubuntu中： apt-get install supervisor 配置supervisorecho_supervisord_conf &gt; /etc/supervisord.conf vim /etc/supervisord.conf 在最后添加监控模块： [program:mysql] command=/etc/inint.d/mysql start autostart=true autorestart=true startretries=10 stderr_logfile=/var/log/mysql/str-err.log stdout_logfile=/var/log/mysql/str-out.log 运行与监控运行： supervisord -c /etc/supervisord.conf 监控： # 停止某一个进程，program_name 为 [program:x] 里的 x supervisorctl stop program_name # 启动某个进程 supervisorctl start program_name # 重启某个进程 supervisorctl restart program_name # 结束所有属于名为 groupworker 这个分组的进程 (start，restart 同理) supervisorctl stop groupworker: # 结束 groupworker:name1 这个进程 (start，restart 同理) supervisorctl stop groupworker:name1 # 停止全部进程，注：start、restart、stop 都不会载入最新的配置文件 supervisorctl stop all # 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程 supervisorctl reload # 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启 supervisorctl update","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://www.toimc.com/tags/mysql/"}]},{"title":"gulp入门教程","slug":"gulp入门到精通","date":"2016-02-16T16:00:00.000Z","updated":"2019-03-12T16:10:32.000Z","comments":true,"path":"gulp入门到精通/","link":"","permalink":"https://www.toimc.com/gulp%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/","excerpt":"本文介绍了前端自动化工具gulp，算是入门介绍，如何安装、配置基础脚本。","text":"本文介绍了前端自动化工具gulp，算是入门介绍，如何安装、配置基础脚本。 安装gulp前提：安装了nodejs，并在项目文件夹下使用了 node init 初始化了项目，生成package.json文件。 第一步：安装命令行工具 $ npm install -g gulp 第二步：在你的项目下把 gulp 安装为开发依赖组件 $ cd &lt;YOUR_PROJECT&gt; $ npm install gulp --save-dev 第三步：在项目的根路径下创建 Gulpfile.js，初始内容为： var gulp = require(&#39;gulp&#39;); gulp.task(&#39;default&#39;, function () &#123; // Hello World console.log(&quot;Hello World&quot;); &#125;); 第四步：运行！ $ gulp gulp-uglify插件使用gulp-uglify插件压缩js： 第一步：安装命令行工具 $ npm install --save-dev gulp-uglify 第二步：修改gulpfile.js文件，新建一个压缩js的task： var gulp = require(&#39;gulp&#39;), uglify = require(&#39;gulp-uglify&#39;); gulp.task(&#39;default&#39;,function()&#123; gulp.src(&#39;js/*.js&#39;) // 指定文件夹下的所有js .pipe(uglify()) //使用uglify .pipe(gulp.dest(&#39;minijs&#39;)); //输出到指定的文件夹 &#125;); 第三步：运行gulp $ gulp 就可以在minjs文件夹下得到压缩完后的js文件 自建Task如下我们新建一个新的task，并给它命名为scripts var gulp = require(&#39;gulp&#39;), uglify = require(&#39;gulp-uglify&#39;); //Scripts Task //Uglifies gulp.task(&#39;scripts&#39;,function()&#123; gulp.src(&#39;js/*.js&#39;) .pipe(uglify()) .pipe(gulp.dest(&#39;build/js&#39;)); &#125;); 之后，我们就可以在命令工具中使用： $ gulp scripts 来运行我们指定的task。 使用default来批量运行tasks： var gulp = require(&#39;gulp&#39;), uglify = require(&#39;gulp-uglify&#39;); //Scripts Task //Uglifies gulp.task(&#39;scripts&#39;,function()&#123; gulp.src(&#39;js/*.js&#39;) .pipe(uglify()) .pipe(gulp.dest(&#39;build/js&#39;)); &#125;); //Styles Task //Uglifies gulp.task(&#39;styles&#39;,function()&#123; console.log(&quot;runs styles&quot;); &#125;); gulp.task(&#39;default&#39;, [&#39;scripts&#39;,&#39;styles&#39;]); 那么当我们使用 $ gulp 系统会按scripts，styles的顺序来执行任务。 动态运行task在gulp中可以使用watch方法来动态监控并运行tasks。 下面我们来介绍下： var gulp = require(&#39;gulp&#39;), uglify = require(&#39;gulp-uglify&#39;); //Scripts Task //Uglifies gulp.task(&#39;scripts&#39;,function()&#123; gulp.src(&#39;js/*.js&#39;) .pipe(uglify()) .pipe(gulp.dest(&#39;build/js&#39;)); &#125;); //Watch Task //Watches Js gulp.task(&#39;watch&#39;,function()&#123; gulp.watch(&#39;js/*.js&#39;, [&#39;scripts&#39;]); &#125;); 其中的gulp.watch(&#39;js/*.js&#39;, [&#39;scripts&#39;]);即监视js文件夹下，所有后缀为js的文件，一旦文件有变化，则会运行scripts任务。 $ gulp watch 来启用监视。 下面，你可以任意在js文件夹下来修改，或者新建js文件，那么gulp会自动把新的js压缩到指定的文件夹build/js中。 如果，你是一个懒人，想在使用$ gulp的默认任务情况下，来实现监控，可以使用如下代码： var gulp = require(&#39;gulp&#39;), uglify = require(&#39;gulp-uglify&#39;); //Scripts Task //Uglifies gulp.task(&#39;scripts&#39;,function()&#123; gulp.src(&#39;js/*.js&#39;) .pipe(uglify()) .pipe(gulp.dest(&#39;build/js&#39;)); &#125;); //Styles Task //Uglifies gulp.task(&#39;styles&#39;,function()&#123; console.log(&quot;runs styles&quot;); &#125;); //Watch Task //Watches Js gulp.task(&#39;watch&#39;,function()&#123; gulp.watch(&#39;js/*.js&#39;, [&#39;scripts&#39;]); &#125;); gulp.task(&#39;default&#39;, [&#39;scripts&#39;,&#39;styles&#39;,&#39;watch&#39;]); 很简单，就只需要在default任务中，加入watch任务就行了。 对Sass压缩第一步：使用npm安装gulp-ruby-sass插件 $ npm install --save-dev gulp-ruby-sass 第二步：新建require引用： var sass = require(&#39;gulp-ruby-sass&#39;); 第三步：新建一个task： //Styles Task //Uglifies gulp.task(&#39;styles&#39;,function()&#123; gulp.src(&#39;scss/**/*.scss&#39;) // 在scss文件夹下的所有scss文件 .pipe(sass()) // 使用sass .pipe(gulp.dest(&#39;css/&#39;));//输出到`css/`下 &#125;); 如需压缩sass文件： //Styles Task //Uglifies gulp.task(&#39;styles&#39;,function()&#123; gulp.src(&#39;scss/**/*.scss&#39;) .pipe(sass(&#123; style:&#39;compressed&#39; //使用压缩选项 &#125;)) .pipe(gulp.dest(&#39;css/&#39;)); &#125;); 如果需要加入到监视文件中，进行动态的修改和输出： //Watch Task //Watches Js gulp.task(&#39;watch&#39;,function()&#123; gulp.watch(&#39;js/*.js&#39;, [&#39;scripts&#39;]); gulp.watch(&#39;scss/**/*.scss&#39;,[&#39;styles&#39;]) &#125;); 那么，就可以使用$ gulp 默认命令来执行我们上述的任务了。 检查代码如果在动态监视代码的时候，自己由于一些低级错误，可能会导致监视停止。那么，我们就要使用到gulp的plumber功能。 使用gulp来动态监视代码中的一些低级错误，导致的监视中止： 第一步：安装gulp-plumber插件 $ npm install --save-dev gulp-plumber 第二步：新建require引用： var plumber = require(&#39;gulp-plumber&#39;); 第三步：在任务中使用plumber //Scripts Task //Uglifies gulp.task(&#39;scripts&#39;,function()&#123; gulp.src(&#39;js/*.js&#39;) .pipe(plumber()) //使用plumber .pipe(uglify()) .pipe(gulp.dest(&#39;build/js&#39;)); &#125;); //Styles Task //Uglifies gulp.task(&#39;styles&#39;,function()&#123; gulp.src(&#39;scss/**/*.scss&#39;) .pipe(plumber()) //使用plumber .pipe(sass(&#123; style:&#39;compressed&#39; &#125;)) .pipe(gulp.dest(&#39;css/&#39;)); &#125;); gulp代码自检同样，当我们不使用plumber时，gulp也提供了一些错误提示方式： //Styles Task //Uglifies gulp.task(&#39;styles&#39;,function()&#123; gulp.src(&#39;scss/**/*.scss&#39;) .pipe(sass(&#123; style:&#39;compressed&#39; &#125;)) .on(&#39;error&#39;,console.error.bind(console)) // 错误提示 .pipe(gulp.dest(&#39;css/&#39;)); &#125;); 或者使用函数把错误提示进行封装： var gulp = require(&#39;gulp&#39;), uglify = require(&#39;gulp-uglify&#39;), sass = require(&#39;gulp-ruby-sass&#39;); function errorLog(error)&#123; //定义一个错误提示 console.error.bind(error); this.emit(&#39;end&#39;); &#125; //Scripts Task //Uglifies gulp.task(&#39;scripts&#39;,function()&#123; gulp.src(&#39;js/*.js&#39;) .pipe(uglify()) .on(&#39;error&#39;,errorLog) .pipe(gulp.dest(&#39;build/js&#39;)); &#125;); //Styles Task //Uglifies gulp.task(&#39;styles&#39;,function()&#123; gulp.src(&#39;scss/**/*.scss&#39;) .pipe(sass(&#123; style:&#39;compressed&#39; &#125;)) .on(&#39;error&#39;,errorLog) .pipe(gulp.dest(&#39;css/&#39;)); &#125;); //Watch Task //Watches Js gulp.task(&#39;watch&#39;,function()&#123; gulp.watch(&#39;js/*.js&#39;, [&#39;scripts&#39;]); gulp.watch(&#39;scss/**/*.scss&#39;,[&#39;styles&#39;]) &#125;); gulp.task(&#39;default&#39;, [&#39;scripts&#39;,&#39;styles&#39;,&#39;watch&#39;]); 动态重载LiveReload第一步：安装gulp-reload插件 $ npm install --save-dev gulp-reload 第二步：新建require引用： var livereload = require(&#39;gulp-livereload&#39;); 第三步：在任务中使用livereload //Watch Task //Watches Js gulp.task(&#39;watch&#39;,function()&#123; var server = livereload(); gulp.watch(&#39;js/*.js&#39;, [&#39;scripts&#39;]); gulp.watch(&#39;scss/**/*.scss&#39;,[&#39;styles&#39;]) &#125;); 压缩图片第一步：安装gulp-imagemin插件 npm install --save-dev gulp-imagemin 第二步：新建require引用： var imagemin = require(&#39;gulp-imagemin&#39;); 第三步：新建压缩任务 //Image Task //Compress gulp.task(&#39;image&#39;,function()&#123; gulp.src(&#39;img/*&#39;) .pipe(imagemin()) .pipe(gulp.dest(&#39;build/img&#39;)); &#125;); 同样，可以加入watch和default任务 加入执行序列比如有的时候，我们需要按照一定的顺序去执行任务，那么就需要使用到run-sequence这个插件： npm install -D run-sequence 在gulpfile.js中添加如下任务： var runSequence = require(&#39;run-sequence&#39;); gulp.task(&#39;default&#39;, function(done)&#123; runSequence( &#39;img&#39;, [&#39;scss&#39;,&#39;scripts&#39;],&#39;watch&#39;,function() &#123; gulp.start([&#39;server&#39;]) done(); &#125;); &#125;); 懒人必备插件gulp-load-plugins引用： var plugins = require(&#39;gulp-load-plugins&#39;)(); 使用： plugins.jshint = require(&#39;gulp-jshint&#39;); plugins.concat = require(&#39;gulp-concat&#39;); 所以引用后，我们就不用去写很多申明插件了，可以直接这样使用： gulp.task(&#39;scripts&#39;,function(done)&#123; gulp.src(config.js.all) .pipe(plugins.plumber(&#123; errorHandler: onError &#125;)) //使用plumber .pipe(plugins.uglify()) .pipe(gulp.dest(config.js.dest)) .pipe(reload(&#123;stream: true&#125;)); done(); &#125;); 例子项目https://www.npmjs.com/package/generator-default-gulp 使用方法： npm install -g yo npm install -g generator-default-gulp yo default-gulp 然后在项目中： gulp 就可以在localhost:3000中看到项目运行起来了。","categories":[],"tags":[{"name":"gulp","slug":"gulp","permalink":"https://www.toimc.com/tags/gulp/"},{"name":"前端自动化","slug":"前端自动化","permalink":"https://www.toimc.com/tags/%E5%89%8D%E7%AB%AF%E8%87%AA%E5%8A%A8%E5%8C%96/"}]},{"title":"github使用ssh密钥","slug":"github使用ssh密钥","date":"2016-01-28T05:49:55.000Z","updated":"2019-03-12T16:10:48.000Z","comments":true,"path":"github使用ssh密钥/","link":"","permalink":"https://www.toimc.com/github%E4%BD%BF%E7%94%A8ssh%E5%AF%86%E9%92%A5/","excerpt":"本文介绍了使用ssh完成对github上仓库的git push，git pull等操作。","text":"本文介绍了使用ssh完成对github上仓库的git push，git pull等操作。 git使用https协议，每次pull, push都要输入密码，相当的烦。使用git协议，然后使用ssh密钥。这样可以省去每次都输密码。 需要三个步骤： 一、本地生成密钥对； 二、设置github上的公钥； 三、修改git的remote url为git协议。 生成密钥对。大多数 Git 服务器都会选择使用 SSH 公钥来进行授权。系统中的每个用户都必须提供一个公钥用于授权，没有的话就要生成一个。生成公钥的过程在所有操作系统上都差不多。首先先确认一下是否已经有一个公钥了。SSH 公钥默认储存在账户的主目录下的 ~/.ssh 目录。进去看看： $ cd ~/.ssh $ ls authorized_keys2 id_dsa known_hosts config id_dsa.pub 关键是看有没有用 something 和 something.pub 来命名的一对文件，这个 something 通常就是 id_dsa 或 id_rsa。有 .pub 后缀的文件就是公钥，另一个文件则是密钥。假如没有这些文件，或者干脆连 .ssh 目录都没有，可以用 ssh-keygen 来创建。该程序在 Linux/Mac 系统上由 SSH 包提供，而在 Windows 上则包含在 MSysGit 包里： $ ssh-keygen -t rsa -C &quot;your_email@youremail.com&quot; # Creates a new ssh key using the provided email # Generating public/private rsa key pair. # Enter file in which to save the key (/home/you/.ssh/id_rsa): 直接Enter就行。然后，会提示你输入密码，如下(建议输一个，安全一点，当然不输也行)： Enter passphrase (empty for no passphrase): [Type a passphrase] # Enter same passphrase again: [Type passphrase again] 完了之后，大概是这样。 Your identification has been saved in /home/you/.ssh/id_rsa. # Your public key has been saved in /home/you/.ssh/id_rsa.pub. # The key fingerprint is: # 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@youremail.com 这样。你本地生成密钥对的工作就做好了。 添加公钥到你的github帐户1、查看你生成的公钥：大概如下： $ cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU GPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlE LEVf4h9lFX5QVkbPppSwg0cda3 Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA t3FaoJoAsncM1Q9x5+3V 0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En mZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx NrRFi9wrf+M7Q== schacon@agadorlaptop.local 2、登陆你的github帐户。然后 Account Settings -&gt; 左栏点击 SSH Keys -&gt; 点击 Add SSH key 3、然后你复制上面的公钥内容，粘贴进“Key”文本域内。 title域，你随便填一个都行。 4、完了，点击 Add key。 这样，就OK了。然后，验证下这个key是不是正常工作。 $ ssh -T git@github.com # Attempts to ssh to github 如果，看到： Hi username! You&#39;ve successfully authenticated, but GitHub does not # provide shell access. 就表示你的设置已经成功了。 修改你本地的ssh remote url. 不用https协议，改用git 协议确保： 1.你已经init了一个空仓库。 2.你已经把远程git的url添加到了本地git仓库的配置文件 ================================================ 可以用git remote -v 查看你当前的remote url $ git remote -v origin https://github.com/someaccount/someproject.git (fetch) origin https://github.com/someaccount/someproject.git (push) 可以看到是使用https协议进行访问的。 你可以使用浏览器登陆你的github，在上面可以看到你的ssh协议相应的url。类似如下： git@github.com:someaccount/someproject.git 这时，你可以使用 git remote set-url 来调整你的url。 git remote set-url origin git@github.com:someaccount/someproject.git 完了之后，你便可以再用 git remote -v 查看一下。 $ git remote -v origin https://git@github.com:someaccount/someproject.git (fetch) origin https://git@github.com:someaccount/someproject.git (push) OK。 至此，你就可以省去输入密码的麻烦，也可以很安全的进行push,pull,fetch,checkout等操作了。 你可以用git fetch, git pull , git push。 注意： 第一次使用git push之前，需要对git push进行配置： 1.simple方式： git config --global push.default.simple 2.matching方式： git config --global push.default.matching matching means git push will push all your local branches to the ones with the same name on the remote. This makes it easy to accidentally push a branch you didn&#39;t intend to. matching与simple方式的push的区别是：matching会把你所有本地的分支push到远程仓库中对应匹配的分支。，； simple means git push will push only the current branch to the one that git pull would pull from, and also checks that their names match. This is a more intuitive behavior, which is why the default is getting changed to this. simple方式，只会push你已经从远程仓库pull过的分支，意思是你曾经pull了分支dev，那么当你使用缺省git push时，当前分支为dev，远程分支dev就会收到你的commit。 3.或者使用git push [远程仓库] [本地分支]","categories":[{"name":"git入门","slug":"git入门","permalink":"https://www.toimc.com/categories/git%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"git","slug":"git","permalink":"https://www.toimc.com/tags/git/"}]},{"title":"git代码仓库转移","slug":"git代码仓库转移","date":"2016-01-28T05:49:55.000Z","updated":"2019-03-12T14:40:25.000Z","comments":true,"path":"git代码仓库转移/","link":"","permalink":"https://www.toimc.com/git%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E8%BD%AC%E7%A7%BB/","excerpt":"","text":"如果你想从别的 Git 托管服务那里复制一份源代码到新的 Git 托管服务器上的话，可以通过以下步骤来操作。 1). 从原地址克隆一份裸版本库，比如原本托管于 GitHub。 git clone --bare git@/github.com:username/project.git 一定要记住clone的是bare仓库。 2). 然后到新的 Git 服务器上创建一个新项目，比如 GitCafe上建立一个项目newproject.git。 3). 以镜像推送的方式上传代码到 GitCafe 服务器上。 cd project.git git push --mirror git@gitcafe.com:username/newproject.git 4). 删除本地代码 cd .. rm -rf project.git 5). 到新服务器 GitCafe 上找到 Clone 地址，直接 Clone 到本地就可以了。 git clone git@gitcafe.com:username/newproject.git 这种方式可以保留原版本库中的所有内容。 我们来测试一下 从gitcafe clone出来的仓库看得到，我们github上的项目的所有commmit记录都得以了保存。","categories":[{"name":"git入门","slug":"git入门","permalink":"https://www.toimc.com/categories/git%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"git","slug":"git","permalink":"https://www.toimc.com/tags/git/"},{"name":"版本控制","slug":"版本控制","permalink":"https://www.toimc.com/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}]},{"title":"使用WampServer搭建本地PHP环境，绑定域名，配置伪静态","slug":"使用WampServer搭建本地PHP环境，绑定域名，配置伪静态","date":"2016-01-26T05:23:48.000Z","updated":"2019-03-13T01:17:33.000Z","comments":true,"path":"/2016/01/wamp/","link":"","permalink":"https://www.toimc.com/2016/01/wamp/","excerpt":"WampServer 简介Wamp就是Windows Apache Mysql PHP集成安装环境，即在window下的apache、php和mysql的服务器软件。也是一件安装，不需要你进行环境的配置。","text":"WampServer 简介Wamp就是Windows Apache Mysql PHP集成安装环境，即在window下的apache、php和mysql的服务器软件。也是一件安装，不需要你进行环境的配置。 WampServer 下载安装官方地址：http://www.wampserver.com/ （支持32位和64位系统，根据自己的系统选择版本） 1.下载后，直接运行安装，安装过程可能会要你设置默认浏览器，过程略过。 2.运行 WampServer ，在右下角的任务栏出现图标，在图标上右键，选择语言为简体中文。 3.在图标上单击左键，出现 WampServer 的快捷管理菜单，包括各种服务的快捷入口和服务设置： Localhost：默认的网站首页，如果打开显示 403 Forbidden，你可以手动输入 http://127.0.0.1 进行访问 或者打开 c:\\windows\\system32\\drivers\\etc 修改hosts文件，添加一条记录 127.0.0.1 localhost 保存即可。 注：如果提示你无法保存hosts文件，可能是你目前的系统用户没有修改权限，请自己搜索解决办法；或者是某些安全软件限制了修改，暂时退出安全软件。 www目录：存放网站文件的根目录 WampServer 绑定域名，添加虚拟主机1.将你要绑定的域名，使用A记录绑定到 127.0.0.1 2.启动wampserver服务，左键单击右下角wampserver图标，打开Apache菜单下“httpd.conf”文件； 找到“# Include conf/extra/httpd-vhosts.conf” ，把这句前面的#号去掉，启用了虚拟主机配置文件 httpd-vhosts.conf 的引用。 ３.在Apache安装目录的confextra目录下，比如我的是 D:\\wamp\\bin\\apache\\apache2.2.22\\conf\\extra，用记事本打开httpd-vhosts.conf，最最底部你会看到２个虚拟主机样例，将其中一个修改为类型下面的，删除多余的样例： &lt;VirtualHost *:80&gt; ServerAdmin admin@xxx.com DocumentRoot &quot;D:/wamp/www/xxx.com&quot; ServerName www.xxx.com ErrorLog &quot;logs/www.xxx.com-error.log&quot; CustomLog &quot;logs/www.xxx.com-access.log&quot; common &lt;/VirtualHost&gt; 4.在托盘中左键单击wampserver，重启所有服务； 5.用记事本打开 c:\\windows\\system32\\drivers\\etc 目录下hosts文件，在最下面添加一行： 127.0.0.1 www.xxx.com 6.在浏览器下输入www.xxx.com,可以看到通过http已经访问到本机下 d:\\wamp\\www\\xxx.com 目录，以后你只要将这个网站的文件放在这个目录即可。 7.如果你要添加多个虚拟主机，重复上面的操作即可。 WampServer 配置伪静态默认情况下，WampServer不支持伪静态，我们需要进行一些配置 1.启动wampserver服务，左键单击右下角wampserver图标，打开Apache菜单下“httpd.conf”文件； 2.搜索找到“LoadModule rewrite_module modules/mod_rewrite.so”这一行，去掉前面的“#”； 3.找到“AllowOverride None”改为“AllowOverride All”； 4.重启wampserver的所有服务 5.新建.haccess文件，放在当前网站根目录下，在.haccess文件中添加伪静态规则，比如添加WordPress伪静态规则 # BEGIN WordPress &lt;IfModule mod_rewrite.c&gt; RewriteEngine On RewriteBase / RewriteRule ^index.php$ - [L] RewriteCond %&#123;REQUEST_FILENAME&#125; !-f RewriteCond %&#123;REQUEST_FILENAME&#125; !-d RewriteRule . /index.php [L] &lt;/IfModule&gt; # END WordPress 注：每个建站程序的伪静态规则不一样，请根据自己的需要添加。","categories":[],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://www.toimc.com/tags/PHP/"},{"name":"开发环境","slug":"开发环境","permalink":"https://www.toimc.com/tags/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"}]},{"title":"用SSH来管理Linux服务器，禁用口令登陆，提高Linux服务器安全","slug":"SSH登陆linux","date":"2016-01-25T16:49:55.000Z","updated":"2019-03-13T01:18:08.000Z","comments":true,"path":"SSH登陆linux/","link":"","permalink":"https://www.toimc.com/SSH%E7%99%BB%E9%99%86linux/","excerpt":"我们一般使用 PuTTY 等 SSH 客户端来远程管理 Linux 服务器。但是，一般的密码方式登录，容易有密码被暴力破解的问题。所以，一般我们会将 SSH 的端口设置为默认的22以外的端口，或者禁用 root 账户登录。 其实，有一个更好的办法来保证安全，而且让你可以放心地用root账户从远程登录——那就是通过密钥方式登录。 密钥形式登录的原理是：利用密钥生成器制作一对密钥，将公钥添加到服务器的某个账户上，然后在客户端利用私钥即可完成认证并登录。这样一来，没有私钥，任何人都无法通过 SSH 暴力破解你的密码来远程登录到系统。此外，如果将公钥复制到其他账户甚至主机，利用私钥也可以登录。 下面来讲解如何在 Linux 服务器上制作密钥对，将公钥添加给账户，设置 SSH，最后通过客户端登录。","text":"我们一般使用 PuTTY 等 SSH 客户端来远程管理 Linux 服务器。但是，一般的密码方式登录，容易有密码被暴力破解的问题。所以，一般我们会将 SSH 的端口设置为默认的22以外的端口，或者禁用 root 账户登录。 其实，有一个更好的办法来保证安全，而且让你可以放心地用root账户从远程登录——那就是通过密钥方式登录。 密钥形式登录的原理是：利用密钥生成器制作一对密钥，将公钥添加到服务器的某个账户上，然后在客户端利用私钥即可完成认证并登录。这样一来，没有私钥，任何人都无法通过 SSH 暴力破解你的密码来远程登录到系统。此外，如果将公钥复制到其他账户甚至主机，利用私钥也可以登录。 下面来讲解如何在 Linux 服务器上制作密钥对，将公钥添加给账户，设置 SSH，最后通过客户端登录。 制作密钥对首先在服务器上制作密钥对。首先用密码登录到你打算使用密钥登录的账户，然后执行以下命令： [root@host ~]$ ssh-keygen &lt;== 建立密钥对 Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): &lt;== 按 Enter Created directory &#39;/root/.ssh&#39;. Enter passphrase (empty for no passphrase): &lt;== 输入密钥锁码，或直接按 Enter 留空 Enter same passphrase again: &lt;== 再输入一遍密钥锁码 Your identification has been saved in /root/.ssh/id_rsa. &lt;== 私钥 Your public key has been saved in /root/.ssh/id_rsa.pub. &lt;== 公钥 The key fingerprint is: 0f:d3:e7:1a:1c:bd:5c:03:f1:19:f1:22:df:9b:cc:08 root@host 密钥锁码在使用私钥时必须输入，这样就可以保护私钥不被盗用。当然，也可以留空，实现无密码登录。现在，在 root 用户的家目录中生成了一个 .ssh 的隐藏目录，内含两个密钥文件。id_rsa 为私钥，id_rsa.pub 为公钥。 在服务器上安装公钥键入以下命令，在服务器上安装公钥： [root@host ~]$ cd .ssh [root@host .ssh]$ cat id_rsa.pub &gt;&gt; authorized_keys 如此便完成了公钥的安装。 为了确保连接成功，请保证以下文件权限正确： [root@host .ssh]$ chmod 600 authorized_keys [root@host .ssh]$ chmod 700 ~/.ssh 或者通过: ls -la 查看文件权限。 将私钥下载到客户端，然后转换为 PuTTY能使用的格式使用 WinSCP、SFTP 等工具将私钥文件 id_rsa 下载到客户端机器上。然后打开 PuTTYGen，单击“载入”（load）按钮，载入你刚才下载到的私钥文件id_rsa，而非id_rsa.pub，载入进来。 如果你刚才设置了密钥锁码，这时则需要输入。 载入成功后，PuTTYGen 会显示密钥相关的信息。在 Key comment 中键入对密钥的说明信息，然后单击 Save private key 按钮即可将私钥文件存放为 PuTTY 能使用的格式。 今后，当你使用 PuTTY 登录时，会话处输入主机IP及端口，选择SSH连接方式。（或者之前有保存过的，直接载入）。 然后， 在左侧的：连接 -&gt; SSH -&gt; 认证 中的：认证私钥文件 （Connection -&gt; SSH -&gt; Auth），选择你的私钥文件。 然后，点击打开。输入root。 即登录了，如果设置了私钥密码过程中只需输入密钥锁码即可。 确保SSH可以连接正常后，设置 SSH，打开密钥登录功能。编辑 vi /etc/ssh/sshd_config 文件，进行如下设置： RSAAuthentication yes PubkeyAuthentication yes 另外，请留意 root 用户能否通过 SSH 登录： PermitRootLogin yes 当你完成全部设置，并以密钥方式登录成功后，再禁用密码登录： PasswordAuthentication no 最后，重启 SSH 服务： [root@host .ssh]$ service ssh restart 其他的说明1.修改默认端口22； 2.使用ufw进行防火墙管理； 3.关于多个ssh密钥的管理，参考如下目录结构： 1234567891011121314151617181920.├── config├── id_rsa├── id_rsa.pub├── known_hosts└── servers ├── BT-jenkins ├── BT-ss ├── NewJira ├── bt-public ├── docker ├── jenkins ├── k8s ├── linode ├── mysql ├── myss-vps ├── pmms-test ├── slave-jenkins ├── slave-jenkins1 └── whtvTest config文件参考： 123456789Host * ServerAliveInterval 30Host jp1 Port 222 HostName 10.10.10.111 User root IdentityFile ~/.ssh/servers/BT-ss IdentitiesOnly yes","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://www.toimc.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"ssh","slug":"ssh","permalink":"https://www.toimc.com/tags/ssh/"}]},{"title":"启动Apache对.htaccess的支持步骤","slug":"Apache对.htaccess 的支持","date":"2016-01-25T16:26:48.000Z","updated":"2019-08-03T17:05:42.000Z","comments":true,"path":"Apache对.htaccess 的支持/","link":"","permalink":"https://www.toimc.com/Apache%E5%AF%B9.htaccess%20%E7%9A%84%E6%94%AF%E6%8C%81/","excerpt":"Ubuntu/Debian下启动Apache对.htaccess 的支持步骤","text":"Ubuntu/Debian下启动Apache对.htaccess 的支持步骤 1.终端运行 sudo a2enmod 程序提示可供激活的模块名称，输入： rewrite 2.修改指向站点的配置文件(该链接) vi /etc/apache2/sites-enabled/000-default 把（默认的www目录、或者需要应用.htaccess的目录）下的AllowOverride 属性改为All，保存。 3.重新加载apache sudo /etc/init.d/apache2 restart14514686.28797 本地环境WAMP下，修改apache的配置文件httpd.conf参考：使用WampServer搭建本地PHP环境，绑定域名，配置伪静态 1.启动wampserver服务，左键单击右下角wampserver图标，打开Apache菜单下“httpd.conf”文件； 2.搜索找到“LoadModule rewritemodule modules/modrewrite.so”这一行，去掉前面的“#”； 3.找到“AllowOverride None”改为“AllowOverride All”； 4.重启wampserver的所有服务。","categories":[],"tags":[{"name":"Apache","slug":"Apache","permalink":"https://www.toimc.com/tags/Apache/"},{"name":"运维","slug":"运维","permalink":"https://www.toimc.com/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"Debian/Ubuntu下更换默认编辑器为vim","slug":"Debian下更换默认编辑器为vim","date":"2016-01-25T16:22:48.000Z","updated":"2019-03-12T16:10:43.000Z","comments":true,"path":"Debian下更换默认编辑器为vim/","link":"","permalink":"https://www.toimc.com/Debian%E4%B8%8B%E6%9B%B4%E6%8D%A2%E9%BB%98%E8%AE%A4%E7%BC%96%E8%BE%91%E5%99%A8%E4%B8%BAvim/","excerpt":"有些同学在debian系统下输入VI或VIM的命令编辑文本，确发现按键盘的上下左右方向键，变成显示ABCD字符了，退格键也失灵。恩，没错这是有些debian系统默认的编辑器并不是VIM而是nano的缘故。下面有几个方法可以解决问题。","text":"有些同学在debian系统下输入VI或VIM的命令编辑文本，确发现按键盘的上下左右方向键，变成显示ABCD字符了，退格键也失灵。恩，没错这是有些debian系统默认的编辑器并不是VIM而是nano的缘故。下面有几个方法可以解决问题。 There is only one alternative in link group editor: /usr/bin/vim.tiny Nothing to configure. 运行如下命令： update-alternatives --config editor 出现如下界面： There are 3 alternatives which provide `editor&#39;. Selection Alternative ----------------------------------------------- 1 /bin/ed + 2 /bin/nano * 3 /usr/bin/vim.tiny Press enter to keep the default[*], or type selection number: 选择3重启一下就可以了.提示，这里只是vim.tiny，而我们经常用的是vim.basic。 apt-get remove nano vi /etc/apt/sources.list 按i，添加源： deb http://ftp.debian.org/debian squeeze main contrib non-free deb http://security.debian.org squeeze/updates main contrib non-free :wq #保存配置，退出 apt-get update #更新源 apt-get upgrade #更新系统 重新安装VIM编辑器： apt-get install vim 再次使用： update-alternatives --config editor 使用vim.basic。 这样就OK了.","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://www.toimc.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"vim","slug":"vim","permalink":"https://www.toimc.com/tags/vim/"}]},{"title":"Ubuntu(Debian)上安装LAMP环境（Linux+Apache+MySQL+PHP）","slug":"Ubuntu(Debian)安装LAMP","date":"2016-01-25T02:28:55.000Z","updated":"2019-03-13T01:20:48.000Z","comments":true,"path":"Ubuntu(Debian)安装LAMP/","link":"","permalink":"https://www.toimc.com/Ubuntu(Debian)%E5%AE%89%E8%A3%85LAMP/","excerpt":"Ubuntu(Debian)上安装LAMP环境（Linux+Apache+MySQL+PHP）的介绍，方便小伙伴们开发PHP，部署Wordpress。 其实还有很多很优秀的安装脚本与工具，比如：宝塔，这个就是一个管理面板，里面集成了很多开发环境。","text":"Ubuntu(Debian)上安装LAMP环境（Linux+Apache+MySQL+PHP）的介绍，方便小伙伴们开发PHP，部署Wordpress。 其实还有很多很优秀的安装脚本与工具，比如：宝塔，这个就是一个管理面板，里面集成了很多开发环境。 更新:apt-get update 安装Apache：apt-get install apache2 安装完之后，你就可以打开自己的IP了，如：http://104.238.148.88/ 会看到apache安装成功并运行了。 安装MySQL:apt-get install mysql-server 之后：运行安装脚本 mysql_secure_installation 提示： Enter current password for root (enter for none): 输入root用户的MySQL密码，如：1234567890，回车； OK, successfully used password, moving on... By default, a MySQL installation has an anonymous user, allowing anyone to log into MySQL without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? [Y/n] y ... Success! Normally, root should only be allowed to connect from &#39;localhost&#39;. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? [Y/n] y ... Success! By default, MySQL comes with a database named &#39;test&#39; that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? [Y/n] y - Dropping test database... ... Success! - Removing privileges on test database... ... Success! Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? [Y/n] y ... Success! Cleaning up... 记住一路y+回车下来！！ 安装PHP：apt-get install php5 php-pear php5-mysql 完成之后： service apache2 restart 重启apache2服务。 或者使用： /etc/init.d/apache2 restart 下面来测试下： vi /var/www/info.php 按i之后，输入： &lt;?php phpinfo(); ?&gt; esc，:wq保存退出。 打开VPS IP/info.php，例：http://IP/info.php","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.toimc.com/tags/Ubuntu/"},{"name":"LAMP","slug":"LAMP","permalink":"https://www.toimc.com/tags/LAMP/"},{"name":"集成环境搭建","slug":"集成环境搭建","permalink":"https://www.toimc.com/tags/%E9%9B%86%E6%88%90%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}]},{"title":"MySQL权限管理","slug":"MySQL中授权(grant)和撤销授权(revoke)","date":"2016-01-20T17:45:55.000Z","updated":"2019-03-13T01:22:41.000Z","comments":true,"path":"MySQL中授权(grant)和撤销授权(revoke)/","link":"","permalink":"https://www.toimc.com/MySQL%E4%B8%AD%E6%8E%88%E6%9D%83(grant)%E5%92%8C%E6%92%A4%E9%94%80%E6%8E%88%E6%9D%83(revoke)/","excerpt":"本文介绍了MySQL的权限管理，可以满足日常的权限管理需求: 授权、查看用户权限等。","text":"本文介绍了MySQL的权限管理，可以满足日常的权限管理需求: 授权、查看用户权限等。 MySQL 赋予用户权限命令的简单格式可概括为： grant 权限 on 数据库对象 to 用户 grant 普通数据用户，查询、插入、更新、删除 数据库中所有表数据的权利grant select on testdb.* to common_user@&#39;%&#39; grant insert on testdb.* to common_user@&#39;%&#39; grant update on testdb.* to common_user@&#39;%&#39; grant delete on testdb.* to common_user@&#39;%&#39; 或者，用一条 MySQL 命令来替代： grant select, insert, update, delete on testdb.* to common_user@&#39;%&#39; grant 数据库开发人员，创建表、索引、视图、存储过程、函数等权限grant 创建、修改、删除 MySQL 数据表结构权限。 grant create on testdb.* to developer@&#39;192.168.0.%&#39;; grant alter on testdb.* to developer@&#39;192.168.0.%&#39;; grant drop on testdb.* to developer@&#39;192.168.0.%&#39;; grant 操作 MySQL 外键权限： grant references on testdb.* to developer@&#39;192.168.0.%&#39;; grant 操作 MySQL 临时表权限： grant create temporary tables on testdb.* to developer@&#39;192.168.0.%&#39;; grant 操作 MySQL 索引权限： grant index on testdb.* to developer@&#39;192.168.0.%&#39;; grant 操作 MySQL 视图、查看视图源代码权限： grant create view on testdb.* to developer@&#39;192.168.0.%&#39;; grant show view on testdb.* to developer@&#39;192.168.0.%&#39;; grant 操作 MySQL 存储过程、函数权限： grant create routine on testdb.* to developer@&#39;192.168.0.%&#39;; -- now, can show procedure status grant alter routine on testdb.* to developer@&#39;192.168.0.%&#39;; -- now, you can drop a procedure grant execute on testdb.* to developer@&#39;192.168.0.%&#39;; grant 普通 DBA 管理某个 MySQL 数据库的权限grant all privileges on testdb to dba@&#39;localhost&#39; 其中，关键字 “privileges” 可以省略。 grant 高级 DBA 管理 MySQL 中所有数据库的权限：grant all on *.* to dba@&#39;localhost&#39; MySQL grant 权限，分别可以作用在多个层次上1.grant 作用在整个 MySQL 服务器上： grant select on *.* to dba@localhost; -- dba 可以查询 MySQL 中所有数据库中的表。 grant all on *.* to dba@localhost; -- dba 可以管理 MySQL 中的所有数据库 2.grant 作用在单个数据库上： grant select on testdb.* to dba@localhost; -- dba 可以查询 testdb 中的表。 3.grant 作用在单个数据表上： grant select, insert, update, delete on testdb.orders to dba@localhost; 这里在给一个用户授权多张表时，可以多次执行以上语句。例如： grant select(user_id,username) on smp.users to mo_user@&#39;%&#39; identified by &#39;123345&#39;; grant select on smp.mo_sms to mo_user@&#39;%&#39; identified by &#39;123345&#39;; 4.grant 作用在表中的列上： grant select(id, se, rank) on testdb.apache_log to dba@localhost; 5.grant 作用在存储过程、函数上： grant execute on procedure testdb.pr_add to &#39;dba&#39;@&#39;localhost&#39; grant execute on function testdb.fn_add to &#39;dba&#39;@&#39;localhost&#39; 查看 MySQL 用户权限查看当前用户（自己）权限： show grants; 查看其他 MySQL 用户权限： show grants for dba@localhost; 撤销已经赋予给 MySQL 用户权限的权限。revoke 跟 grant 的语法差不多，只需要把关键字 “to” 换成 “from” 即可： grant all on *.* to dba@localhost; revoke all on *.* from dba@localhost; MySQL grant、revoke 用户权限注意事项1.grant, revoke 用户权限后，该用户只有重新连接 MySQL 数据库，权限才能生效。2.如果想让授权的用户，也可以将这些权限 grant 给其他用户，需要选项 “grant option“ grant select on testdb.* to dba@localhost with grant option; 这个特性一般用不到。实际中，数据库权限最好由 DBA 来统一管理。 补充：mysql授权表共有5个表：user、db、host、tables_priv和columns_priv。 授权表的内容有如下用途： user表 user表列出可以连接服务器的用户及其口令，并且它指定他们有哪种全局（超级用户）权限。在user表启用的任何权限均是全局权限，并适用于所有数据库。例如，如果你启用了DELETE权限，在这里列出的用户可以从任何表中删除记录，所以在你这样做之前要认真考虑。 db表 db表列出数据库，而用户有权限访问它们。在这里指定的权限适用于一个数据库中的所有表。 host表 host表与db表结合使用在一个较好层次上控制特定主机对数据库的访问权限，这可能比单独使用db好些。这个表不受GRANT和REVOKE语句的影响，所以，你可能发觉你根本不是用它。 tables_priv表 tables_priv表指定表级权限，在这里指定的一个权限适用于一个表的所有列。 columns_priv表 columns_priv表指定列级权限。这里指定的权限适用于一个表的特定列。","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://www.toimc.com/tags/mysql/"}]}],"categories":[{"name":"nestjs搭建通用业务框架","slug":"nestjs搭建通用业务框架","permalink":"https://www.toimc.com/categories/nestjs%E6%90%AD%E5%BB%BA%E9%80%9A%E7%94%A8%E4%B8%9A%E5%8A%A1%E6%A1%86%E6%9E%B6/"},{"name":"flutter","slug":"flutter","permalink":"https://www.toimc.com/categories/flutter/"},{"name":"架构","slug":"架构","permalink":"https://www.toimc.com/categories/%E6%9E%B6%E6%9E%84/"},{"name":"前端跳槽面试必备技巧","slug":"前端跳槽面试必备技巧","permalink":"https://www.toimc.com/categories/%E5%89%8D%E7%AB%AF%E8%B7%B3%E6%A7%BD%E9%9D%A2%E8%AF%95%E5%BF%85%E5%A4%87%E6%8A%80%E5%B7%A7/"},{"name":"Docker入门","slug":"Docker入门","permalink":"https://www.toimc.com/categories/Docker%E5%85%A5%E9%97%A8/"},{"name":"成长路上","slug":"成长路上","permalink":"https://www.toimc.com/categories/%E6%88%90%E9%95%BF%E8%B7%AF%E4%B8%8A/"},{"name":"git入门","slug":"git入门","permalink":"https://www.toimc.com/categories/git%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"https://www.toimc.com/tags/node-js/"},{"name":"nestjs","slug":"nestjs","permalink":"https://www.toimc.com/tags/nestjs/"},{"name":"web框架","slug":"web框架","permalink":"https://www.toimc.com/tags/web%E6%A1%86%E6%9E%B6/"},{"name":"Dependecy Injection(DI)","slug":"Dependecy-Injection-DI","permalink":"https://www.toimc.com/tags/Dependecy-Injection-DI/"},{"name":"Invention of Control(IoC)","slug":"Invention-of-Control-IoC","permalink":"https://www.toimc.com/tags/Invention-of-Control-IoC/"},{"name":"依赖注入","slug":"依赖注入","permalink":"https://www.toimc.com/tags/%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/"},{"name":"架构思维","slug":"架构思维","permalink":"https://www.toimc.com/tags/%E6%9E%B6%E6%9E%84%E6%80%9D%E7%BB%B4/"},{"name":"flutter","slug":"flutter","permalink":"https://www.toimc.com/tags/flutter/"},{"name":"https","slug":"https","permalink":"https://www.toimc.com/tags/https/"},{"name":"ssl","slug":"ssl","permalink":"https://www.toimc.com/tags/ssl/"},{"name":"nginx","slug":"nginx","permalink":"https://www.toimc.com/tags/nginx/"},{"name":"docker","slug":"docker","permalink":"https://www.toimc.com/tags/docker/"},{"name":"Redis","slug":"Redis","permalink":"https://www.toimc.com/tags/Redis/"},{"name":"redis-cli","slug":"redis-cli","permalink":"https://www.toimc.com/tags/redis-cli/"},{"name":"Hyper-V","slug":"Hyper-V","permalink":"https://www.toimc.com/tags/Hyper-V/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://www.toimc.com/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"Vue3","slug":"Vue3","permalink":"https://www.toimc.com/tags/Vue3/"},{"name":"Vuejs","slug":"Vuejs","permalink":"https://www.toimc.com/tags/Vuejs/"},{"name":"Vue","slug":"Vue","permalink":"https://www.toimc.com/tags/Vue/"},{"name":"Docker","slug":"Docker","permalink":"https://www.toimc.com/tags/Docker/"},{"name":"前端面试","slug":"前端面试","permalink":"https://www.toimc.com/tags/%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95/"},{"name":"技巧总结","slug":"技巧总结","permalink":"https://www.toimc.com/tags/%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/"},{"name":"Linux","slug":"Linux","permalink":"https://www.toimc.com/tags/Linux/"},{"name":"vps","slug":"vps","permalink":"https://www.toimc.com/tags/vps/"},{"name":"读书计划","slug":"读书计划","permalink":"https://www.toimc.com/tags/%E8%AF%BB%E4%B9%A6%E8%AE%A1%E5%88%92/"},{"name":"时间计划","slug":"时间计划","permalink":"https://www.toimc.com/tags/%E6%97%B6%E9%97%B4%E8%AE%A1%E5%88%92/"},{"name":"生活随感","slug":"生活随感","permalink":"https://www.toimc.com/tags/%E7%94%9F%E6%B4%BB%E9%9A%8F%E6%84%9F/"},{"name":"逻辑思维","slug":"逻辑思维","permalink":"https://www.toimc.com/tags/%E9%80%BB%E8%BE%91%E6%80%9D%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://www.toimc.com/tags/mysql/"},{"name":"linux","slug":"linux","permalink":"https://www.toimc.com/tags/linux/"},{"name":"创业","slug":"创业","permalink":"https://www.toimc.com/tags/%E5%88%9B%E4%B8%9A/"},{"name":"php","slug":"php","permalink":"https://www.toimc.com/tags/php/"},{"name":"python","slug":"python","permalink":"https://www.toimc.com/tags/python/"},{"name":"UI","slug":"UI","permalink":"https://www.toimc.com/tags/UI/"},{"name":"Gitlab","slug":"Gitlab","permalink":"https://www.toimc.com/tags/Gitlab/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://www.toimc.com/tags/Jenkins/"},{"name":"git","slug":"git","permalink":"https://www.toimc.com/tags/git/"},{"name":"版本控制","slug":"版本控制","permalink":"https://www.toimc.com/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"name":"运维","slug":"运维","permalink":"https://www.toimc.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.toimc.com/tags/Ubuntu/"},{"name":"集成环境搭建","slug":"集成环境搭建","permalink":"https://www.toimc.com/tags/%E9%9B%86%E6%88%90%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"LNMP","slug":"LNMP","permalink":"https://www.toimc.com/tags/LNMP/"},{"name":"webstorm","slug":"webstorm","permalink":"https://www.toimc.com/tags/webstorm/"},{"name":"css","slug":"css","permalink":"https://www.toimc.com/tags/css/"},{"name":"autoprefixer","slug":"autoprefixer","permalink":"https://www.toimc.com/tags/autoprefixer/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://www.toimc.com/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"Javascript","slug":"Javascript","permalink":"https://www.toimc.com/tags/Javascript/"},{"name":"http","slug":"http","permalink":"https://www.toimc.com/tags/http/"},{"name":"调试技巧","slug":"调试技巧","permalink":"https://www.toimc.com/tags/%E8%B0%83%E8%AF%95%E6%8A%80%E5%B7%A7/"},{"name":"MySQL","slug":"MySQL","permalink":"https://www.toimc.com/tags/MySQL/"},{"name":"wordpress","slug":"wordpress","permalink":"https://www.toimc.com/tags/wordpress/"},{"name":"gulp","slug":"gulp","permalink":"https://www.toimc.com/tags/gulp/"},{"name":"前端自动化","slug":"前端自动化","permalink":"https://www.toimc.com/tags/%E5%89%8D%E7%AB%AF%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"PHP","slug":"PHP","permalink":"https://www.toimc.com/tags/PHP/"},{"name":"开发环境","slug":"开发环境","permalink":"https://www.toimc.com/tags/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"name":"ssh","slug":"ssh","permalink":"https://www.toimc.com/tags/ssh/"},{"name":"Apache","slug":"Apache","permalink":"https://www.toimc.com/tags/Apache/"},{"name":"vim","slug":"vim","permalink":"https://www.toimc.com/tags/vim/"},{"name":"LAMP","slug":"LAMP","permalink":"https://www.toimc.com/tags/LAMP/"}]}